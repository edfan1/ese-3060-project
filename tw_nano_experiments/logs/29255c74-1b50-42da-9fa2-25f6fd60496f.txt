====================================================================================================
# NOTE: record from https://github.com/KellerJordan/modded-nanogpt/blob/master/records/track_1_short/2024-10-14_ModernArch/dabaaddd-237c-4ec9-939d-6608a9ed5e27.txt
# ====================================================================================================
import os
import sys
with open(sys.argv[0]) as f:
    code = f.read() # read the code of this file ASAP, for logging
import uuid
import glob
import time
import math
import random
import argparse
from dataclasses import dataclass, field
from typing import Optional, Tuple, Dict, Any

import numpy as np
import torch
from torch import nn
import torch.nn.functional as F
import torch.distributed as dist
import torch._inductor.config as config
from torch.nn.parallel import DistributedDataParallel as DDP

# -----------------------------------------------------------------------------
# Token Importance Weighting Configuration

@dataclass
class TokenWeightingConfig:
    """Configuration for token importance weighting ablations."""
    enabled: bool = False
    function: str = "linear"  # linear, sqrt, log, focal
    clamp_min: float = 0.5
    clamp_max: float = 2.0
    schedule: str = "constant"  # constant, warmup, anneal, cyclical, adaptive
    warmup_steps: int = 1000
    anneal_final_strength: float = 0.3  # for anneal schedule
    cyclical_period: int = 500  # for cyclical schedule
    focal_gamma: float = 2.0  # for focal loss style weighting
    percentile_clamp: bool = False  # use percentile-based clamping instead of fixed bounds
    percentile_low: float = 0.05  # lower percentile for clamping
    percentile_high: float = 0.95  # upper percentile for clamping
    log_weights: bool = True  # whether to log weight statistics
    log_every: int = 50  # log weight stats every N steps

def compute_schedule_strength(
    step: int,
    total_steps: int,
    config: TokenWeightingConfig,
    val_loss: Optional[float] = None
) -> float:
    """
    Compute the weighting strength multiplier based on the schedule.
    Returns a value in [0, 1] that scales the deviation from uniform weighting.
    """
    if config.schedule == "constant":
        return 1.0
    
    elif config.schedule == "warmup":
        # Linear warmup: start uniform, gradually introduce weighting
        return min(step / config.warmup_steps, 1.0)
    
    elif config.schedule == "anneal":
        # Annealing: start with strong weighting, decay toward uniform
        # decay_ratio goes from 1.0 to anneal_final_strength
        progress = step / total_steps
        return 1.0 - progress * (1.0 - config.anneal_final_strength)
    
    elif config.schedule == "cyclical":
        # Sine wave oscillation between weak and strong weighting
        return 0.5 + 0.5 * math.sin(step / config.cyclical_period * 2 * math.pi)
    
    elif config.schedule == "adaptive":
        # Validation-loss-based: strong when loss is high, weaker as loss decreases
        if val_loss is None:
            return 1.0  # Default to full strength if no val loss available
        # Normalize by approximate initial loss (~4.0 for GPT training)
        return min(val_loss / 4.0, 1.0)
    
    else:
        raise ValueError(f"Unknown schedule: {config.schedule}")

def compute_token_weights(
    per_token_loss: torch.Tensor,
    config: TokenWeightingConfig,
    step: int,
    total_steps: int,
    val_loss: Optional[float] = None
) -> Tuple[torch.Tensor, Dict[str, float]]:
    """
    Compute importance weights for tokens based on their loss.
    
    Args:
        per_token_loss: Tensor of shape (batch_size * seq_len,) with per-token losses
        config: TokenWeightingConfig with weighting parameters
        step: Current training step
        total_steps: Total number of training steps
        val_loss: Current validation loss (for adaptive schedule)
    
    Returns:
        weights: Tensor of same shape as per_token_loss with importance weights
        stats: Dictionary with weight statistics for logging
    """
    if not config.enabled:
        return torch.ones_like(per_token_loss), {}
    
    # Detach to prevent gradient flow through weights
    loss_detached = per_token_loss.detach()
    
    # Compute raw weights based on weighting function
    if config.function == "linear":
        # Relative weighting: weight = loss / mean_loss
        mean_loss = loss_detached.mean()
        weights = loss_detached / (mean_loss + 1e-8)
    
    elif config.function == "sqrt":
        # Square root weighting: more moderate than linear
        mean_loss = loss_detached.mean()
        normalized_loss = loss_detached / (mean_loss + 1e-8)
        weights = torch.sqrt(normalized_loss)
    
    elif config.function == "log":
        # Logarithmic weighting: most conservative
        mean_loss = loss_detached.mean()
        normalized_loss = loss_detached / (mean_loss + 1e-8)
        # log1p for numerical stability (log(1 + x))
        weights = torch.log1p(normalized_loss)
    
    elif config.function == "focal":
        # Focal loss style: (loss / max_loss)^gamma
        max_loss = loss_detached.max()
        normalized_loss = loss_detached / (max_loss + 1e-8)
        weights = torch.pow(normalized_loss, config.focal_gamma)
    
    else:
        raise ValueError(f"Unknown weighting function: {config.function}")
    
    # Apply clamping
    if config.percentile_clamp:
        # Dynamic bounds based on percentiles
        p_low = torch.quantile(weights, config.percentile_low)
        p_high = torch.quantile(weights, config.percentile_high)
        weights = weights.clamp(p_low, p_high)
    else:
        # Fixed bounds
        weights = weights.clamp(config.clamp_min, config.clamp_max)
    
    # Apply schedule (interpolate between uniform and computed weights)
    strength = compute_schedule_strength(step, total_steps, config, val_loss)
    # weights = 1.0 + (weights - 1.0) * strength
    # This interpolates: at strength=0, weights=1 (uniform); at strength=1, weights=computed
    weights = 1.0 + (weights - 1.0) * strength
    
    # Normalize weights to have mean 1.0 (preserve expected gradient magnitude)
    weights = weights / (weights.mean() + 1e-8)
    
    # Compute statistics for logging
    stats = {}
    if config.log_weights:
        stats = {
            'weight_mean': weights.mean().item(),
            'weight_std': weights.std().item(),
            'weight_min': weights.min().item(),
            'weight_max': weights.max().item(),
            'weight_gt_1.5': (weights > 1.5).float().mean().item() * 100,  # percentage
            'weight_lt_0.5': (weights < 0.5).float().mean().item() * 100,  # percentage
            'schedule_strength': strength,
        }
    
    return weights, stats

# -----------------------------------------------------------------------------
# Random seed utilities for reproducibility

def set_seed(seed: int, rank: int = 0, deterministic: bool = True):
    """
    Set random seeds for reproducibility across distributed training.
    
    Args:
        seed: Base random seed
        rank: DDP rank (used to offset data sampling seeds)
        deterministic: If True, enable deterministic algorithms (may impact performance)
    """
    # Set Python random seed
    random.seed(seed)
    
    # Set NumPy seed (offset by rank for different data sampling per GPU)
    np.random.seed(seed + rank)
    
    # Set PyTorch seeds
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)  # for multi-GPU
    
    # Configure deterministic behavior
    if deterministic:
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False
        # Enable deterministic algorithms (PyTorch 1.8+)
        if hasattr(torch, 'use_deterministic_algorithms'):
            try:
                torch.use_deterministic_algorithms(True, warn_only=True)
            except Exception:
                pass  # Some operations may not have deterministic implementations
    else:
        # For maximum performance, allow non-deterministic algorithms
        torch.backends.cudnn.deterministic = False
        torch.backends.cudnn.benchmark = True

# -----------------------------------------------------------------------------
# Muon optimizer

def zeropower_via_svd(G, steps=None):
    U, S, V = G.svd()
    return U @ V.T

@torch.compile
def zeropower_via_newtonschulz5(G, steps=10, eps=1e-7):
    """
    Newton-Schulz iteration to compute the zeroth power / orthogonalization of G. We opt to use a
    quintic iteration whose coefficients are selected to maximize the slope at zero. For the purpose
    of minimizing steps, it turns out to be empirically effective to keep increasing the slope at
    zero even beyond the point where the iteration no longer converges all the way to one everywhere
    on the interval. This iteration therefore does not produce UV^T but rather something like US'V^T
    where S' is diagonal with S_{ii}' \sim Uniform(0.5, 1.5), which turns out not to hurt model
    performance at all relative to UV^T, where USV^T = G is the SVD.
    """
    assert len(G.shape) == 2
    a, b, c = (3.4445, -4.7750,  2.0315)
    X = G.bfloat16()
    X /= (X.norm() + eps) # ensure top singular value <= 1
    if G.size(0) > G.size(1):
        X = X.T
    for _ in range(steps):
        A = X @ X.T
        B = A @ X
        X = a * X + b * B + c * A @ B
    if G.size(0) > G.size(1):
        X = X.T
    return X

zeropower_backends = dict(svd=zeropower_via_svd, newtonschulz5=zeropower_via_newtonschulz5)

class Muon(torch.optim.Optimizer):
    """
    Muon - MomentUm Orthogonalized by Newton-schulz

    Muon internally runs standard SGD-momentum, and then performs an orthogonalization post-
    processing step, in which each 2D parameter's update is replaced with the nearest orthogonal
    matrix. To efficiently orthogonalize each update, we use a Newton-Schulz iteration, which has
    the advantage that it can be stably run in bfloat16 on the GPU.

    Some warnings:
    - This optimizer assumes that all parameters passed in are 2D.
    - It should not be used for the embedding layer, the final fully connected layer, or any {0,1}-D
    parameters; those should all be optimized by a standard method (e.g., AdamW).
    - To use it with 4D convolutional filters, it works well to just flatten their last 3 dimensions.
    - We believe it is unlikely to work well for training with small batch size.
    - We believe it may not work well for finetuning pretrained models, but we haven't tested this.
    - We have not yet tried this optimizer for training scenarios larger than NanoGPT (124M).

    Arguments:
        lr: The learning rate used by the internal SGD.
        momentum: The momentum used by the internal SGD.
        nesterov: Whether to use Nesterov-style momentum in the internal SGD. (recommended)
        backend: The chosen backend for the orthogonalization step. (recommended: 'newtonschulz5')
        backend_steps: The number of iteration steps to use in the backend, if it is iterative.
    """
    def __init__(self, params, lr=3e-4, momentum=0.95, nesterov=True, backend='newtonschulz5', backend_steps=5):
        defaults = dict(lr=lr, momentum=momentum, nesterov=nesterov, backend=backend, backend_steps=backend_steps)
        super().__init__(params, defaults)

    def step(self):
        for group in self.param_groups:
            lr = group['lr']
            momentum = group['momentum']
            zeropower_backend = zeropower_backends[group['backend']]
            for p in group['params']:
                g = p.grad
                if g is None:
                    continue
                state = self.state[p]
                if 'momentum_buffer' not in state:
                    state['momentum_buffer'] = torch.zeros_like(g)
                buf = state['momentum_buffer']
                buf.mul_(momentum).add_(g)
                if group['nesterov']:
                    g = g.add(buf, alpha=momentum)
                if g.size(0) == 3 * g.size(1): # split grouped QKV parameters
                    g = torch.cat([zeropower_backend(g1, steps=group['backend_steps']) for g1 in g.split(g.size(1))])
                    scale = g.size(1)**0.5
                else:
                    g = zeropower_backend(g, steps=group['backend_steps'])
                    scale = max(g.size(0), g.size(1))**0.5 # scale to have update.square().mean() == 1
                p.data.add_(g, alpha=-lr * scale)

# -----------------------------------------------------------------------------
# PyTorch nn.Module definitions for the GPT-2 model

class Rotary(torch.nn.Module):

    def __init__(self, dim, base=10000):
        super().__init__()
        self.inv_freq = 1.0 / (base ** (torch.arange(0, dim, 2).float() / dim))
        self.seq_len_cached = None
        self.cos_cached = None
        self.sin_cached = None

    def forward(self, x):
        seq_len = x.shape[1]
        if seq_len != self.seq_len_cached:
            self.seq_len_cached = seq_len
            t = torch.arange(seq_len, device=x.device).type_as(self.inv_freq)
            freqs = torch.outer(t, self.inv_freq).to(x.device)
            self.cos_cached = freqs.cos().bfloat16()
            self.sin_cached = freqs.sin().bfloat16()
        return self.cos_cached[None, :, None, :], self.sin_cached[None, :, None, :]

def apply_rotary_emb(x, cos, sin):
    assert x.ndim == 4 # multihead attention
    d = x.shape[3]//2
    x1 = x[..., :d]
    x2 = x[..., d:]
    y1 = x1 * cos + x2 * sin
    y2 = x1 * (-sin) + x2 * cos
    return torch.cat([y1, y2], 3).type_as(x)

class CausalSelfAttention(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.n_head = config.n_head
        self.n_embd = config.n_embd
        self.head_dim = self.n_embd // self.n_head
        assert self.n_embd % self.n_head == 0
        self.c_q = nn.Linear(self.n_embd, self.n_embd, bias=False)
        self.c_k = nn.Linear(self.n_embd, self.n_embd, bias=False)
        self.c_v = nn.Linear(self.n_embd, self.n_embd, bias=False)
        # output projection
        self.c_proj = nn.Linear(self.n_embd, self.n_embd, bias=False)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977
        self.rotary = Rotary(self.head_dim)

    def forward(self, x):
        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)
        q = self.c_q(x).view(B, T, self.n_head, self.head_dim)
        k = self.c_k(x).view(B, T, self.n_head, self.head_dim)
        v = self.c_v(x).view(B, T, self.n_head, self.head_dim)
        cos, sin = self.rotary(q)
        q, k = apply_rotary_emb(q, cos, sin), apply_rotary_emb(k, cos, sin)
        q, k = F.rms_norm(q, (q.size(-1),)), F.rms_norm(k, (k.size(-1),)) # QK norm suggested by @Grad62304977
        y = F.scaled_dot_product_attention(q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2), is_causal=True)
        y = y.transpose(1, 2).contiguous().view_as(x) # re-assemble all head outputs side by side
        y = self.c_proj(y)
        return y

class MLP(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.c_fc    = nn.Linear(config.n_embd, 4 * config.n_embd, bias=False)
        self.c_proj  = nn.Linear(4 * config.n_embd, config.n_embd, bias=False)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977

    def forward(self, x):
        x = self.c_fc(x)
        x = F.relu(x).square() # https://arxiv.org/abs/2109.08668v2; ~1-2% better than GELU; suggested by @SKYLINEZ007 and @Grad62304977
        x = self.c_proj(x)
        return x

class Block(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.attn = CausalSelfAttention(config)
        self.mlp = MLP(config)

    def forward(self, x):
        x = x + self.attn(F.rms_norm(x, (x.size(-1),)))
        x = x + self.mlp(F.rms_norm(x, (x.size(-1),)))
        return x

# -----------------------------------------------------------------------------
# The main GPT-2 model

@dataclass
class GPTConfig:
    vocab_size : int = 50304
    n_layer : int = 12
    n_head : int = 6 # head dim 128 suggested by @Grad62304977
    n_embd : int = 768

class GPT(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.config = config

        self.transformer = nn.ModuleDict(dict(
            wte = nn.Embedding(config.vocab_size, config.n_embd),
            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),
        ))
        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)
        self.transformer.wte.weight = self.lm_head.weight # https://paperswithcode.com/method/weight-tying

    def forward(self, idx, targets=None, return_logits=True, return_per_token_loss=False):
        """
        Forward pass through the GPT model.
        
        Args:
            idx: Input token indices of shape (batch_size, seq_len)
            targets: Target token indices of shape (batch_size, seq_len)
            return_logits: Whether to return logits
            return_per_token_loss: Whether to return per-token loss (for token weighting)
        
        Returns:
            logits: Output logits (if return_logits=True)
            loss: Scalar loss (mean) or per-token loss tensor (if return_per_token_loss=True)
        """
        # forward the GPT model itself
        x = self.transformer.wte(idx) # token embeddings of shape (b, t, n_embd)
        for block in self.transformer.h:
            x = block(x)
        x = F.rms_norm(x, (x.size(-1),))

        if targets is not None:
            # if we are given some desired targets also calculate the loss
            logits = self.lm_head(x)
            logits = logits.float() # use tf32/fp32 for logits
            
            if return_per_token_loss:
                # Return per-token loss for token importance weighting
                # Shape: (batch_size * seq_len,)
                per_token_loss = F.cross_entropy(
                    logits.view(-1, logits.size(-1)), 
                    targets.view(-1), 
                    ignore_index=-1,
                    reduction='none'
                )
                loss = per_token_loss  # Return unreduced loss
            else:
                loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)
        else:
            # inference-time mini-optimization: only forward the lm_head on the very last position
            logits = self.lm_head(x[:, [-1], :]) # note: using list [-1] to preserve the time dim
            logits = logits.float() # use tf32/fp32 for logits
            loss = None

        # there are performance reasons why not returning logits is prudent, if not needed
        if not return_logits:
            logits = None

        return logits, loss

# -----------------------------------------------------------------------------
# Our own simple Distributed Data Loader

def _peek_data_shard(filename):
    # only reads the header, returns header data
    with open(filename, "rb") as f:
        # first read the header, which is 256 int32 integers (4 bytes each)
        header = np.frombuffer(f.read(256*4), dtype=np.int32)
    if header[0] != 20240520:
        print("ERROR: magic number mismatch in the data .bin file!")
        print("---> HINT: Are you passing in a correct file with --input_bin?")
        print("---> HINT: Dataset encoding changed recently, re-run data prepro or refer again to README")
        print("---> HINT: For example re-run: `python dev/data/tinyshakespeare.py`, then re-try")
        exit(1)
    assert header[1] == 1, "unsupported version"
    ntok = header[2] # number of tokens (claimed)
    return ntok # for now just return the number of tokens

def _load_data_shard(filename):
    with open(filename, "rb") as f:
        # first read the header, which is 256 int32 integers (4 bytes each)
        header = np.frombuffer(f.read(256*4), dtype=np.int32)
        assert header[0] == 20240520, "magic number mismatch in the data .bin file"
        assert header[1] == 1, "unsupported version"
        ntok = header[2] # number of tokens (claimed)
        # the rest of it are tokens, stored as uint16
        tokens = np.frombuffer(f.read(), dtype=np.uint16)
    assert len(tokens) == ntok, "number of tokens read does not match header?"
    return tokens

class DistributedDataLoader:
    def __init__(self, filename_pattern, B, T, process_rank, num_processes, seed=None):
        self.process_rank = process_rank
        self.num_processes = num_processes
        self.B = B
        self.T = T
        self.seed = seed

        # glob files that match the pattern
        self.files = sorted(glob.glob(filename_pattern))
        assert len(self.files) > 0, f"did not find any files that match the pattern {filename_pattern}"

        # load and validate all data shards, count number of tokens in total
        ntok_total = 0
        for fname in self.files:
            shard_ntok = _peek_data_shard(fname)
            assert shard_ntok >= num_processes * B * T + 1
            ntok_total += int(shard_ntok)
        self.ntok_total = ntok_total

        # kick things off
        self.reset()

    def reset(self):
        self.current_shard = 0
        self.current_position = self.process_rank * self.B * self.T
        self.tokens = _load_data_shard(self.files[self.current_shard])

    def advance(self): # advance to next data shard
        self.current_shard = (self.current_shard + 1) % len(self.files)
        self.current_position = self.process_rank * self.B * self.T
        self.tokens = _load_data_shard(self.files[self.current_shard])

    def next_batch(self):
        B = self.B
        T = self.T
        buf = self.tokens[self.current_position : self.current_position+B*T+1]
        buf = torch.tensor(buf.astype(np.int32), dtype=torch.long)
        x = (buf[:-1]).view(B, T) # inputs
        y = (buf[1:]).view(B, T) # targets
        # advance current position and load next shard if necessary
        self.current_position += B * T * self.num_processes
        if self.current_position + (B * T * self.num_processes + 1) > len(self.tokens):
            self.advance()
        return x.cuda(), y.cuda()

# -----------------------------------------------------------------------------
# int main

@dataclass
class Hyperparameters:
    # data hyperparams
    input_bin : str = 'data/fineweb10B/fineweb_train_*.bin' # input .bin to train on
    input_val_bin : str = 'data/fineweb10B/fineweb_val_*.bin' # input .bin to eval validation loss on
    # optimization hyperparams
    batch_size : int = 8*64 # batch size, in sequences, across all devices
    device_batch_size : int = 64 # batch size, in sequences, per device
    sequence_length : int = 1024 # sequence length, in tokens
    num_iterations : int = 5100 # number of iterations to run
    learning_rate : float = 0.0036
    warmup_iters : int = 0
    warmdown_iters : int = 1450 # number of iterations of linear warmup/warmdown for triangular or trapezoidal schedule
    weight_decay : float = 0
    # evaluation and logging hyperparams
    val_loss_every : int = 125 # every how many steps to evaluate val loss? 0 for only at the end
    val_tokens : int = 10485760 # how many tokens of validation data? it's important to keep this fixed for consistent comparisons
    save_every : int = 0 # every how many steps to save the checkpoint? 0 for only at the end
    # reproducibility hyperparams
    seed : int = None # random seed for reproducibility (None = no seeding, uses system entropy)
    deterministic : bool = False # if True, use deterministic algorithms (slower but reproducible)
    # token weighting hyperparams (for ablations)
    tw_enabled : bool = False  # enable token importance weighting
    tw_function : str = "linear"  # weighting function: linear, sqrt, log, focal
    tw_clamp_min : float = 0.5  # minimum weight clamp
    tw_clamp_max : float = 2.0  # maximum weight clamp
    tw_schedule : str = "constant"  # schedule: constant, warmup, anneal, cyclical, adaptive
    tw_warmup_steps : int = 1000  # warmup steps for warmup schedule
    tw_anneal_final : float = 0.3  # final strength for anneal schedule
    tw_cyclical_period : int = 500  # period for cyclical schedule
    tw_focal_gamma : float = 2.0  # gamma for focal loss style weighting
    tw_percentile_clamp : bool = False  # use percentile-based clamping
    tw_percentile_low : float = 0.05  # lower percentile for clamping
    tw_percentile_high : float = 0.95  # upper percentile for clamping
    tw_log_weights : bool = True  # log weight statistics
    tw_log_every : int = 50  # log weight stats every N steps

def parse_args():
    """Parse command line arguments and return Hyperparameters and TokenWeightingConfig."""
    parser = argparse.ArgumentParser(description='NanoGPT Training with Token Importance Weighting')
    
    # Data hyperparams
    parser.add_argument('--input_bin', type=str, default='../fineweb10B/fineweb_train_*.bin')
    parser.add_argument('--input_val_bin', type=str, default='../fineweb10B/fineweb_val_*.bin')
    
    # Optimization hyperparams
    parser.add_argument('--batch_size', type=int, default=8*64)
    parser.add_argument('--device_batch_size', type=int, default=64)
    parser.add_argument('--sequence_length', type=int, default=1024)
    parser.add_argument('--num_iterations', type=int, default=5100)
    parser.add_argument('--learning_rate', type=float, default=0.0036)
    parser.add_argument('--warmup_iters', type=int, default=0)
    parser.add_argument('--warmdown_iters', type=int, default=1450)
    parser.add_argument('--weight_decay', type=float, default=0)
    
    # Evaluation and logging hyperparams
    parser.add_argument('--val_loss_every', type=int, default=125)
    parser.add_argument('--val_tokens', type=int, default=10485760)
    parser.add_argument('--save_every', type=int, default=0)
    
    # Reproducibility hyperparams
    parser.add_argument('--seed', type=int, default=None)
    parser.add_argument('--deterministic', action='store_true')
    
    # Token weighting hyperparams (for ablations)
    parser.add_argument('--tw_enabled', action='store_true', help='Enable token importance weighting')
    parser.add_argument('--tw_function', type=str, default='linear', 
                        choices=['linear', 'sqrt', 'log', 'focal'],
                        help='Weighting function')
    parser.add_argument('--tw_clamp_min', type=float, default=0.5, help='Minimum weight clamp')
    parser.add_argument('--tw_clamp_max', type=float, default=2.0, help='Maximum weight clamp')
    parser.add_argument('--tw_schedule', type=str, default='constant',
                        choices=['constant', 'warmup', 'anneal', 'cyclical', 'adaptive'],
                        help='Weighting schedule')
    parser.add_argument('--tw_warmup_steps', type=int, default=1000, help='Warmup steps')
    parser.add_argument('--tw_anneal_final', type=float, default=0.3, help='Final strength for anneal')
    parser.add_argument('--tw_cyclical_period', type=int, default=500, help='Period for cyclical')
    parser.add_argument('--tw_focal_gamma', type=float, default=2.0, help='Gamma for focal loss')
    parser.add_argument('--tw_percentile_clamp', action='store_true', help='Use percentile clamping')
    parser.add_argument('--tw_percentile_low', type=float, default=0.05, help='Lower percentile')
    parser.add_argument('--tw_percentile_high', type=float, default=0.95, help='Upper percentile')
    parser.add_argument('--tw_log_weights', action='store_true', help='Log weight statistics')
    parser.add_argument('--tw_log_every', type=int, default=50, help='Log weights every N steps')
    
    parsed_args = parser.parse_args()
    
    # Create Hyperparameters
    args = Hyperparameters(
        input_bin=parsed_args.input_bin,
        input_val_bin=parsed_args.input_val_bin,
        batch_size=parsed_args.batch_size,
        device_batch_size=parsed_args.device_batch_size,
        sequence_length=parsed_args.sequence_length,
        num_iterations=parsed_args.num_iterations,
        learning_rate=parsed_args.learning_rate,
        warmup_iters=parsed_args.warmup_iters,
        warmdown_iters=parsed_args.warmdown_iters,
        weight_decay=parsed_args.weight_decay,
        val_loss_every=parsed_args.val_loss_every,
        val_tokens=parsed_args.val_tokens,
        save_every=parsed_args.save_every,
        seed=parsed_args.seed,
        deterministic=parsed_args.deterministic,
        tw_enabled=parsed_args.tw_enabled,
        tw_function=parsed_args.tw_function,
        tw_clamp_min=parsed_args.tw_clamp_min,
        tw_clamp_max=parsed_args.tw_clamp_max,
        tw_schedule=parsed_args.tw_schedule,
        tw_warmup_steps=parsed_args.tw_warmup_steps,
        tw_anneal_final=parsed_args.tw_anneal_final,
        tw_cyclical_period=parsed_args.tw_cyclical_period,
        tw_focal_gamma=parsed_args.tw_focal_gamma,
        tw_percentile_clamp=parsed_args.tw_percentile_clamp,
        tw_percentile_low=parsed_args.tw_percentile_low,
        tw_percentile_high=parsed_args.tw_percentile_high,
        tw_log_weights=parsed_args.tw_log_weights,
        tw_log_every=parsed_args.tw_log_every,
    )
    
    # Create TokenWeightingConfig
    tw_config = TokenWeightingConfig(
        enabled=parsed_args.tw_enabled,
        function=parsed_args.tw_function,
        clamp_min=parsed_args.tw_clamp_min,
        clamp_max=parsed_args.tw_clamp_max,
        schedule=parsed_args.tw_schedule,
        warmup_steps=parsed_args.tw_warmup_steps,
        anneal_final_strength=parsed_args.tw_anneal_final,
        cyclical_period=parsed_args.tw_cyclical_period,
        focal_gamma=parsed_args.tw_focal_gamma,
        percentile_clamp=parsed_args.tw_percentile_clamp,
        percentile_low=parsed_args.tw_percentile_low,
        percentile_high=parsed_args.tw_percentile_high,
        log_weights=parsed_args.tw_log_weights,
        log_every=parsed_args.tw_log_every,
    )
    
    return args, tw_config

# Parse arguments
args, tw_config = parse_args()

# set up DDP (distributed data parallel). torchrun sets this env variable
assert torch.cuda.is_available()
dist.init_process_group(backend='nccl')
ddp_rank = int(os.environ['RANK'])
ddp_local_rank = int(os.environ['LOCAL_RANK'])
ddp_world_size = int(os.environ['WORLD_SIZE'])
device = f'cuda:{ddp_local_rank}'
torch.cuda.set_device(device)
print(f"using device: {device}")
master_process = (ddp_rank == 0) # this process will do logging, checkpointing etc.

# Set random seeds for reproducibility (must be done after DDP init but before model creation)
if args.seed is not None:
    set_seed(args.seed, rank=ddp_rank, deterministic=args.deterministic)
    if master_process:
        print(f"Random seed set to {args.seed} (deterministic={args.deterministic})")

# convenience variables
B, T = args.device_batch_size, args.sequence_length
# calculate the number of steps to take in the val loop.
assert args.val_tokens % (B * T * ddp_world_size) == 0
val_steps = args.val_tokens // (B * T * ddp_world_size)
# calculate the steps of gradient accumulation required to attain the desired global batch size.
assert args.batch_size % (B * ddp_world_size) == 0
train_accumulation_steps = args.batch_size // (B * ddp_world_size)

# load tokens
train_loader = DistributedDataLoader(args.input_bin, B, T, ddp_rank, ddp_world_size, seed=args.seed)
val_loader = DistributedDataLoader(args.input_val_bin, B, T, ddp_rank, ddp_world_size, seed=args.seed)
if master_process:
    print(f"Training DataLoader: total number of tokens: {train_loader.ntok_total} across {len(train_loader.files)} files")
    print(f"Validation DataLoader: total number of tokens: {val_loader.ntok_total} across {len(val_loader.files)} files")
x, y = train_loader.next_batch()

# there are only 50257 unique GPT-2 tokens; we extend to nearest multiple of 128 for efficiency. suggested to me by @Grad62304977.
# this originates from Karpathy's experiments.
num_vocab = 50304
model = GPT(GPTConfig(vocab_size=num_vocab, n_layer=12, n_head=6, n_embd=768))
model = model.cuda()
if hasattr(config, "coordinate_descent_tuning"):
    config.coordinate_descent_tuning = True # suggested by @Chillee
model = torch.compile(model)
# here we wrap model into DDP container
model = DDP(model, device_ids=[ddp_local_rank])
raw_model = model.module # always contains the "raw" unwrapped model
ctx = torch.amp.autocast(device_type='cuda', dtype=torch.bfloat16)

# init the optimizer(s)
optimizer1 = torch.optim.AdamW(raw_model.lm_head.parameters(), lr=args.learning_rate, betas=(0.9, 0.95),
                               weight_decay=args.weight_decay, fused=True)
optimizer2 = Muon(raw_model.transformer.h.parameters(), lr=0.1*args.learning_rate, momentum=0.95)
optimizers = [optimizer1, optimizer2]
# learning rate decay scheduler (linear warmup and warmdown)
def get_lr(it):
    assert it <= args.num_iterations
    # 1) linear warmup for warmup_iters steps
    if it < args.warmup_iters:
        return (it+1) / args.warmup_iters
    # 2) constant lr for a while
    elif it < args.num_iterations - args.warmdown_iters:
        return 1.0
    # 3) linear warmdown
    else:
        decay_ratio = (args.num_iterations - it) / args.warmdown_iters
        return decay_ratio
schedulers = [torch.optim.lr_scheduler.LambdaLR(opt, get_lr) for opt in optimizers]

# begin logging
if master_process:
    run_id = str(uuid.uuid4())
    logdir = 'logs/%s/' % run_id
    os.makedirs(logdir, exist_ok=True)
    logfile = 'logs/%s.txt' % run_id
    # create the log file
    with open(logfile, "w") as f:
        # begin the log by printing this file (the Python code)
        f.write('='*100 + '\n')
        f.write(code)
        f.write('='*100 + '\n')
        # log information about the hardware/software environment this is running on
        # and print the full `nvidia-smi` to file
        f.write(f"Running pytorch {torch.version.__version__} compiled for CUDA {torch.version.cuda}\nnvidia-smi:\n")
        import subprocess
        result = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
        f.write(f'{result.stdout}\n')
        f.write('='*100 + '\n')
        # log the random seed if set
        if args.seed is not None:
            f.write(f"Random seed: {args.seed} (deterministic={args.deterministic})\n")
            f.write('='*100 + '\n')
        # log token weighting configuration
        if tw_config.enabled:
            f.write(f"Token Weighting Configuration:\n")
            f.write(f"  function: {tw_config.function}\n")
            f.write(f"  clamp: [{tw_config.clamp_min}, {tw_config.clamp_max}]\n")
            f.write(f"  schedule: {tw_config.schedule}\n")
            if tw_config.schedule == 'warmup':
                f.write(f"  warmup_steps: {tw_config.warmup_steps}\n")
            elif tw_config.schedule == 'anneal':
                f.write(f"  anneal_final_strength: {tw_config.anneal_final_strength}\n")
            elif tw_config.schedule == 'cyclical':
                f.write(f"  cyclical_period: {tw_config.cyclical_period}\n")
            if tw_config.function == 'focal':
                f.write(f"  focal_gamma: {tw_config.focal_gamma}\n")
            if tw_config.percentile_clamp:
                f.write(f"  percentile_clamp: [{tw_config.percentile_low}, {tw_config.percentile_high}]\n")
            f.write('='*100 + '\n')
        else:
            f.write("Token Weighting: DISABLED (baseline run)\n")
            f.write('='*100 + '\n')
    
    # Also log token weighting config to console
    if tw_config.enabled:
        print(f"Token Weighting: ENABLED")
        print(f"  function={tw_config.function}, clamp=[{tw_config.clamp_min}, {tw_config.clamp_max}], schedule={tw_config.schedule}")
    else:
        print(f"Token Weighting: DISABLED (baseline run)")

# Track validation loss for adaptive schedule
current_val_loss = None

training_time_ms = 0
# start the clock
torch.cuda.synchronize()
t0 = time.time()
# begin training
train_loader.reset()
for step in range(args.num_iterations + 1):
    last_step = (step == args.num_iterations)
    # This effectively ignores timing first 10 steps, which are slower for weird reasons.
    # Alternately, and slightly more correctly in terms of benchmarking, we could do 10
    # steps with dummy data first, and then re-initialize the model and reset the loader.
    if step == 10:
        training_time_ms = 0
        t0 = time.time()
    timed_steps = float('nan') if step <= 11 else (step - 10) + 1 # <= 11 to avoid bug in val

    # once in a while evaluate the validation dataset
    if (last_step or (args.val_loss_every > 0 and step % args.val_loss_every == 0)):
        # stop the clock
        torch.cuda.synchronize()
        training_time_ms += 1000 * (time.time() - t0)
        # run validation batches
        model.eval()
        val_loader.reset()
        val_loss = 0.0
        for _ in range(val_steps):
            x_val, y_val = val_loader.next_batch()
            with ctx: # of course, we'd like to use no_grad() here too, but that creates a torch.compile error for some reason
                _, loss = model(x_val, y_val, return_logits=False)
                val_loss += loss.detach()
                del loss
        dist.all_reduce(val_loss, op=dist.ReduceOp.AVG)
        val_loss /= val_steps
        current_val_loss = val_loss.item()  # Store for adaptive schedule
        # log val loss to console and to logfile
        if master_process:
            print(f'step:{step}/{args.num_iterations} val_loss:{val_loss:.4f} train_time:{training_time_ms:.0f}ms step_avg:{training_time_ms/(timed_steps-1):.2f}ms')
            with open(logfile, "a") as f:
                f.write(f'step:{step}/{args.num_iterations} val_loss:{val_loss:.4f} train_time:{training_time_ms:.0f}ms step_avg:{training_time_ms/(timed_steps-1):.2f}ms\n')
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.time()

    if master_process and (last_step or (args.save_every > 0 and step % args.save_every == 0)):
        # stop the clock
        torch.cuda.synchronize()
        training_time_ms += 1000 * (time.time() - t0)
        # save the state of the training process
        log = dict(step=step, code=code, model=raw_model.state_dict(), optimizers=[opt.state_dict() for opt in optimizers])
        # also save the seed for reproducibility
        if args.seed is not None:
            log['seed'] = args.seed
        # save token weighting config
        if tw_config.enabled:
            log['tw_config'] = {
                'function': tw_config.function,
                'clamp_min': tw_config.clamp_min,
                'clamp_max': tw_config.clamp_max,
                'schedule': tw_config.schedule,
            }
        torch.save(log, 'logs/%s/state_step%06d.pt' % (run_id, step))
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.time()

    # bit confusing: we want to make sure to eval on 0th iteration
    # but also after the very last iteration. so we loop for step <= num_iterations
    # instead of just < num_iterations (one extra due to <=), only to do
    # the validation/sampling one last time, and then we break right here as we're done.
    if last_step:
        break

    # --------------- TRAINING SECTION BEGIN -----------------
    model.train()
    
    # Accumulate weight statistics across accumulation steps
    accumulated_weight_stats = {}
    
    for i in range(1, train_accumulation_steps+1):
        # forward pass
        with ctx:
            if tw_config.enabled:
                # Get per-token loss for token weighting
                _, per_token_loss = model(x, y, return_logits=False, return_per_token_loss=True)
                
                # Compute token importance weights
                weights, weight_stats = compute_token_weights(
                    per_token_loss,
                    tw_config,
                    step,
                    args.num_iterations,
                    current_val_loss
                )
                
                # Apply weights and compute mean loss
                weighted_loss = per_token_loss * weights
                loss = weighted_loss.mean()
                train_loss = per_token_loss.mean().detach()  # Log unweighted loss for fair comparison
                
                # Accumulate weight stats
                if weight_stats and (step % tw_config.log_every == 0):
                    for k, v in weight_stats.items():
                        if k not in accumulated_weight_stats:
                            accumulated_weight_stats[k] = []
                        accumulated_weight_stats[k].append(v)
            else:
                # Standard training without token weighting
                _, loss = model(x, y, return_logits=False)
                train_loss = loss.detach()
        
        # advance the dataset for the next batch
        x, y = train_loader.next_batch()
        # backward pass
        if i < train_accumulation_steps:
            with model.no_sync(): # there's no need to sync gradients every accumulation step
                loss.backward()
        else:
            loss.backward() # just sync on the last step
    for p in model.parameters():
        p.grad /= train_accumulation_steps
    # step the optimizers and schedulers
    for opt, sched in zip(optimizers, schedulers):
        opt.step()
        sched.step()
    # null the gradients
    model.zero_grad(set_to_none=True)
    # --------------- TRAINING SECTION END -------------------
    # everything that follows now is just diagnostics, prints, logging, etc.

    #dist.all_reduce(train_loss, op=dist.ReduceOp.AVG) # all-reducing the training loss would be more correct in terms of logging, but slower
    if master_process:
        approx_time = training_time_ms + 1000 * (time.time() - t0)
        
        # Build log message
        log_msg = f"step:{step+1}/{args.num_iterations} train_loss:{train_loss.item():.4f} train_time:{approx_time:.0f}ms step_avg:{approx_time/timed_steps:.2f}ms"
        
        # Add weight statistics if enabled and this is a logging step
        if tw_config.enabled and tw_config.log_weights and accumulated_weight_stats and (step % tw_config.log_every == 0):
            # Average the accumulated stats
            avg_weight_stats = {k: sum(v)/len(v) for k, v in accumulated_weight_stats.items()}
            weight_log = f" w_mean:{avg_weight_stats.get('weight_mean', 1.0):.3f} w_std:{avg_weight_stats.get('weight_std', 0.0):.3f} w_min:{avg_weight_stats.get('weight_min', 1.0):.3f} w_max:{avg_weight_stats.get('weight_max', 1.0):.3f}"
            log_msg += weight_log
        
        print(log_msg)
        with open(logfile, "a") as f:
            f.write(log_msg + "\n")

if master_process:
    print(f"peak memory consumption: {torch.cuda.max_memory_allocated() // 1024 // 1024} MiB")====================================================================================================
Running pytorch 2.8.0+cu128 compiled for CUDA 12.8
nvidia-smi:
Tue Dec  9 20:41:11 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.195.03             Driver Version: 570.195.03     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA H100 PCIe               On  |   00000000:00:08.0 Off |                    0 |
| N/A   45C    P0             83W /  310W |    2363MiB /  81559MiB |     15%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA H100 PCIe               On  |   00000000:00:09.0 Off |                    0 |
| N/A   44C    P0             84W /  310W |    2363MiB /  81559MiB |     21%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA H100 PCIe               On  |   00000000:00:0A.0 Off |                    0 |
| N/A   49C    P0             89W /  310W |    2363MiB /  81559MiB |     30%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA H100 PCIe               On  |   00000000:00:0B.0 Off |                    0 |
| N/A   45C    P0             86W /  310W |    2363MiB /  81559MiB |     31%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   4  NVIDIA H100 PCIe               On  |   00000000:00:0C.0 Off |                    0 |
| N/A   43C    P0             81W /  310W |    2363MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   5  NVIDIA H100 PCIe               On  |   00000000:00:0D.0 Off |                    0 |
| N/A   48C    P0             86W /  310W |    2363MiB /  81559MiB |     35%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   6  NVIDIA H100 PCIe               On  |   00000000:00:0E.0 Off |                    0 |
| N/A   53C    P0             89W /  310W |    2363MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   7  NVIDIA H100 PCIe               On  |   00000000:00:0F.0 Off |                    0 |
| N/A   45C    P0             84W /  310W |    2363MiB /  81559MiB |      3%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A           50315      C   /usr/local/bin/python                  2354MiB |
|    1   N/A  N/A           50316      C   /usr/local/bin/python                  2354MiB |
|    2   N/A  N/A           50317      C   /usr/local/bin/python                  2354MiB |
|    3   N/A  N/A           50318      C   /usr/local/bin/python                  2354MiB |
|    4   N/A  N/A           50319      C   /usr/local/bin/python                  2354MiB |
|    5   N/A  N/A           50320      C   /usr/local/bin/python                  2354MiB |
|    6   N/A  N/A           50321      C   /usr/local/bin/python                  2354MiB |
|    7   N/A  N/A           50322      C   /usr/local/bin/python                  2354MiB |
+-----------------------------------------------------------------------------------------+

====================================================================================================
Random seed: 789 (deterministic=False)
====================================================================================================
Token Weighting: DISABLED (baseline run)
====================================================================================================
step:0/3000 val_loss:15.9807 train_time:266ms step_avg:nanms
step:1/3000 train_loss:15.9709 train_time:48167ms step_avg:nanms
step:2/3000 train_loss:9.5154 train_time:48609ms step_avg:nanms
step:3/3000 train_loss:8.7528 train_time:48888ms step_avg:nanms
step:4/3000 train_loss:8.0438 train_time:49168ms step_avg:nanms
step:5/3000 train_loss:7.5935 train_time:49449ms step_avg:nanms
step:6/3000 train_loss:7.5911 train_time:49729ms step_avg:nanms
step:7/3000 train_loss:7.3357 train_time:50008ms step_avg:nanms
step:8/3000 train_loss:7.5029 train_time:50291ms step_avg:nanms
step:9/3000 train_loss:7.2482 train_time:50570ms step_avg:nanms
step:10/3000 train_loss:7.0393 train_time:50851ms step_avg:nanms
step:11/3000 train_loss:7.0679 train_time:281ms step_avg:nanms
step:12/3000 train_loss:6.8777 train_time:561ms step_avg:nanms
step:13/3000 train_loss:6.6897 train_time:841ms step_avg:280.40ms
step:14/3000 train_loss:6.6563 train_time:1122ms step_avg:280.59ms
step:15/3000 train_loss:6.6095 train_time:1404ms step_avg:280.72ms
step:16/3000 train_loss:6.5362 train_time:1685ms step_avg:280.86ms
step:17/3000 train_loss:6.5526 train_time:1966ms step_avg:280.90ms
step:18/3000 train_loss:6.5725 train_time:2247ms step_avg:280.82ms
step:19/3000 train_loss:6.4010 train_time:2531ms step_avg:281.21ms
step:20/3000 train_loss:6.4315 train_time:2813ms step_avg:281.35ms
step:21/3000 train_loss:6.0984 train_time:3099ms step_avg:281.73ms
step:22/3000 train_loss:6.4397 train_time:3382ms step_avg:281.79ms
step:23/3000 train_loss:6.6540 train_time:3662ms step_avg:281.73ms
step:24/3000 train_loss:6.3441 train_time:3945ms step_avg:281.75ms
step:25/3000 train_loss:6.4646 train_time:4230ms step_avg:282.02ms
step:26/3000 train_loss:6.1815 train_time:4513ms step_avg:282.08ms
step:27/3000 train_loss:6.0944 train_time:4799ms step_avg:282.32ms
step:28/3000 train_loss:6.2417 train_time:5083ms step_avg:282.38ms
step:29/3000 train_loss:5.9179 train_time:5365ms step_avg:282.37ms
step:30/3000 train_loss:6.2025 train_time:5647ms step_avg:282.36ms
step:31/3000 train_loss:6.0328 train_time:5933ms step_avg:282.54ms
step:32/3000 train_loss:6.0064 train_time:6217ms step_avg:282.59ms
step:33/3000 train_loss:5.8366 train_time:6502ms step_avg:282.70ms
step:34/3000 train_loss:6.1200 train_time:6783ms step_avg:282.63ms
step:35/3000 train_loss:6.0460 train_time:7065ms step_avg:282.61ms
step:36/3000 train_loss:6.2008 train_time:7351ms step_avg:282.75ms
step:37/3000 train_loss:6.1248 train_time:7637ms step_avg:282.85ms
step:38/3000 train_loss:6.0330 train_time:7921ms step_avg:282.90ms
step:39/3000 train_loss:5.9205 train_time:8205ms step_avg:282.93ms
step:40/3000 train_loss:5.9304 train_time:8490ms step_avg:283.00ms
step:41/3000 train_loss:5.8444 train_time:8775ms step_avg:283.07ms
step:42/3000 train_loss:5.8703 train_time:9060ms step_avg:283.13ms
step:43/3000 train_loss:5.7451 train_time:9343ms step_avg:283.12ms
step:44/3000 train_loss:5.8476 train_time:9628ms step_avg:283.19ms
step:45/3000 train_loss:5.8163 train_time:9913ms step_avg:283.23ms
step:46/3000 train_loss:5.9675 train_time:10200ms step_avg:283.32ms
step:47/3000 train_loss:5.7643 train_time:10486ms step_avg:283.40ms
step:48/3000 train_loss:5.6392 train_time:10768ms step_avg:283.37ms
step:49/3000 train_loss:5.8417 train_time:11053ms step_avg:283.41ms
step:50/3000 train_loss:5.7283 train_time:11341ms step_avg:283.52ms
step:51/3000 train_loss:5.8522 train_time:11624ms step_avg:283.52ms
step:52/3000 train_loss:5.7263 train_time:11907ms step_avg:283.50ms
step:53/3000 train_loss:5.5840 train_time:12194ms step_avg:283.59ms
step:54/3000 train_loss:5.7327 train_time:12482ms step_avg:283.67ms
step:55/3000 train_loss:5.6002 train_time:12765ms step_avg:283.66ms
step:56/3000 train_loss:5.9473 train_time:13049ms step_avg:283.67ms
step:57/3000 train_loss:5.6113 train_time:13335ms step_avg:283.73ms
step:58/3000 train_loss:5.4737 train_time:13624ms step_avg:283.84ms
step:59/3000 train_loss:5.6154 train_time:13905ms step_avg:283.78ms
step:60/3000 train_loss:5.5826 train_time:14191ms step_avg:283.82ms
step:61/3000 train_loss:5.6775 train_time:14478ms step_avg:283.88ms
step:62/3000 train_loss:5.4532 train_time:14762ms step_avg:283.89ms
step:63/3000 train_loss:5.5585 train_time:15048ms step_avg:283.93ms
step:64/3000 train_loss:5.5414 train_time:15334ms step_avg:283.96ms
step:65/3000 train_loss:5.2246 train_time:15619ms step_avg:283.98ms
step:66/3000 train_loss:5.3505 train_time:15904ms step_avg:283.99ms
step:67/3000 train_loss:5.5059 train_time:16187ms step_avg:283.99ms
step:68/3000 train_loss:5.3727 train_time:16474ms step_avg:284.03ms
step:69/3000 train_loss:5.6284 train_time:16759ms step_avg:284.06ms
step:70/3000 train_loss:5.2856 train_time:17044ms step_avg:284.07ms
step:71/3000 train_loss:5.3018 train_time:17327ms step_avg:284.05ms
step:72/3000 train_loss:5.5097 train_time:17613ms step_avg:284.08ms
step:73/3000 train_loss:5.4458 train_time:17901ms step_avg:284.14ms
step:74/3000 train_loss:5.3157 train_time:18185ms step_avg:284.14ms
step:75/3000 train_loss:5.4472 train_time:18471ms step_avg:284.16ms
step:76/3000 train_loss:5.4103 train_time:18757ms step_avg:284.20ms
step:77/3000 train_loss:5.3715 train_time:19042ms step_avg:284.21ms
step:78/3000 train_loss:5.4621 train_time:19327ms step_avg:284.22ms
step:79/3000 train_loss:5.5274 train_time:19613ms step_avg:284.25ms
step:80/3000 train_loss:5.3146 train_time:19901ms step_avg:284.31ms
step:81/3000 train_loss:5.4264 train_time:20186ms step_avg:284.31ms
step:82/3000 train_loss:5.1952 train_time:20472ms step_avg:284.33ms
step:83/3000 train_loss:5.3635 train_time:20757ms step_avg:284.34ms
step:84/3000 train_loss:5.3136 train_time:21043ms step_avg:284.37ms
step:85/3000 train_loss:5.3053 train_time:21327ms step_avg:284.36ms
step:86/3000 train_loss:5.1573 train_time:21613ms step_avg:284.39ms
step:87/3000 train_loss:5.3762 train_time:21901ms step_avg:284.43ms
step:88/3000 train_loss:5.2762 train_time:22185ms step_avg:284.43ms
step:89/3000 train_loss:5.3219 train_time:22471ms step_avg:284.44ms
step:90/3000 train_loss:5.2855 train_time:22758ms step_avg:284.47ms
step:91/3000 train_loss:5.2187 train_time:23043ms step_avg:284.49ms
step:92/3000 train_loss:5.1897 train_time:23330ms step_avg:284.51ms
step:93/3000 train_loss:5.3413 train_time:23615ms step_avg:284.52ms
step:94/3000 train_loss:5.1533 train_time:23902ms step_avg:284.55ms
step:95/3000 train_loss:5.1604 train_time:24187ms step_avg:284.55ms
step:96/3000 train_loss:5.1993 train_time:24475ms step_avg:284.59ms
step:97/3000 train_loss:5.1195 train_time:24762ms step_avg:284.62ms
step:98/3000 train_loss:5.1944 train_time:25046ms step_avg:284.61ms
step:99/3000 train_loss:5.1179 train_time:25333ms step_avg:284.64ms
step:100/3000 train_loss:5.2383 train_time:25621ms step_avg:284.67ms
step:101/3000 train_loss:5.2193 train_time:25905ms step_avg:284.67ms
step:102/3000 train_loss:5.1183 train_time:26192ms step_avg:284.70ms
step:103/3000 train_loss:5.2050 train_time:26479ms step_avg:284.72ms
step:104/3000 train_loss:5.1444 train_time:26764ms step_avg:284.73ms
step:105/3000 train_loss:5.0144 train_time:27048ms step_avg:284.71ms
step:106/3000 train_loss:5.1129 train_time:27337ms step_avg:284.76ms
step:107/3000 train_loss:5.3185 train_time:27623ms step_avg:284.78ms
step:108/3000 train_loss:5.0862 train_time:27907ms step_avg:284.76ms
step:109/3000 train_loss:4.8761 train_time:28193ms step_avg:284.78ms
step:110/3000 train_loss:5.0650 train_time:28482ms step_avg:284.82ms
step:111/3000 train_loss:5.0491 train_time:28767ms step_avg:284.82ms
step:112/3000 train_loss:5.0000 train_time:29053ms step_avg:284.83ms
step:113/3000 train_loss:5.1179 train_time:29341ms step_avg:284.87ms
step:114/3000 train_loss:5.0414 train_time:29627ms step_avg:284.87ms
step:115/3000 train_loss:4.8952 train_time:29914ms step_avg:284.89ms
step:116/3000 train_loss:5.0501 train_time:30202ms step_avg:284.93ms
step:117/3000 train_loss:4.9615 train_time:30488ms step_avg:284.93ms
step:118/3000 train_loss:4.9114 train_time:30774ms step_avg:284.95ms
step:119/3000 train_loss:5.0598 train_time:31061ms step_avg:284.96ms
step:120/3000 train_loss:5.0246 train_time:31346ms step_avg:284.96ms
step:121/3000 train_loss:4.9581 train_time:31633ms step_avg:284.98ms
step:122/3000 train_loss:4.8435 train_time:31919ms step_avg:284.99ms
step:123/3000 train_loss:4.9686 train_time:32205ms step_avg:285.00ms
step:124/3000 train_loss:4.8139 train_time:32492ms step_avg:285.02ms
step:125/3000 train_loss:5.1339 train_time:32781ms step_avg:285.05ms
step:125/3000 val_loss:4.9642 train_time:32781ms step_avg:285.05ms
step:126/3000 train_loss:5.0112 train_time:33072ms step_avg:285.10ms
step:127/3000 train_loss:4.9562 train_time:33359ms step_avg:285.12ms
step:128/3000 train_loss:5.0135 train_time:33647ms step_avg:285.15ms
step:129/3000 train_loss:4.8872 train_time:33934ms step_avg:285.16ms
step:130/3000 train_loss:5.1914 train_time:34220ms step_avg:285.17ms
step:131/3000 train_loss:4.9401 train_time:34505ms step_avg:285.17ms
step:132/3000 train_loss:4.9530 train_time:34790ms step_avg:285.16ms
step:133/3000 train_loss:4.9059 train_time:35080ms step_avg:285.21ms
step:134/3000 train_loss:4.9421 train_time:35365ms step_avg:285.20ms
step:135/3000 train_loss:4.8333 train_time:35649ms step_avg:285.19ms
step:136/3000 train_loss:4.9643 train_time:35939ms step_avg:285.23ms
step:137/3000 train_loss:4.7348 train_time:36225ms step_avg:285.24ms
step:138/3000 train_loss:4.8986 train_time:36510ms step_avg:285.23ms
step:139/3000 train_loss:4.8470 train_time:36797ms step_avg:285.25ms
step:140/3000 train_loss:4.8856 train_time:37085ms step_avg:285.27ms
step:141/3000 train_loss:4.9424 train_time:37369ms step_avg:285.26ms
step:142/3000 train_loss:4.8173 train_time:37655ms step_avg:285.27ms
step:143/3000 train_loss:4.8690 train_time:37944ms step_avg:285.29ms
step:144/3000 train_loss:4.7363 train_time:38231ms step_avg:285.30ms
step:145/3000 train_loss:4.8709 train_time:38516ms step_avg:285.31ms
step:146/3000 train_loss:4.8198 train_time:38805ms step_avg:285.33ms
step:147/3000 train_loss:4.6941 train_time:39090ms step_avg:285.33ms
step:148/3000 train_loss:4.8477 train_time:39377ms step_avg:285.34ms
step:149/3000 train_loss:4.8416 train_time:39664ms step_avg:285.35ms
step:150/3000 train_loss:4.8695 train_time:39949ms step_avg:285.35ms
step:151/3000 train_loss:4.9110 train_time:40237ms step_avg:285.37ms
step:152/3000 train_loss:4.7942 train_time:40524ms step_avg:285.38ms
step:153/3000 train_loss:4.7958 train_time:40809ms step_avg:285.38ms
step:154/3000 train_loss:4.8897 train_time:41097ms step_avg:285.39ms
step:155/3000 train_loss:4.8393 train_time:41384ms step_avg:285.41ms
step:156/3000 train_loss:4.8043 train_time:41669ms step_avg:285.40ms
step:157/3000 train_loss:4.8197 train_time:41954ms step_avg:285.40ms
step:158/3000 train_loss:4.9458 train_time:42245ms step_avg:285.44ms
step:159/3000 train_loss:4.7237 train_time:42531ms step_avg:285.44ms
step:160/3000 train_loss:4.7953 train_time:42816ms step_avg:285.44ms
step:161/3000 train_loss:4.6348 train_time:43104ms step_avg:285.46ms
step:162/3000 train_loss:4.8067 train_time:43389ms step_avg:285.45ms
step:163/3000 train_loss:4.8413 train_time:43675ms step_avg:285.46ms
step:164/3000 train_loss:4.8337 train_time:43962ms step_avg:285.47ms
step:165/3000 train_loss:4.6403 train_time:44247ms step_avg:285.46ms
step:166/3000 train_loss:4.7599 train_time:44533ms step_avg:285.47ms
step:167/3000 train_loss:4.8994 train_time:44820ms step_avg:285.48ms
step:168/3000 train_loss:4.6858 train_time:45107ms step_avg:285.49ms
step:169/3000 train_loss:4.7863 train_time:45394ms step_avg:285.50ms
step:170/3000 train_loss:4.6346 train_time:45681ms step_avg:285.50ms
step:171/3000 train_loss:4.5392 train_time:45967ms step_avg:285.51ms
step:172/3000 train_loss:4.6884 train_time:46253ms step_avg:285.51ms
step:173/3000 train_loss:4.6787 train_time:46541ms step_avg:285.53ms
step:174/3000 train_loss:4.7315 train_time:46827ms step_avg:285.53ms
step:175/3000 train_loss:4.8808 train_time:47110ms step_avg:285.51ms
step:176/3000 train_loss:4.7334 train_time:47399ms step_avg:285.54ms
step:177/3000 train_loss:4.5879 train_time:47686ms step_avg:285.54ms
step:178/3000 train_loss:4.5522 train_time:47971ms step_avg:285.54ms
step:179/3000 train_loss:4.6288 train_time:48255ms step_avg:285.53ms
step:180/3000 train_loss:4.6342 train_time:48546ms step_avg:285.56ms
step:181/3000 train_loss:4.6278 train_time:48831ms step_avg:285.56ms
step:182/3000 train_loss:4.7633 train_time:49117ms step_avg:285.56ms
step:183/3000 train_loss:4.6289 train_time:49407ms step_avg:285.59ms
step:184/3000 train_loss:4.5755 train_time:49693ms step_avg:285.59ms
step:185/3000 train_loss:4.5890 train_time:49979ms step_avg:285.60ms
step:186/3000 train_loss:4.7156 train_time:50265ms step_avg:285.60ms
step:187/3000 train_loss:4.6252 train_time:50551ms step_avg:285.60ms
step:188/3000 train_loss:4.8169 train_time:50839ms step_avg:285.61ms
step:189/3000 train_loss:4.6428 train_time:51311ms step_avg:286.65ms
step:190/3000 train_loss:4.5636 train_time:51794ms step_avg:287.75ms
step:191/3000 train_loss:4.6973 train_time:52079ms step_avg:287.73ms
step:192/3000 train_loss:4.5501 train_time:52362ms step_avg:287.70ms
step:193/3000 train_loss:4.4685 train_time:52647ms step_avg:287.69ms
step:194/3000 train_loss:4.7086 train_time:52935ms step_avg:287.69ms
step:195/3000 train_loss:4.6317 train_time:53221ms step_avg:287.68ms
step:196/3000 train_loss:4.8068 train_time:53507ms step_avg:287.67ms
step:197/3000 train_loss:4.6773 train_time:53791ms step_avg:287.65ms
step:198/3000 train_loss:4.5232 train_time:54076ms step_avg:287.64ms
step:199/3000 train_loss:4.5971 train_time:54362ms step_avg:287.63ms
step:200/3000 train_loss:4.4643 train_time:54648ms step_avg:287.62ms
step:201/3000 train_loss:4.5625 train_time:54936ms step_avg:287.62ms
step:202/3000 train_loss:4.4549 train_time:55222ms step_avg:287.61ms
step:203/3000 train_loss:4.7112 train_time:55508ms step_avg:287.60ms
step:204/3000 train_loss:4.5733 train_time:55794ms step_avg:287.60ms
step:205/3000 train_loss:4.5940 train_time:56080ms step_avg:287.59ms
step:206/3000 train_loss:4.7186 train_time:56365ms step_avg:287.58ms
step:207/3000 train_loss:4.3774 train_time:56651ms step_avg:287.57ms
step:208/3000 train_loss:4.5404 train_time:56940ms step_avg:287.57ms
step:209/3000 train_loss:4.5052 train_time:57226ms step_avg:287.57ms
step:210/3000 train_loss:4.6660 train_time:57510ms step_avg:287.55ms
step:211/3000 train_loss:4.5832 train_time:57796ms step_avg:287.54ms
step:212/3000 train_loss:4.4739 train_time:58083ms step_avg:287.54ms
step:213/3000 train_loss:4.5907 train_time:58369ms step_avg:287.53ms
step:214/3000 train_loss:4.4456 train_time:58655ms step_avg:287.52ms
step:215/3000 train_loss:4.5158 train_time:58943ms step_avg:287.53ms
step:216/3000 train_loss:4.3815 train_time:59228ms step_avg:287.51ms
step:217/3000 train_loss:4.4750 train_time:59511ms step_avg:287.49ms
step:218/3000 train_loss:4.4468 train_time:59798ms step_avg:287.49ms
step:219/3000 train_loss:4.4683 train_time:60085ms step_avg:287.49ms
step:220/3000 train_loss:4.4677 train_time:60370ms step_avg:287.48ms
step:221/3000 train_loss:4.5001 train_time:60655ms step_avg:287.47ms
step:222/3000 train_loss:4.5155 train_time:60944ms step_avg:287.47ms
step:223/3000 train_loss:4.4331 train_time:61229ms step_avg:287.46ms
step:224/3000 train_loss:4.4378 train_time:61512ms step_avg:287.44ms
step:225/3000 train_loss:4.6416 train_time:61800ms step_avg:287.44ms
step:226/3000 train_loss:4.3145 train_time:62087ms step_avg:287.44ms
step:227/3000 train_loss:4.3625 train_time:62370ms step_avg:287.42ms
step:228/3000 train_loss:4.3723 train_time:62656ms step_avg:287.42ms
step:229/3000 train_loss:4.5189 train_time:62946ms step_avg:287.42ms
step:230/3000 train_loss:4.3173 train_time:63231ms step_avg:287.41ms
step:231/3000 train_loss:4.4563 train_time:63517ms step_avg:287.41ms
step:232/3000 train_loss:4.3191 train_time:63805ms step_avg:287.41ms
step:233/3000 train_loss:4.3248 train_time:64090ms step_avg:287.40ms
step:234/3000 train_loss:4.4924 train_time:64376ms step_avg:287.39ms
step:235/3000 train_loss:4.3744 train_time:64663ms step_avg:287.39ms
step:236/3000 train_loss:4.2760 train_time:64949ms step_avg:287.39ms
step:237/3000 train_loss:4.4792 train_time:65235ms step_avg:287.38ms
step:238/3000 train_loss:4.4368 train_time:65520ms step_avg:287.37ms
step:239/3000 train_loss:4.3039 train_time:65807ms step_avg:287.37ms
step:240/3000 train_loss:4.4581 train_time:66092ms step_avg:287.35ms
step:241/3000 train_loss:4.4551 train_time:66379ms step_avg:287.35ms
step:242/3000 train_loss:4.3403 train_time:66663ms step_avg:287.34ms
step:243/3000 train_loss:4.5142 train_time:66948ms step_avg:287.33ms
step:244/3000 train_loss:4.3537 train_time:67234ms step_avg:287.33ms
step:245/3000 train_loss:4.3831 train_time:67519ms step_avg:287.31ms
step:246/3000 train_loss:4.4668 train_time:67806ms step_avg:287.31ms
step:247/3000 train_loss:4.4007 train_time:68093ms step_avg:287.31ms
step:248/3000 train_loss:4.3415 train_time:68379ms step_avg:287.31ms
step:249/3000 train_loss:4.4706 train_time:68664ms step_avg:287.30ms
step:250/3000 train_loss:4.2372 train_time:68949ms step_avg:287.29ms
step:250/3000 val_loss:4.3406 train_time:68950ms step_avg:287.29ms
step:251/3000 train_loss:4.2985 train_time:69239ms step_avg:287.30ms
step:252/3000 train_loss:4.4033 train_time:69529ms step_avg:287.31ms
step:253/3000 train_loss:4.4416 train_time:69815ms step_avg:287.31ms
step:254/3000 train_loss:4.2653 train_time:70100ms step_avg:287.30ms
step:255/3000 train_loss:4.2198 train_time:70387ms step_avg:287.29ms
step:256/3000 train_loss:4.3986 train_time:70674ms step_avg:287.29ms
step:257/3000 train_loss:4.3160 train_time:70957ms step_avg:287.28ms
step:258/3000 train_loss:4.3193 train_time:71240ms step_avg:287.26ms
step:259/3000 train_loss:4.2881 train_time:71528ms step_avg:287.26ms
step:260/3000 train_loss:4.3215 train_time:71815ms step_avg:287.26ms
step:261/3000 train_loss:4.3659 train_time:72099ms step_avg:287.25ms
step:262/3000 train_loss:4.3255 train_time:72384ms step_avg:287.24ms
step:263/3000 train_loss:4.2925 train_time:72672ms step_avg:287.24ms
step:264/3000 train_loss:4.2013 train_time:72958ms step_avg:287.23ms
step:265/3000 train_loss:4.2895 train_time:73241ms step_avg:287.22ms
step:266/3000 train_loss:4.1513 train_time:73529ms step_avg:287.22ms
step:267/3000 train_loss:4.2152 train_time:73817ms step_avg:287.23ms
step:268/3000 train_loss:4.2294 train_time:74100ms step_avg:287.21ms
step:269/3000 train_loss:4.2338 train_time:74386ms step_avg:287.20ms
step:270/3000 train_loss:4.1531 train_time:74672ms step_avg:287.20ms
step:271/3000 train_loss:4.3952 train_time:74958ms step_avg:287.20ms
step:272/3000 train_loss:4.2892 train_time:75244ms step_avg:287.19ms
step:273/3000 train_loss:4.1949 train_time:75533ms step_avg:287.20ms
step:274/3000 train_loss:4.2481 train_time:75817ms step_avg:287.18ms
step:275/3000 train_loss:4.3212 train_time:76101ms step_avg:287.17ms
step:276/3000 train_loss:4.3425 train_time:76387ms step_avg:287.17ms
step:277/3000 train_loss:4.5183 train_time:76673ms step_avg:287.17ms
step:278/3000 train_loss:4.3193 train_time:76959ms step_avg:287.16ms
step:279/3000 train_loss:4.3861 train_time:77242ms step_avg:287.14ms
step:280/3000 train_loss:4.2798 train_time:77530ms step_avg:287.15ms
step:281/3000 train_loss:4.3996 train_time:77816ms step_avg:287.15ms
step:282/3000 train_loss:4.2232 train_time:78101ms step_avg:287.14ms
step:283/3000 train_loss:4.2459 train_time:78388ms step_avg:287.13ms
step:284/3000 train_loss:4.1800 train_time:78674ms step_avg:287.13ms
step:285/3000 train_loss:4.3328 train_time:78958ms step_avg:287.12ms
step:286/3000 train_loss:4.3389 train_time:79243ms step_avg:287.11ms
step:287/3000 train_loss:4.3664 train_time:79533ms step_avg:287.12ms
step:288/3000 train_loss:4.1931 train_time:79820ms step_avg:287.12ms
step:289/3000 train_loss:4.2787 train_time:80102ms step_avg:287.11ms
step:290/3000 train_loss:4.1523 train_time:80390ms step_avg:287.11ms
step:291/3000 train_loss:4.1323 train_time:80677ms step_avg:287.11ms
step:292/3000 train_loss:4.2216 train_time:80962ms step_avg:287.10ms
step:293/3000 train_loss:4.1330 train_time:81247ms step_avg:287.09ms
step:294/3000 train_loss:4.1785 train_time:81535ms step_avg:287.10ms
step:295/3000 train_loss:4.2158 train_time:81821ms step_avg:287.09ms
step:296/3000 train_loss:4.0981 train_time:82105ms step_avg:287.08ms
step:297/3000 train_loss:4.1126 train_time:82393ms step_avg:287.08ms
step:298/3000 train_loss:4.1203 train_time:82679ms step_avg:287.08ms
step:299/3000 train_loss:4.2345 train_time:82966ms step_avg:287.08ms
step:300/3000 train_loss:4.0902 train_time:83251ms step_avg:287.07ms
step:301/3000 train_loss:4.2375 train_time:83537ms step_avg:287.07ms
step:302/3000 train_loss:4.2470 train_time:83822ms step_avg:287.06ms
step:303/3000 train_loss:4.1821 train_time:84108ms step_avg:287.06ms
step:304/3000 train_loss:4.2425 train_time:84395ms step_avg:287.06ms
step:305/3000 train_loss:4.2174 train_time:84680ms step_avg:287.05ms
step:306/3000 train_loss:4.7027 train_time:84965ms step_avg:287.04ms
step:307/3000 train_loss:4.1947 train_time:85251ms step_avg:287.04ms
step:308/3000 train_loss:4.1011 train_time:85539ms step_avg:287.04ms
step:309/3000 train_loss:4.2605 train_time:85825ms step_avg:287.04ms
step:310/3000 train_loss:4.1001 train_time:86110ms step_avg:287.03ms
step:311/3000 train_loss:4.3326 train_time:86396ms step_avg:287.03ms
step:312/3000 train_loss:4.1831 train_time:86680ms step_avg:287.02ms
step:313/3000 train_loss:4.1256 train_time:86967ms step_avg:287.02ms
step:314/3000 train_loss:4.2258 train_time:87253ms step_avg:287.02ms
step:315/3000 train_loss:4.3439 train_time:87539ms step_avg:287.01ms
step:316/3000 train_loss:4.2017 train_time:87824ms step_avg:287.01ms
step:317/3000 train_loss:4.0396 train_time:88109ms step_avg:287.00ms
step:318/3000 train_loss:4.1269 train_time:88399ms step_avg:287.01ms
step:319/3000 train_loss:4.1602 train_time:88683ms step_avg:287.00ms
step:320/3000 train_loss:4.1330 train_time:88969ms step_avg:287.00ms
step:321/3000 train_loss:4.2405 train_time:89255ms step_avg:286.99ms
step:322/3000 train_loss:4.1976 train_time:89540ms step_avg:286.99ms
step:323/3000 train_loss:4.1650 train_time:89827ms step_avg:286.99ms
step:324/3000 train_loss:4.2509 train_time:90112ms step_avg:286.98ms
step:325/3000 train_loss:4.2140 train_time:90399ms step_avg:286.98ms
step:326/3000 train_loss:4.2716 train_time:90684ms step_avg:286.97ms
step:327/3000 train_loss:4.1256 train_time:90968ms step_avg:286.97ms
step:328/3000 train_loss:4.6164 train_time:91253ms step_avg:286.96ms
step:329/3000 train_loss:4.3141 train_time:91539ms step_avg:286.96ms
step:330/3000 train_loss:4.0556 train_time:91823ms step_avg:286.95ms
step:331/3000 train_loss:3.9973 train_time:92109ms step_avg:286.94ms
step:332/3000 train_loss:4.2180 train_time:92397ms step_avg:286.95ms
step:333/3000 train_loss:4.1437 train_time:92681ms step_avg:286.94ms
step:334/3000 train_loss:4.1267 train_time:92967ms step_avg:286.94ms
step:335/3000 train_loss:4.0836 train_time:93254ms step_avg:286.94ms
step:336/3000 train_loss:4.2547 train_time:93539ms step_avg:286.93ms
step:337/3000 train_loss:4.1908 train_time:93824ms step_avg:286.92ms
step:338/3000 train_loss:4.6594 train_time:94110ms step_avg:286.92ms
step:339/3000 train_loss:4.1818 train_time:94397ms step_avg:286.92ms
step:340/3000 train_loss:4.1254 train_time:94681ms step_avg:286.91ms
step:341/3000 train_loss:4.1562 train_time:94967ms step_avg:286.91ms
step:342/3000 train_loss:4.0750 train_time:95253ms step_avg:286.91ms
step:343/3000 train_loss:4.0433 train_time:95540ms step_avg:286.91ms
step:344/3000 train_loss:4.1018 train_time:95826ms step_avg:286.90ms
step:345/3000 train_loss:4.2311 train_time:96111ms step_avg:286.90ms
step:346/3000 train_loss:4.0713 train_time:96398ms step_avg:286.90ms
step:347/3000 train_loss:4.0043 train_time:96682ms step_avg:286.89ms
step:348/3000 train_loss:4.0513 train_time:96970ms step_avg:286.89ms
step:349/3000 train_loss:4.0920 train_time:97258ms step_avg:286.90ms
step:350/3000 train_loss:4.0522 train_time:97542ms step_avg:286.89ms
step:351/3000 train_loss:3.7731 train_time:97828ms step_avg:286.89ms
step:352/3000 train_loss:4.0472 train_time:98113ms step_avg:286.88ms
step:353/3000 train_loss:4.3871 train_time:98399ms step_avg:286.88ms
step:354/3000 train_loss:3.8856 train_time:98684ms step_avg:286.87ms
step:355/3000 train_loss:4.1542 train_time:98971ms step_avg:286.87ms
step:356/3000 train_loss:4.0196 train_time:99256ms step_avg:286.87ms
step:357/3000 train_loss:4.1194 train_time:99540ms step_avg:286.86ms
step:358/3000 train_loss:4.0829 train_time:99829ms step_avg:286.86ms
step:359/3000 train_loss:4.0756 train_time:100113ms step_avg:286.86ms
step:360/3000 train_loss:4.1258 train_time:100399ms step_avg:286.85ms
step:361/3000 train_loss:3.6941 train_time:100682ms step_avg:286.84ms
step:362/3000 train_loss:4.2509 train_time:100970ms step_avg:286.85ms
step:363/3000 train_loss:4.1455 train_time:101258ms step_avg:286.85ms
step:364/3000 train_loss:4.0647 train_time:101542ms step_avg:286.84ms
step:365/3000 train_loss:3.9758 train_time:101828ms step_avg:286.84ms
step:366/3000 train_loss:4.1433 train_time:102118ms step_avg:286.85ms
step:367/3000 train_loss:4.1014 train_time:102400ms step_avg:286.83ms
step:368/3000 train_loss:4.0819 train_time:102686ms step_avg:286.83ms
step:369/3000 train_loss:4.0735 train_time:102972ms step_avg:286.83ms
step:370/3000 train_loss:3.9623 train_time:103257ms step_avg:286.83ms
step:371/3000 train_loss:4.1155 train_time:103543ms step_avg:286.82ms
step:372/3000 train_loss:3.9905 train_time:103831ms step_avg:286.83ms
step:373/3000 train_loss:3.9169 train_time:104117ms step_avg:286.82ms
step:374/3000 train_loss:4.1322 train_time:104401ms step_avg:286.81ms
step:375/3000 train_loss:4.0571 train_time:104687ms step_avg:286.81ms
step:375/3000 val_loss:4.0597 train_time:104687ms step_avg:286.81ms
step:376/3000 train_loss:4.0363 train_time:104976ms step_avg:286.82ms
step:377/3000 train_loss:4.0943 train_time:105266ms step_avg:286.83ms
step:378/3000 train_loss:4.0065 train_time:105736ms step_avg:287.33ms
step:379/3000 train_loss:4.0629 train_time:106020ms step_avg:287.32ms
step:380/3000 train_loss:4.1021 train_time:106492ms step_avg:287.82ms
step:381/3000 train_loss:4.1713 train_time:106775ms step_avg:287.80ms
step:382/3000 train_loss:4.0752 train_time:107057ms step_avg:287.79ms
step:383/3000 train_loss:4.0517 train_time:107339ms step_avg:287.77ms
step:384/3000 train_loss:4.0039 train_time:107629ms step_avg:287.78ms
step:385/3000 train_loss:4.0945 train_time:107913ms step_avg:287.77ms
step:386/3000 train_loss:4.0054 train_time:108198ms step_avg:287.76ms
step:387/3000 train_loss:4.1170 train_time:108480ms step_avg:287.74ms
step:388/3000 train_loss:4.3016 train_time:108767ms step_avg:287.74ms
step:389/3000 train_loss:4.0209 train_time:109052ms step_avg:287.74ms
step:390/3000 train_loss:4.0076 train_time:109336ms step_avg:287.73ms
step:391/3000 train_loss:4.1100 train_time:109620ms step_avg:287.72ms
step:392/3000 train_loss:4.0374 train_time:109906ms step_avg:287.71ms
step:393/3000 train_loss:4.1375 train_time:110193ms step_avg:287.71ms
step:394/3000 train_loss:3.9722 train_time:110476ms step_avg:287.70ms
step:395/3000 train_loss:4.1115 train_time:110759ms step_avg:287.69ms
step:396/3000 train_loss:3.8529 train_time:111047ms step_avg:287.69ms
step:397/3000 train_loss:4.0502 train_time:111335ms step_avg:287.69ms
step:398/3000 train_loss:4.1075 train_time:111620ms step_avg:287.68ms
step:399/3000 train_loss:4.1099 train_time:111904ms step_avg:287.67ms
step:400/3000 train_loss:4.0020 train_time:112192ms step_avg:287.67ms
step:401/3000 train_loss:4.0610 train_time:112476ms step_avg:287.66ms
step:402/3000 train_loss:4.1241 train_time:112760ms step_avg:287.65ms
step:403/3000 train_loss:4.0585 train_time:113046ms step_avg:287.65ms
step:404/3000 train_loss:4.1690 train_time:113334ms step_avg:287.65ms
step:405/3000 train_loss:3.9223 train_time:113618ms step_avg:287.64ms
step:406/3000 train_loss:4.0064 train_time:113901ms step_avg:287.63ms
step:407/3000 train_loss:4.3041 train_time:114188ms step_avg:287.63ms
step:408/3000 train_loss:4.0124 train_time:114475ms step_avg:287.63ms
step:409/3000 train_loss:4.0370 train_time:114759ms step_avg:287.62ms
step:410/3000 train_loss:4.0812 train_time:115043ms step_avg:287.61ms
step:411/3000 train_loss:3.9653 train_time:115331ms step_avg:287.61ms
step:412/3000 train_loss:3.9806 train_time:115617ms step_avg:287.60ms
step:413/3000 train_loss:4.4048 train_time:115900ms step_avg:287.59ms
step:414/3000 train_loss:3.8551 train_time:116185ms step_avg:287.59ms
step:415/3000 train_loss:4.2322 train_time:116472ms step_avg:287.58ms
step:416/3000 train_loss:3.9831 train_time:116755ms step_avg:287.57ms
step:417/3000 train_loss:3.9793 train_time:117040ms step_avg:287.57ms
step:418/3000 train_loss:4.1754 train_time:117328ms step_avg:287.57ms
step:419/3000 train_loss:3.9069 train_time:117614ms step_avg:287.57ms
step:420/3000 train_loss:4.0160 train_time:117898ms step_avg:287.56ms
step:421/3000 train_loss:3.9569 train_time:118184ms step_avg:287.55ms
step:422/3000 train_loss:3.8631 train_time:118471ms step_avg:287.55ms
step:423/3000 train_loss:3.9934 train_time:118755ms step_avg:287.54ms
step:424/3000 train_loss:4.0886 train_time:119040ms step_avg:287.54ms
step:425/3000 train_loss:3.8459 train_time:119328ms step_avg:287.54ms
step:426/3000 train_loss:4.0224 train_time:119614ms step_avg:287.53ms
step:427/3000 train_loss:3.9093 train_time:119900ms step_avg:287.53ms
step:428/3000 train_loss:4.1229 train_time:120186ms step_avg:287.53ms
step:429/3000 train_loss:4.0356 train_time:120472ms step_avg:287.52ms
step:430/3000 train_loss:3.9677 train_time:120756ms step_avg:287.51ms
step:431/3000 train_loss:3.9383 train_time:121040ms step_avg:287.51ms
step:432/3000 train_loss:3.8475 train_time:121328ms step_avg:287.51ms
step:433/3000 train_loss:3.9842 train_time:121613ms step_avg:287.50ms
step:434/3000 train_loss:4.0469 train_time:121899ms step_avg:287.50ms
step:435/3000 train_loss:3.9869 train_time:122184ms step_avg:287.49ms
step:436/3000 train_loss:4.0345 train_time:122470ms step_avg:287.49ms
step:437/3000 train_loss:4.0416 train_time:122756ms step_avg:287.48ms
step:438/3000 train_loss:3.9216 train_time:123040ms step_avg:287.48ms
step:439/3000 train_loss:3.9399 train_time:123327ms step_avg:287.48ms
step:440/3000 train_loss:3.9125 train_time:123612ms step_avg:287.47ms
step:441/3000 train_loss:4.0929 train_time:123896ms step_avg:287.46ms
step:442/3000 train_loss:3.9777 train_time:124180ms step_avg:287.45ms
step:443/3000 train_loss:3.9637 train_time:124466ms step_avg:287.45ms
step:444/3000 train_loss:3.8521 train_time:124752ms step_avg:287.45ms
step:445/3000 train_loss:4.1175 train_time:125037ms step_avg:287.44ms
step:446/3000 train_loss:4.0546 train_time:125322ms step_avg:287.44ms
step:447/3000 train_loss:4.0453 train_time:125607ms step_avg:287.43ms
step:448/3000 train_loss:3.9625 train_time:125895ms step_avg:287.43ms
step:449/3000 train_loss:4.0597 train_time:126179ms step_avg:287.42ms
step:450/3000 train_loss:3.8905 train_time:126464ms step_avg:287.42ms
step:451/3000 train_loss:3.9352 train_time:126751ms step_avg:287.42ms
step:452/3000 train_loss:3.8004 train_time:127037ms step_avg:287.41ms
step:453/3000 train_loss:3.9188 train_time:127321ms step_avg:287.41ms
step:454/3000 train_loss:3.8905 train_time:127608ms step_avg:287.41ms
step:455/3000 train_loss:3.8477 train_time:127895ms step_avg:287.41ms
step:456/3000 train_loss:4.0642 train_time:128179ms step_avg:287.40ms
step:457/3000 train_loss:3.9379 train_time:128464ms step_avg:287.39ms
step:458/3000 train_loss:4.0081 train_time:128751ms step_avg:287.39ms
step:459/3000 train_loss:4.0502 train_time:129038ms step_avg:287.39ms
step:460/3000 train_loss:3.8480 train_time:129324ms step_avg:287.39ms
step:461/3000 train_loss:4.0148 train_time:129608ms step_avg:287.38ms
step:462/3000 train_loss:3.9164 train_time:129897ms step_avg:287.38ms
step:463/3000 train_loss:3.9312 train_time:130180ms step_avg:287.37ms
step:464/3000 train_loss:3.9896 train_time:130467ms step_avg:287.37ms
step:465/3000 train_loss:3.9334 train_time:130753ms step_avg:287.37ms
step:466/3000 train_loss:3.9428 train_time:131038ms step_avg:287.36ms
step:467/3000 train_loss:4.0342 train_time:131323ms step_avg:287.36ms
step:468/3000 train_loss:4.0413 train_time:131610ms step_avg:287.36ms
step:469/3000 train_loss:4.0192 train_time:131896ms step_avg:287.36ms
step:470/3000 train_loss:3.9040 train_time:132180ms step_avg:287.35ms
step:471/3000 train_loss:3.9826 train_time:132467ms step_avg:287.35ms
step:472/3000 train_loss:4.0404 train_time:132752ms step_avg:287.34ms
step:473/3000 train_loss:3.9791 train_time:133037ms step_avg:287.34ms
step:474/3000 train_loss:3.9334 train_time:133322ms step_avg:287.33ms
step:475/3000 train_loss:3.7923 train_time:133608ms step_avg:287.33ms
step:476/3000 train_loss:4.2348 train_time:133896ms step_avg:287.33ms
step:477/3000 train_loss:3.9773 train_time:134180ms step_avg:287.32ms
step:478/3000 train_loss:3.7920 train_time:134465ms step_avg:287.32ms
step:479/3000 train_loss:4.0271 train_time:134751ms step_avg:287.32ms
step:480/3000 train_loss:3.9801 train_time:135037ms step_avg:287.31ms
step:481/3000 train_loss:4.1213 train_time:135323ms step_avg:287.31ms
step:482/3000 train_loss:3.9366 train_time:135607ms step_avg:287.30ms
step:483/3000 train_loss:3.7424 train_time:135894ms step_avg:287.30ms
step:484/3000 train_loss:4.0265 train_time:136178ms step_avg:287.30ms
step:485/3000 train_loss:3.8780 train_time:136466ms step_avg:287.30ms
step:486/3000 train_loss:3.8826 train_time:136750ms step_avg:287.29ms
step:487/3000 train_loss:3.8148 train_time:137037ms step_avg:287.29ms
step:488/3000 train_loss:3.8779 train_time:137322ms step_avg:287.28ms
step:489/3000 train_loss:4.0778 train_time:137607ms step_avg:287.28ms
step:490/3000 train_loss:3.9253 train_time:137894ms step_avg:287.28ms
step:491/3000 train_loss:3.8148 train_time:138178ms step_avg:287.27ms
step:492/3000 train_loss:3.8292 train_time:138463ms step_avg:287.27ms
step:493/3000 train_loss:3.9513 train_time:138748ms step_avg:287.26ms
step:494/3000 train_loss:3.7909 train_time:139037ms step_avg:287.27ms
step:495/3000 train_loss:3.9246 train_time:139322ms step_avg:287.26ms
step:496/3000 train_loss:3.8608 train_time:139608ms step_avg:287.26ms
step:497/3000 train_loss:3.7491 train_time:139895ms step_avg:287.26ms
step:498/3000 train_loss:3.9401 train_time:140180ms step_avg:287.25ms
step:499/3000 train_loss:4.0169 train_time:140467ms step_avg:287.25ms
step:500/3000 train_loss:4.0474 train_time:140752ms step_avg:287.25ms
step:500/3000 val_loss:3.9214 train_time:140752ms step_avg:287.25ms
step:501/3000 train_loss:3.9600 train_time:141041ms step_avg:287.25ms
step:502/3000 train_loss:4.0148 train_time:141330ms step_avg:287.26ms
step:503/3000 train_loss:3.9517 train_time:141617ms step_avg:287.26ms
step:504/3000 train_loss:3.9924 train_time:141902ms step_avg:287.25ms
step:505/3000 train_loss:3.9453 train_time:142187ms step_avg:287.25ms
step:506/3000 train_loss:4.0219 train_time:142474ms step_avg:287.25ms
step:507/3000 train_loss:3.8514 train_time:142758ms step_avg:287.24ms
step:508/3000 train_loss:3.9742 train_time:143042ms step_avg:287.23ms
step:509/3000 train_loss:4.0498 train_time:143330ms step_avg:287.23ms
step:510/3000 train_loss:3.9894 train_time:143616ms step_avg:287.23ms
step:511/3000 train_loss:3.7968 train_time:143901ms step_avg:287.23ms
step:512/3000 train_loss:3.9921 train_time:144186ms step_avg:287.22ms
step:513/3000 train_loss:3.9339 train_time:144473ms step_avg:287.22ms
step:514/3000 train_loss:3.9004 train_time:144760ms step_avg:287.22ms
step:515/3000 train_loss:3.9706 train_time:145044ms step_avg:287.22ms
step:516/3000 train_loss:3.9494 train_time:145330ms step_avg:287.21ms
step:517/3000 train_loss:4.2840 train_time:145616ms step_avg:287.21ms
step:518/3000 train_loss:3.8884 train_time:145900ms step_avg:287.20ms
step:519/3000 train_loss:3.9983 train_time:146185ms step_avg:287.20ms
step:520/3000 train_loss:3.8929 train_time:146471ms step_avg:287.20ms
step:521/3000 train_loss:3.9000 train_time:146757ms step_avg:287.20ms
step:522/3000 train_loss:3.8486 train_time:147042ms step_avg:287.19ms
step:523/3000 train_loss:3.8648 train_time:147329ms step_avg:287.19ms
step:524/3000 train_loss:4.4946 train_time:147615ms step_avg:287.19ms
step:525/3000 train_loss:3.9568 train_time:147900ms step_avg:287.18ms
step:526/3000 train_loss:3.8992 train_time:148187ms step_avg:287.18ms
step:527/3000 train_loss:3.9093 train_time:148474ms step_avg:287.18ms
step:528/3000 train_loss:3.8619 train_time:148759ms step_avg:287.18ms
step:529/3000 train_loss:3.8350 train_time:149044ms step_avg:287.17ms
step:530/3000 train_loss:4.0568 train_time:149330ms step_avg:287.17ms
step:531/3000 train_loss:3.8496 train_time:149617ms step_avg:287.17ms
step:532/3000 train_loss:4.1239 train_time:149901ms step_avg:287.17ms
step:533/3000 train_loss:3.9425 train_time:150186ms step_avg:287.16ms
step:534/3000 train_loss:3.8669 train_time:150473ms step_avg:287.16ms
step:535/3000 train_loss:3.8851 train_time:150758ms step_avg:287.16ms
step:536/3000 train_loss:3.8274 train_time:151041ms step_avg:287.15ms
step:537/3000 train_loss:3.9542 train_time:151328ms step_avg:287.15ms
step:538/3000 train_loss:3.9436 train_time:151614ms step_avg:287.15ms
step:539/3000 train_loss:3.8488 train_time:151900ms step_avg:287.15ms
step:540/3000 train_loss:4.3343 train_time:152185ms step_avg:287.14ms
step:541/3000 train_loss:3.8785 train_time:152470ms step_avg:287.14ms
step:542/3000 train_loss:3.9935 train_time:152757ms step_avg:287.14ms
step:543/3000 train_loss:3.8162 train_time:153043ms step_avg:287.13ms
step:544/3000 train_loss:3.7933 train_time:153329ms step_avg:287.13ms
step:545/3000 train_loss:3.8805 train_time:153614ms step_avg:287.13ms
step:546/3000 train_loss:3.8031 train_time:153900ms step_avg:287.13ms
step:547/3000 train_loss:3.8554 train_time:154184ms step_avg:287.12ms
step:548/3000 train_loss:3.8679 train_time:154471ms step_avg:287.12ms
step:549/3000 train_loss:3.8407 train_time:154758ms step_avg:287.12ms
step:550/3000 train_loss:3.9395 train_time:155042ms step_avg:287.11ms
step:551/3000 train_loss:3.8192 train_time:155329ms step_avg:287.11ms
step:552/3000 train_loss:3.8335 train_time:155616ms step_avg:287.11ms
step:553/3000 train_loss:4.1574 train_time:155901ms step_avg:287.11ms
step:554/3000 train_loss:3.9643 train_time:156185ms step_avg:287.11ms
step:555/3000 train_loss:3.9157 train_time:156472ms step_avg:287.11ms
step:556/3000 train_loss:3.8624 train_time:156758ms step_avg:287.10ms
step:557/3000 train_loss:3.8954 train_time:157042ms step_avg:287.10ms
step:558/3000 train_loss:3.5477 train_time:157330ms step_avg:287.10ms
step:559/3000 train_loss:3.8181 train_time:157617ms step_avg:287.10ms
step:560/3000 train_loss:3.8623 train_time:157902ms step_avg:287.09ms
step:561/3000 train_loss:3.9073 train_time:158188ms step_avg:287.09ms
step:562/3000 train_loss:3.8176 train_time:158475ms step_avg:287.09ms
step:563/3000 train_loss:3.7579 train_time:158759ms step_avg:287.09ms
step:564/3000 train_loss:3.9657 train_time:159044ms step_avg:287.08ms
step:565/3000 train_loss:3.7766 train_time:159332ms step_avg:287.09ms
step:566/3000 train_loss:3.8963 train_time:159618ms step_avg:287.08ms
step:567/3000 train_loss:3.8430 train_time:160093ms step_avg:287.42ms
step:568/3000 train_loss:3.7897 train_time:160379ms step_avg:287.42ms
step:569/3000 train_loss:3.8924 train_time:160662ms step_avg:287.41ms
step:570/3000 train_loss:3.8695 train_time:161133ms step_avg:287.74ms
step:571/3000 train_loss:3.8941 train_time:161416ms step_avg:287.73ms
step:572/3000 train_loss:3.9761 train_time:161700ms step_avg:287.72ms
step:573/3000 train_loss:3.9225 train_time:161983ms step_avg:287.71ms
step:574/3000 train_loss:3.9298 train_time:162269ms step_avg:287.71ms
step:575/3000 train_loss:3.9798 train_time:162555ms step_avg:287.71ms
step:576/3000 train_loss:3.9382 train_time:162840ms step_avg:287.70ms
step:577/3000 train_loss:3.9579 train_time:163123ms step_avg:287.69ms
step:578/3000 train_loss:3.8891 train_time:163409ms step_avg:287.69ms
step:579/3000 train_loss:3.8790 train_time:163698ms step_avg:287.69ms
step:580/3000 train_loss:3.8675 train_time:163982ms step_avg:287.69ms
step:581/3000 train_loss:3.8080 train_time:164267ms step_avg:287.68ms
step:582/3000 train_loss:3.8346 train_time:164553ms step_avg:287.68ms
step:583/3000 train_loss:4.0571 train_time:164839ms step_avg:287.68ms
step:584/3000 train_loss:3.8304 train_time:165124ms step_avg:287.67ms
step:585/3000 train_loss:3.7888 train_time:165407ms step_avg:287.66ms
step:586/3000 train_loss:3.9836 train_time:165694ms step_avg:287.66ms
step:587/3000 train_loss:3.7405 train_time:165980ms step_avg:287.66ms
step:588/3000 train_loss:3.8809 train_time:166263ms step_avg:287.65ms
step:589/3000 train_loss:3.8593 train_time:166551ms step_avg:287.65ms
step:590/3000 train_loss:4.2112 train_time:166839ms step_avg:287.65ms
step:591/3000 train_loss:3.9860 train_time:167123ms step_avg:287.65ms
step:592/3000 train_loss:3.7276 train_time:167407ms step_avg:287.64ms
step:593/3000 train_loss:3.7405 train_time:167694ms step_avg:287.64ms
step:594/3000 train_loss:3.7303 train_time:167980ms step_avg:287.64ms
step:595/3000 train_loss:3.7736 train_time:168263ms step_avg:287.63ms
step:596/3000 train_loss:4.1379 train_time:168549ms step_avg:287.63ms
step:597/3000 train_loss:3.8526 train_time:168838ms step_avg:287.63ms
step:598/3000 train_loss:3.7854 train_time:169122ms step_avg:287.62ms
step:599/3000 train_loss:3.8655 train_time:169407ms step_avg:287.62ms
step:600/3000 train_loss:3.6858 train_time:169694ms step_avg:287.62ms
step:601/3000 train_loss:3.8008 train_time:169980ms step_avg:287.61ms
step:602/3000 train_loss:3.8379 train_time:170263ms step_avg:287.61ms
step:603/3000 train_loss:3.8573 train_time:170550ms step_avg:287.60ms
step:604/3000 train_loss:3.9857 train_time:170839ms step_avg:287.61ms
step:605/3000 train_loss:3.8436 train_time:171125ms step_avg:287.61ms
step:606/3000 train_loss:3.8250 train_time:171410ms step_avg:287.60ms
step:607/3000 train_loss:3.7735 train_time:171699ms step_avg:287.60ms
step:608/3000 train_loss:4.0199 train_time:171983ms step_avg:287.60ms
step:609/3000 train_loss:3.8529 train_time:172272ms step_avg:287.60ms
step:610/3000 train_loss:3.8218 train_time:172555ms step_avg:287.59ms
step:611/3000 train_loss:3.9237 train_time:172840ms step_avg:287.59ms
step:612/3000 train_loss:3.8280 train_time:173125ms step_avg:287.58ms
step:613/3000 train_loss:3.8042 train_time:173410ms step_avg:287.58ms
step:614/3000 train_loss:3.9734 train_time:173697ms step_avg:287.58ms
step:615/3000 train_loss:3.9332 train_time:173983ms step_avg:287.58ms
step:616/3000 train_loss:3.8933 train_time:174267ms step_avg:287.57ms
step:617/3000 train_loss:3.8238 train_time:174553ms step_avg:287.57ms
step:618/3000 train_loss:3.7752 train_time:174840ms step_avg:287.57ms
step:619/3000 train_loss:3.8846 train_time:175124ms step_avg:287.56ms
step:620/3000 train_loss:3.7857 train_time:175410ms step_avg:287.56ms
step:621/3000 train_loss:3.7965 train_time:175697ms step_avg:287.56ms
step:622/3000 train_loss:4.1084 train_time:175983ms step_avg:287.55ms
step:623/3000 train_loss:3.7969 train_time:176269ms step_avg:287.55ms
step:624/3000 train_loss:3.8244 train_time:176555ms step_avg:287.55ms
step:625/3000 train_loss:3.9019 train_time:176841ms step_avg:287.55ms
step:625/3000 val_loss:3.8345 train_time:176841ms step_avg:287.55ms
step:626/3000 train_loss:3.9289 train_time:177129ms step_avg:287.55ms
step:627/3000 train_loss:3.9533 train_time:177420ms step_avg:287.55ms
step:628/3000 train_loss:3.9376 train_time:177707ms step_avg:287.55ms
step:629/3000 train_loss:3.9796 train_time:177990ms step_avg:287.55ms
step:630/3000 train_loss:3.7993 train_time:178276ms step_avg:287.54ms
step:631/3000 train_loss:3.9237 train_time:178562ms step_avg:287.54ms
step:632/3000 train_loss:3.9560 train_time:178847ms step_avg:287.54ms
step:633/3000 train_loss:3.8667 train_time:179132ms step_avg:287.53ms
step:634/3000 train_loss:3.7930 train_time:179418ms step_avg:287.53ms
step:635/3000 train_loss:3.8931 train_time:179706ms step_avg:287.53ms
step:636/3000 train_loss:4.1492 train_time:179991ms step_avg:287.53ms
step:637/3000 train_loss:3.7398 train_time:180277ms step_avg:287.52ms
step:638/3000 train_loss:3.5628 train_time:180561ms step_avg:287.52ms
step:639/3000 train_loss:3.7852 train_time:180847ms step_avg:287.51ms
step:640/3000 train_loss:3.8200 train_time:181133ms step_avg:287.51ms
step:641/3000 train_loss:3.7719 train_time:181418ms step_avg:287.51ms
step:642/3000 train_loss:3.7837 train_time:181706ms step_avg:287.51ms
step:643/3000 train_loss:3.8229 train_time:181990ms step_avg:287.50ms
step:644/3000 train_loss:3.8310 train_time:182275ms step_avg:287.50ms
step:645/3000 train_loss:3.7594 train_time:182559ms step_avg:287.50ms
step:646/3000 train_loss:3.9830 train_time:182847ms step_avg:287.49ms
step:647/3000 train_loss:3.8788 train_time:183133ms step_avg:287.49ms
step:648/3000 train_loss:3.8755 train_time:183418ms step_avg:287.49ms
step:649/3000 train_loss:3.9016 train_time:183705ms step_avg:287.49ms
step:650/3000 train_loss:3.9741 train_time:183989ms step_avg:287.48ms
step:651/3000 train_loss:3.8265 train_time:184277ms step_avg:287.48ms
step:652/3000 train_loss:3.9701 train_time:184561ms step_avg:287.48ms
step:653/3000 train_loss:3.7914 train_time:184847ms step_avg:287.48ms
step:654/3000 train_loss:3.8649 train_time:185131ms step_avg:287.47ms
step:655/3000 train_loss:3.6382 train_time:185416ms step_avg:287.47ms
step:656/3000 train_loss:3.7776 train_time:185703ms step_avg:287.47ms
step:657/3000 train_loss:3.7879 train_time:185987ms step_avg:287.46ms
step:658/3000 train_loss:3.7199 train_time:186270ms step_avg:287.45ms
step:659/3000 train_loss:3.8928 train_time:186556ms step_avg:287.45ms
step:660/3000 train_loss:3.7931 train_time:186843ms step_avg:287.45ms
step:661/3000 train_loss:3.8922 train_time:187128ms step_avg:287.45ms
step:662/3000 train_loss:3.9581 train_time:187412ms step_avg:287.44ms
step:663/3000 train_loss:3.8720 train_time:187699ms step_avg:287.44ms
step:664/3000 train_loss:3.7552 train_time:187986ms step_avg:287.44ms
step:665/3000 train_loss:3.8378 train_time:188270ms step_avg:287.44ms
step:666/3000 train_loss:3.7023 train_time:188556ms step_avg:287.43ms
step:667/3000 train_loss:3.9847 train_time:188844ms step_avg:287.43ms
step:668/3000 train_loss:3.8242 train_time:189128ms step_avg:287.43ms
step:669/3000 train_loss:3.8313 train_time:189411ms step_avg:287.42ms
step:670/3000 train_loss:3.6852 train_time:189697ms step_avg:287.42ms
step:671/3000 train_loss:3.8029 train_time:189985ms step_avg:287.42ms
step:672/3000 train_loss:3.7561 train_time:190269ms step_avg:287.41ms
step:673/3000 train_loss:3.7804 train_time:190552ms step_avg:287.41ms
step:674/3000 train_loss:4.0623 train_time:190841ms step_avg:287.41ms
step:675/3000 train_loss:3.8517 train_time:191128ms step_avg:287.41ms
step:676/3000 train_loss:3.9170 train_time:191411ms step_avg:287.40ms
step:677/3000 train_loss:3.6941 train_time:191698ms step_avg:287.40ms
step:678/3000 train_loss:3.8054 train_time:191985ms step_avg:287.40ms
step:679/3000 train_loss:3.7454 train_time:192269ms step_avg:287.40ms
step:680/3000 train_loss:3.8893 train_time:192552ms step_avg:287.39ms
step:681/3000 train_loss:3.7894 train_time:192841ms step_avg:287.39ms
step:682/3000 train_loss:3.8193 train_time:193127ms step_avg:287.39ms
step:683/3000 train_loss:3.8906 train_time:193411ms step_avg:287.39ms
step:684/3000 train_loss:3.9408 train_time:193696ms step_avg:287.38ms
step:685/3000 train_loss:3.8383 train_time:193983ms step_avg:287.38ms
step:686/3000 train_loss:3.9076 train_time:194266ms step_avg:287.38ms
step:687/3000 train_loss:3.8317 train_time:194550ms step_avg:287.37ms
step:688/3000 train_loss:3.8760 train_time:194839ms step_avg:287.37ms
step:689/3000 train_loss:3.5079 train_time:195125ms step_avg:287.37ms
step:690/3000 train_loss:3.6229 train_time:195409ms step_avg:287.37ms
step:691/3000 train_loss:3.7546 train_time:195695ms step_avg:287.36ms
step:692/3000 train_loss:3.6413 train_time:195982ms step_avg:287.36ms
step:693/3000 train_loss:3.8480 train_time:196267ms step_avg:287.36ms
step:694/3000 train_loss:3.8677 train_time:196552ms step_avg:287.36ms
step:695/3000 train_loss:3.7491 train_time:196841ms step_avg:287.36ms
step:696/3000 train_loss:3.7393 train_time:197128ms step_avg:287.36ms
step:697/3000 train_loss:4.0677 train_time:197411ms step_avg:287.35ms
step:698/3000 train_loss:3.8087 train_time:197698ms step_avg:287.35ms
step:699/3000 train_loss:3.8474 train_time:197985ms step_avg:287.35ms
step:700/3000 train_loss:4.0025 train_time:198268ms step_avg:287.34ms
step:701/3000 train_loss:3.7755 train_time:198553ms step_avg:287.34ms
step:702/3000 train_loss:3.7418 train_time:198841ms step_avg:287.34ms
step:703/3000 train_loss:3.7226 train_time:199127ms step_avg:287.34ms
step:704/3000 train_loss:3.6830 train_time:199412ms step_avg:287.34ms
step:705/3000 train_loss:3.7668 train_time:199699ms step_avg:287.34ms
step:706/3000 train_loss:3.7617 train_time:199989ms step_avg:287.34ms
step:707/3000 train_loss:3.7830 train_time:200270ms step_avg:287.33ms
step:708/3000 train_loss:3.8498 train_time:200556ms step_avg:287.33ms
step:709/3000 train_loss:3.7956 train_time:200844ms step_avg:287.33ms
step:710/3000 train_loss:3.7827 train_time:201128ms step_avg:287.33ms
step:711/3000 train_loss:3.7468 train_time:201412ms step_avg:287.32ms
step:712/3000 train_loss:3.7902 train_time:201701ms step_avg:287.32ms
step:713/3000 train_loss:3.8470 train_time:201987ms step_avg:287.32ms
step:714/3000 train_loss:3.8583 train_time:202270ms step_avg:287.32ms
step:715/3000 train_loss:3.7787 train_time:202555ms step_avg:287.31ms
step:716/3000 train_loss:3.7766 train_time:202844ms step_avg:287.31ms
step:717/3000 train_loss:3.7830 train_time:203128ms step_avg:287.31ms
step:718/3000 train_loss:3.9345 train_time:203411ms step_avg:287.30ms
step:719/3000 train_loss:3.7977 train_time:203700ms step_avg:287.31ms
step:720/3000 train_loss:3.8724 train_time:203988ms step_avg:287.31ms
step:721/3000 train_loss:4.0301 train_time:204275ms step_avg:287.31ms
step:722/3000 train_loss:3.6583 train_time:204559ms step_avg:287.30ms
step:723/3000 train_loss:3.9274 train_time:204847ms step_avg:287.30ms
step:724/3000 train_loss:3.9829 train_time:205132ms step_avg:287.30ms
step:725/3000 train_loss:3.7674 train_time:205416ms step_avg:287.30ms
step:726/3000 train_loss:3.8472 train_time:205703ms step_avg:287.29ms
step:727/3000 train_loss:3.7491 train_time:205987ms step_avg:287.29ms
step:728/3000 train_loss:3.7596 train_time:206271ms step_avg:287.29ms
step:729/3000 train_loss:3.9409 train_time:206560ms step_avg:287.29ms
step:730/3000 train_loss:3.8879 train_time:206847ms step_avg:287.29ms
step:731/3000 train_loss:3.8812 train_time:207133ms step_avg:287.29ms
step:732/3000 train_loss:3.7627 train_time:207417ms step_avg:287.28ms
step:733/3000 train_loss:3.7927 train_time:207705ms step_avg:287.28ms
step:734/3000 train_loss:4.0276 train_time:207990ms step_avg:287.28ms
step:735/3000 train_loss:3.7601 train_time:208275ms step_avg:287.28ms
step:736/3000 train_loss:3.8246 train_time:208560ms step_avg:287.27ms
step:737/3000 train_loss:3.9523 train_time:208847ms step_avg:287.27ms
step:738/3000 train_loss:3.8607 train_time:209131ms step_avg:287.27ms
step:739/3000 train_loss:3.8027 train_time:209418ms step_avg:287.27ms
step:740/3000 train_loss:3.7034 train_time:209704ms step_avg:287.27ms
step:741/3000 train_loss:4.3369 train_time:209988ms step_avg:287.26ms
step:742/3000 train_loss:3.6998 train_time:210271ms step_avg:287.26ms
step:743/3000 train_loss:3.7770 train_time:210560ms step_avg:287.26ms
step:744/3000 train_loss:3.7900 train_time:210847ms step_avg:287.26ms
step:745/3000 train_loss:3.8455 train_time:211133ms step_avg:287.26ms
step:746/3000 train_loss:3.8251 train_time:211417ms step_avg:287.25ms
step:747/3000 train_loss:3.7995 train_time:211705ms step_avg:287.25ms
step:748/3000 train_loss:3.8291 train_time:211989ms step_avg:287.25ms
step:749/3000 train_loss:3.7648 train_time:212275ms step_avg:287.25ms
step:750/3000 train_loss:3.7630 train_time:212561ms step_avg:287.24ms
step:750/3000 val_loss:3.7745 train_time:212562ms step_avg:287.25ms
step:751/3000 train_loss:3.8064 train_time:212850ms step_avg:287.25ms
step:752/3000 train_loss:3.7615 train_time:213139ms step_avg:287.25ms
step:753/3000 train_loss:3.7999 train_time:213426ms step_avg:287.25ms
step:754/3000 train_loss:3.8161 train_time:213709ms step_avg:287.24ms
step:755/3000 train_loss:3.7919 train_time:213995ms step_avg:287.24ms
step:756/3000 train_loss:3.8683 train_time:214467ms step_avg:287.49ms
step:757/3000 train_loss:3.6960 train_time:214749ms step_avg:287.48ms
step:758/3000 train_loss:3.9387 train_time:215033ms step_avg:287.48ms
step:759/3000 train_loss:3.8523 train_time:215322ms step_avg:287.48ms
step:760/3000 train_loss:3.7850 train_time:215785ms step_avg:287.71ms
step:761/3000 train_loss:3.8921 train_time:216066ms step_avg:287.70ms
step:762/3000 train_loss:3.5989 train_time:216349ms step_avg:287.70ms
step:763/3000 train_loss:3.7500 train_time:216634ms step_avg:287.69ms
step:764/3000 train_loss:3.8682 train_time:216920ms step_avg:287.69ms
step:765/3000 train_loss:3.5262 train_time:217207ms step_avg:287.69ms
step:766/3000 train_loss:3.9461 train_time:217490ms step_avg:287.68ms
step:767/3000 train_loss:3.7958 train_time:217775ms step_avg:287.68ms
step:768/3000 train_loss:3.7598 train_time:218060ms step_avg:287.68ms
step:769/3000 train_loss:3.7793 train_time:218346ms step_avg:287.68ms
step:770/3000 train_loss:3.7964 train_time:218630ms step_avg:287.67ms
step:771/3000 train_loss:3.8557 train_time:218915ms step_avg:287.67ms
step:772/3000 train_loss:4.0857 train_time:219202ms step_avg:287.67ms
step:773/3000 train_loss:3.6602 train_time:219487ms step_avg:287.66ms
step:774/3000 train_loss:3.8538 train_time:219770ms step_avg:287.66ms
step:775/3000 train_loss:3.8416 train_time:220054ms step_avg:287.65ms
step:776/3000 train_loss:3.8136 train_time:220342ms step_avg:287.65ms
step:777/3000 train_loss:3.6016 train_time:220628ms step_avg:287.65ms
step:778/3000 train_loss:3.6035 train_time:220910ms step_avg:287.64ms
step:779/3000 train_loss:3.6776 train_time:221197ms step_avg:287.64ms
step:780/3000 train_loss:3.7700 train_time:221482ms step_avg:287.64ms
step:781/3000 train_loss:3.7982 train_time:221766ms step_avg:287.63ms
step:782/3000 train_loss:3.8580 train_time:222050ms step_avg:287.63ms
step:783/3000 train_loss:3.7728 train_time:222339ms step_avg:287.63ms
step:784/3000 train_loss:3.7709 train_time:222626ms step_avg:287.63ms
step:785/3000 train_loss:3.7801 train_time:222910ms step_avg:287.63ms
step:786/3000 train_loss:3.7533 train_time:223194ms step_avg:287.62ms
step:787/3000 train_loss:3.6600 train_time:223482ms step_avg:287.62ms
step:788/3000 train_loss:3.9119 train_time:223768ms step_avg:287.62ms
step:789/3000 train_loss:3.6991 train_time:224051ms step_avg:287.61ms
step:790/3000 train_loss:3.7640 train_time:224338ms step_avg:287.61ms
step:791/3000 train_loss:3.8216 train_time:224623ms step_avg:287.61ms
step:792/3000 train_loss:3.9620 train_time:224907ms step_avg:287.61ms
step:793/3000 train_loss:3.9669 train_time:225191ms step_avg:287.60ms
step:794/3000 train_loss:3.6710 train_time:225479ms step_avg:287.60ms
step:795/3000 train_loss:3.8024 train_time:225766ms step_avg:287.60ms
step:796/3000 train_loss:3.8525 train_time:226050ms step_avg:287.60ms
step:797/3000 train_loss:3.9588 train_time:226337ms step_avg:287.59ms
step:798/3000 train_loss:3.7129 train_time:226623ms step_avg:287.59ms
step:799/3000 train_loss:3.8571 train_time:226909ms step_avg:287.59ms
step:800/3000 train_loss:3.7505 train_time:227193ms step_avg:287.59ms
step:801/3000 train_loss:3.7437 train_time:227481ms step_avg:287.59ms
step:802/3000 train_loss:3.8423 train_time:227767ms step_avg:287.58ms
step:803/3000 train_loss:3.6949 train_time:228050ms step_avg:287.58ms
step:804/3000 train_loss:3.7262 train_time:228339ms step_avg:287.58ms
step:805/3000 train_loss:3.8373 train_time:228625ms step_avg:287.58ms
step:806/3000 train_loss:3.7356 train_time:228910ms step_avg:287.58ms
step:807/3000 train_loss:3.7440 train_time:229196ms step_avg:287.57ms
step:808/3000 train_loss:3.8454 train_time:229482ms step_avg:287.57ms
step:809/3000 train_loss:3.7664 train_time:229766ms step_avg:287.57ms
step:810/3000 train_loss:3.6824 train_time:230050ms step_avg:287.56ms
step:811/3000 train_loss:3.7701 train_time:230338ms step_avg:287.56ms
step:812/3000 train_loss:3.8015 train_time:230626ms step_avg:287.56ms
step:813/3000 train_loss:3.7907 train_time:230910ms step_avg:287.56ms
step:814/3000 train_loss:3.8324 train_time:231197ms step_avg:287.56ms
step:815/3000 train_loss:3.7779 train_time:231483ms step_avg:287.56ms
step:816/3000 train_loss:3.7577 train_time:231768ms step_avg:287.55ms
step:817/3000 train_loss:3.8610 train_time:232053ms step_avg:287.55ms
step:818/3000 train_loss:3.9587 train_time:232340ms step_avg:287.55ms
step:819/3000 train_loss:3.7228 train_time:232626ms step_avg:287.55ms
step:820/3000 train_loss:3.9247 train_time:232910ms step_avg:287.54ms
step:821/3000 train_loss:3.7036 train_time:233197ms step_avg:287.54ms
step:822/3000 train_loss:3.7506 train_time:233484ms step_avg:287.54ms
step:823/3000 train_loss:3.8696 train_time:233768ms step_avg:287.54ms
step:824/3000 train_loss:3.7841 train_time:234052ms step_avg:287.53ms
step:825/3000 train_loss:3.7119 train_time:234342ms step_avg:287.54ms
step:826/3000 train_loss:3.8167 train_time:234627ms step_avg:287.53ms
step:827/3000 train_loss:3.7027 train_time:234911ms step_avg:287.53ms
step:828/3000 train_loss:3.9340 train_time:235199ms step_avg:287.53ms
step:829/3000 train_loss:3.8225 train_time:235486ms step_avg:287.53ms
step:830/3000 train_loss:3.8744 train_time:235771ms step_avg:287.53ms
step:831/3000 train_loss:3.7320 train_time:236056ms step_avg:287.52ms
step:832/3000 train_loss:3.7850 train_time:236344ms step_avg:287.52ms
step:833/3000 train_loss:3.7176 train_time:236628ms step_avg:287.52ms
step:834/3000 train_loss:3.8457 train_time:236912ms step_avg:287.51ms
step:835/3000 train_loss:3.6827 train_time:237198ms step_avg:287.51ms
step:836/3000 train_loss:3.6623 train_time:237485ms step_avg:287.51ms
step:837/3000 train_loss:3.9272 train_time:237769ms step_avg:287.51ms
step:838/3000 train_loss:3.6215 train_time:238055ms step_avg:287.51ms
step:839/3000 train_loss:3.7934 train_time:238343ms step_avg:287.51ms
step:840/3000 train_loss:3.6281 train_time:238627ms step_avg:287.50ms
step:841/3000 train_loss:3.6756 train_time:238911ms step_avg:287.50ms
step:842/3000 train_loss:3.7582 train_time:239197ms step_avg:287.50ms
step:843/3000 train_loss:3.7770 train_time:239483ms step_avg:287.50ms
step:844/3000 train_loss:3.7820 train_time:239768ms step_avg:287.49ms
step:845/3000 train_loss:3.6259 train_time:240052ms step_avg:287.49ms
step:846/3000 train_loss:3.8660 train_time:240340ms step_avg:287.49ms
step:847/3000 train_loss:3.7301 train_time:240626ms step_avg:287.49ms
step:848/3000 train_loss:3.6921 train_time:240911ms step_avg:287.48ms
step:849/3000 train_loss:3.8301 train_time:241198ms step_avg:287.48ms
step:850/3000 train_loss:3.6957 train_time:241484ms step_avg:287.48ms
step:851/3000 train_loss:3.6486 train_time:241768ms step_avg:287.48ms
step:852/3000 train_loss:3.9448 train_time:242054ms step_avg:287.47ms
step:853/3000 train_loss:3.6500 train_time:242340ms step_avg:287.47ms
step:854/3000 train_loss:3.7664 train_time:242626ms step_avg:287.47ms
step:855/3000 train_loss:3.8447 train_time:242911ms step_avg:287.47ms
step:856/3000 train_loss:3.7257 train_time:243197ms step_avg:287.47ms
step:857/3000 train_loss:3.7470 train_time:243483ms step_avg:287.47ms
step:858/3000 train_loss:3.7996 train_time:243767ms step_avg:287.46ms
step:859/3000 train_loss:3.6901 train_time:244050ms step_avg:287.46ms
step:860/3000 train_loss:3.7558 train_time:244337ms step_avg:287.46ms
step:861/3000 train_loss:3.7941 train_time:244624ms step_avg:287.46ms
step:862/3000 train_loss:3.8415 train_time:244908ms step_avg:287.45ms
step:863/3000 train_loss:3.7878 train_time:245194ms step_avg:287.45ms
step:864/3000 train_loss:3.7694 train_time:245482ms step_avg:287.45ms
step:865/3000 train_loss:3.5999 train_time:245768ms step_avg:287.45ms
step:866/3000 train_loss:3.7856 train_time:246052ms step_avg:287.44ms
step:867/3000 train_loss:4.0579 train_time:246339ms step_avg:287.44ms
step:868/3000 train_loss:3.6504 train_time:246625ms step_avg:287.44ms
step:869/3000 train_loss:3.8336 train_time:246909ms step_avg:287.44ms
step:870/3000 train_loss:3.8166 train_time:247196ms step_avg:287.44ms
step:871/3000 train_loss:3.6530 train_time:247483ms step_avg:287.44ms
step:872/3000 train_loss:3.6263 train_time:247768ms step_avg:287.43ms
step:873/3000 train_loss:3.8637 train_time:248053ms step_avg:287.43ms
step:874/3000 train_loss:3.6518 train_time:248341ms step_avg:287.43ms
step:875/3000 train_loss:3.3702 train_time:248626ms step_avg:287.43ms
step:875/3000 val_loss:3.7264 train_time:248627ms step_avg:287.43ms
step:876/3000 train_loss:3.8447 train_time:248915ms step_avg:287.43ms
step:877/3000 train_loss:3.6492 train_time:249203ms step_avg:287.43ms
step:878/3000 train_loss:3.8272 train_time:249490ms step_avg:287.43ms
step:879/3000 train_loss:3.6793 train_time:249778ms step_avg:287.43ms
step:880/3000 train_loss:3.8600 train_time:250060ms step_avg:287.43ms
step:881/3000 train_loss:3.5198 train_time:250345ms step_avg:287.42ms
step:882/3000 train_loss:3.7000 train_time:250633ms step_avg:287.42ms
step:883/3000 train_loss:3.8896 train_time:250920ms step_avg:287.42ms
step:884/3000 train_loss:4.0424 train_time:251204ms step_avg:287.42ms
step:885/3000 train_loss:3.7722 train_time:251490ms step_avg:287.42ms
step:886/3000 train_loss:3.6844 train_time:251777ms step_avg:287.42ms
step:887/3000 train_loss:3.7789 train_time:252059ms step_avg:287.41ms
step:888/3000 train_loss:4.2884 train_time:252344ms step_avg:287.41ms
step:889/3000 train_loss:4.0486 train_time:252632ms step_avg:287.41ms
step:890/3000 train_loss:3.7210 train_time:252918ms step_avg:287.41ms
step:891/3000 train_loss:3.7376 train_time:253202ms step_avg:287.40ms
step:892/3000 train_loss:3.5647 train_time:253488ms step_avg:287.40ms
step:893/3000 train_loss:3.9012 train_time:253774ms step_avg:287.40ms
step:894/3000 train_loss:3.6316 train_time:254058ms step_avg:287.40ms
step:895/3000 train_loss:3.8832 train_time:254342ms step_avg:287.39ms
step:896/3000 train_loss:3.8939 train_time:254629ms step_avg:287.39ms
step:897/3000 train_loss:3.6921 train_time:254915ms step_avg:287.39ms
step:898/3000 train_loss:3.7337 train_time:255200ms step_avg:287.39ms
step:899/3000 train_loss:3.7891 train_time:255486ms step_avg:287.39ms
step:900/3000 train_loss:3.6763 train_time:255772ms step_avg:287.38ms
step:901/3000 train_loss:3.6219 train_time:256057ms step_avg:287.38ms
step:902/3000 train_loss:3.8300 train_time:256343ms step_avg:287.38ms
step:903/3000 train_loss:3.8326 train_time:256630ms step_avg:287.38ms
step:904/3000 train_loss:3.7324 train_time:256916ms step_avg:287.38ms
step:905/3000 train_loss:3.7014 train_time:257201ms step_avg:287.38ms
step:906/3000 train_loss:3.6979 train_time:257486ms step_avg:287.37ms
step:907/3000 train_loss:3.9284 train_time:257773ms step_avg:287.37ms
step:908/3000 train_loss:3.7056 train_time:258058ms step_avg:287.37ms
step:909/3000 train_loss:3.7549 train_time:258343ms step_avg:287.37ms
step:910/3000 train_loss:3.6598 train_time:258630ms step_avg:287.37ms
step:911/3000 train_loss:3.7493 train_time:258916ms step_avg:287.37ms
step:912/3000 train_loss:3.8193 train_time:259200ms step_avg:287.36ms
step:913/3000 train_loss:3.8071 train_time:259485ms step_avg:287.36ms
step:914/3000 train_loss:3.6858 train_time:259773ms step_avg:287.36ms
step:915/3000 train_loss:3.9360 train_time:260061ms step_avg:287.36ms
step:916/3000 train_loss:3.7334 train_time:260345ms step_avg:287.36ms
step:917/3000 train_loss:3.8317 train_time:260631ms step_avg:287.35ms
step:918/3000 train_loss:3.7937 train_time:260917ms step_avg:287.35ms
step:919/3000 train_loss:5.0237 train_time:261201ms step_avg:287.35ms
step:920/3000 train_loss:3.7239 train_time:261487ms step_avg:287.35ms
step:921/3000 train_loss:3.7694 train_time:261774ms step_avg:287.35ms
step:922/3000 train_loss:3.7343 train_time:262059ms step_avg:287.35ms
step:923/3000 train_loss:3.7844 train_time:262343ms step_avg:287.34ms
step:924/3000 train_loss:3.7930 train_time:262631ms step_avg:287.34ms
step:925/3000 train_loss:3.8793 train_time:262918ms step_avg:287.34ms
step:926/3000 train_loss:3.8597 train_time:263201ms step_avg:287.34ms
step:927/3000 train_loss:3.7514 train_time:263487ms step_avg:287.34ms
step:928/3000 train_loss:3.7390 train_time:263775ms step_avg:287.34ms
step:929/3000 train_loss:3.9722 train_time:264058ms step_avg:287.33ms
step:930/3000 train_loss:3.8135 train_time:264342ms step_avg:287.33ms
step:931/3000 train_loss:3.5999 train_time:264631ms step_avg:287.33ms
step:932/3000 train_loss:3.6908 train_time:264917ms step_avg:287.33ms
step:933/3000 train_loss:3.8753 train_time:265203ms step_avg:287.33ms
step:934/3000 train_loss:3.5960 train_time:265491ms step_avg:287.33ms
step:935/3000 train_loss:3.7762 train_time:265777ms step_avg:287.33ms
step:936/3000 train_loss:3.6568 train_time:266061ms step_avg:287.32ms
step:937/3000 train_loss:3.7103 train_time:266346ms step_avg:287.32ms
step:938/3000 train_loss:3.8075 train_time:266633ms step_avg:287.32ms
step:939/3000 train_loss:3.7364 train_time:266921ms step_avg:287.32ms
step:940/3000 train_loss:3.8966 train_time:267203ms step_avg:287.32ms
step:941/3000 train_loss:3.6848 train_time:267490ms step_avg:287.31ms
step:942/3000 train_loss:3.7498 train_time:267777ms step_avg:287.31ms
step:943/3000 train_loss:3.5483 train_time:268061ms step_avg:287.31ms
step:944/3000 train_loss:3.8975 train_time:268343ms step_avg:287.31ms
step:945/3000 train_loss:3.6082 train_time:268818ms step_avg:287.51ms
step:946/3000 train_loss:3.6223 train_time:269101ms step_avg:287.50ms
step:947/3000 train_loss:5.2463 train_time:269389ms step_avg:287.50ms
step:948/3000 train_loss:3.7919 train_time:269676ms step_avg:287.50ms
step:949/3000 train_loss:3.6942 train_time:269959ms step_avg:287.50ms
step:950/3000 train_loss:3.5943 train_time:270429ms step_avg:287.69ms
step:951/3000 train_loss:3.6460 train_time:270712ms step_avg:287.69ms
step:952/3000 train_loss:3.6049 train_time:270998ms step_avg:287.68ms
step:953/3000 train_loss:3.6734 train_time:271282ms step_avg:287.68ms
step:954/3000 train_loss:3.7567 train_time:271567ms step_avg:287.68ms
step:955/3000 train_loss:3.6337 train_time:271852ms step_avg:287.67ms
step:956/3000 train_loss:3.6716 train_time:272138ms step_avg:287.67ms
step:957/3000 train_loss:3.6357 train_time:272423ms step_avg:287.67ms
step:958/3000 train_loss:3.7069 train_time:272709ms step_avg:287.67ms
step:959/3000 train_loss:3.6910 train_time:272998ms step_avg:287.67ms
step:960/3000 train_loss:3.7044 train_time:273281ms step_avg:287.66ms
step:961/3000 train_loss:3.5893 train_time:273565ms step_avg:287.66ms
step:962/3000 train_loss:3.8522 train_time:273852ms step_avg:287.66ms
step:963/3000 train_loss:3.8066 train_time:274139ms step_avg:287.66ms
step:964/3000 train_loss:3.7320 train_time:274424ms step_avg:287.66ms
step:965/3000 train_loss:3.6507 train_time:274710ms step_avg:287.65ms
step:966/3000 train_loss:3.6817 train_time:274996ms step_avg:287.65ms
step:967/3000 train_loss:3.9078 train_time:275280ms step_avg:287.65ms
step:968/3000 train_loss:3.7307 train_time:275566ms step_avg:287.65ms
step:969/3000 train_loss:3.7164 train_time:275850ms step_avg:287.64ms
step:970/3000 train_loss:3.7743 train_time:276137ms step_avg:287.64ms
step:971/3000 train_loss:3.5834 train_time:276421ms step_avg:287.64ms
step:972/3000 train_loss:3.7455 train_time:276704ms step_avg:287.63ms
step:973/3000 train_loss:3.6860 train_time:276991ms step_avg:287.63ms
step:974/3000 train_loss:3.7412 train_time:277279ms step_avg:287.63ms
step:975/3000 train_loss:3.8145 train_time:277562ms step_avg:287.63ms
step:976/3000 train_loss:3.6924 train_time:277845ms step_avg:287.62ms
step:977/3000 train_loss:3.8846 train_time:278133ms step_avg:287.62ms
step:978/3000 train_loss:3.7651 train_time:278418ms step_avg:287.62ms
step:979/3000 train_loss:3.5972 train_time:278702ms step_avg:287.62ms
step:980/3000 train_loss:3.8930 train_time:278989ms step_avg:287.62ms
step:981/3000 train_loss:3.6151 train_time:279276ms step_avg:287.62ms
step:982/3000 train_loss:3.7830 train_time:279560ms step_avg:287.61ms
step:983/3000 train_loss:3.7658 train_time:279843ms step_avg:287.61ms
step:984/3000 train_loss:3.7709 train_time:280134ms step_avg:287.61ms
step:985/3000 train_loss:3.7083 train_time:280417ms step_avg:287.61ms
step:986/3000 train_loss:3.8010 train_time:280701ms step_avg:287.60ms
step:987/3000 train_loss:3.6158 train_time:280986ms step_avg:287.60ms
step:988/3000 train_loss:3.6903 train_time:281273ms step_avg:287.60ms
step:989/3000 train_loss:3.7237 train_time:281559ms step_avg:287.60ms
step:990/3000 train_loss:3.6300 train_time:281841ms step_avg:287.59ms
step:991/3000 train_loss:3.8420 train_time:282128ms step_avg:287.59ms
step:992/3000 train_loss:3.6717 train_time:282415ms step_avg:287.59ms
step:993/3000 train_loss:3.6414 train_time:282700ms step_avg:287.59ms
step:994/3000 train_loss:3.7119 train_time:282984ms step_avg:287.59ms
step:995/3000 train_loss:3.7944 train_time:283271ms step_avg:287.59ms
step:996/3000 train_loss:3.7430 train_time:283558ms step_avg:287.58ms
step:997/3000 train_loss:3.6560 train_time:283842ms step_avg:287.58ms
step:998/3000 train_loss:4.0069 train_time:284129ms step_avg:287.58ms
step:999/3000 train_loss:3.6659 train_time:284415ms step_avg:287.58ms
step:1000/3000 train_loss:3.7925 train_time:284701ms step_avg:287.58ms
step:1000/3000 val_loss:3.6842 train_time:284702ms step_avg:287.58ms
step:1001/3000 train_loss:3.6574 train_time:284989ms step_avg:287.58ms
step:1002/3000 train_loss:3.7116 train_time:285279ms step_avg:287.58ms
step:1003/3000 train_loss:3.5931 train_time:285565ms step_avg:287.58ms
step:1004/3000 train_loss:3.7810 train_time:285848ms step_avg:287.57ms
step:1005/3000 train_loss:3.8279 train_time:286134ms step_avg:287.57ms
step:1006/3000 train_loss:3.5995 train_time:286421ms step_avg:287.57ms
step:1007/3000 train_loss:3.6810 train_time:286707ms step_avg:287.57ms
step:1008/3000 train_loss:3.6468 train_time:286991ms step_avg:287.57ms
step:1009/3000 train_loss:3.7702 train_time:287277ms step_avg:287.56ms
step:1010/3000 train_loss:3.8747 train_time:287565ms step_avg:287.57ms
step:1011/3000 train_loss:3.7744 train_time:287849ms step_avg:287.56ms
step:1012/3000 train_loss:3.7285 train_time:288136ms step_avg:287.56ms
step:1013/3000 train_loss:3.5950 train_time:288421ms step_avg:287.56ms
step:1014/3000 train_loss:3.7368 train_time:288706ms step_avg:287.56ms
step:1015/3000 train_loss:3.8490 train_time:288990ms step_avg:287.55ms
step:1016/3000 train_loss:3.5590 train_time:289276ms step_avg:287.55ms
step:1017/3000 train_loss:3.6456 train_time:289561ms step_avg:287.55ms
step:1018/3000 train_loss:3.6464 train_time:289847ms step_avg:287.55ms
step:1019/3000 train_loss:3.5942 train_time:290132ms step_avg:287.54ms
step:1020/3000 train_loss:3.7316 train_time:290419ms step_avg:287.54ms
step:1021/3000 train_loss:3.6453 train_time:290706ms step_avg:287.54ms
step:1022/3000 train_loss:3.5814 train_time:290990ms step_avg:287.54ms
step:1023/3000 train_loss:3.6866 train_time:291275ms step_avg:287.54ms
step:1024/3000 train_loss:3.7158 train_time:291561ms step_avg:287.54ms
step:1025/3000 train_loss:3.6912 train_time:291848ms step_avg:287.53ms
step:1026/3000 train_loss:3.7035 train_time:292133ms step_avg:287.53ms
step:1027/3000 train_loss:3.8690 train_time:292418ms step_avg:287.53ms
step:1028/3000 train_loss:3.5476 train_time:292705ms step_avg:287.53ms
step:1029/3000 train_loss:3.6024 train_time:292989ms step_avg:287.53ms
step:1030/3000 train_loss:3.5656 train_time:293274ms step_avg:287.52ms
step:1031/3000 train_loss:3.7280 train_time:293562ms step_avg:287.52ms
step:1032/3000 train_loss:3.7180 train_time:293847ms step_avg:287.52ms
step:1033/3000 train_loss:3.8990 train_time:294131ms step_avg:287.52ms
step:1034/3000 train_loss:3.7084 train_time:294418ms step_avg:287.52ms
step:1035/3000 train_loss:3.6286 train_time:294705ms step_avg:287.52ms
step:1036/3000 train_loss:3.6427 train_time:294989ms step_avg:287.51ms
step:1037/3000 train_loss:3.7115 train_time:295275ms step_avg:287.51ms
step:1038/3000 train_loss:4.0174 train_time:295561ms step_avg:287.51ms
step:1039/3000 train_loss:3.8389 train_time:295848ms step_avg:287.51ms
step:1040/3000 train_loss:3.7368 train_time:296131ms step_avg:287.51ms
step:1041/3000 train_loss:3.6329 train_time:296415ms step_avg:287.50ms
step:1042/3000 train_loss:3.7058 train_time:296703ms step_avg:287.50ms
step:1043/3000 train_loss:3.7393 train_time:296987ms step_avg:287.50ms
step:1044/3000 train_loss:3.6647 train_time:297273ms step_avg:287.50ms
step:1045/3000 train_loss:3.6772 train_time:297559ms step_avg:287.50ms
step:1046/3000 train_loss:3.7516 train_time:297848ms step_avg:287.50ms
step:1047/3000 train_loss:3.6545 train_time:298134ms step_avg:287.50ms
step:1048/3000 train_loss:3.8653 train_time:298418ms step_avg:287.49ms
step:1049/3000 train_loss:3.7187 train_time:298707ms step_avg:287.49ms
step:1050/3000 train_loss:3.6401 train_time:298991ms step_avg:287.49ms
step:1051/3000 train_loss:3.6059 train_time:299275ms step_avg:287.49ms
step:1052/3000 train_loss:3.7351 train_time:299562ms step_avg:287.49ms
step:1053/3000 train_loss:3.6037 train_time:299848ms step_avg:287.49ms
step:1054/3000 train_loss:3.9239 train_time:300134ms step_avg:287.48ms
step:1055/3000 train_loss:3.7640 train_time:300419ms step_avg:287.48ms
step:1056/3000 train_loss:3.6156 train_time:300706ms step_avg:287.48ms
step:1057/3000 train_loss:3.7211 train_time:300990ms step_avg:287.48ms
step:1058/3000 train_loss:3.7934 train_time:301276ms step_avg:287.48ms
step:1059/3000 train_loss:3.5222 train_time:301561ms step_avg:287.48ms
step:1060/3000 train_loss:3.6434 train_time:301847ms step_avg:287.47ms
step:1061/3000 train_loss:3.6700 train_time:302132ms step_avg:287.47ms
step:1062/3000 train_loss:3.6379 train_time:302418ms step_avg:287.47ms
step:1063/3000 train_loss:3.6128 train_time:302706ms step_avg:287.47ms
step:1064/3000 train_loss:3.7123 train_time:302989ms step_avg:287.47ms
step:1065/3000 train_loss:3.6125 train_time:303275ms step_avg:287.46ms
step:1066/3000 train_loss:3.5918 train_time:303562ms step_avg:287.46ms
step:1067/3000 train_loss:3.6228 train_time:303849ms step_avg:287.46ms
step:1068/3000 train_loss:3.5355 train_time:304134ms step_avg:287.46ms
step:1069/3000 train_loss:3.6484 train_time:304419ms step_avg:287.46ms
step:1070/3000 train_loss:3.5167 train_time:304706ms step_avg:287.46ms
step:1071/3000 train_loss:3.7794 train_time:304990ms step_avg:287.46ms
step:1072/3000 train_loss:3.7272 train_time:305278ms step_avg:287.46ms
step:1073/3000 train_loss:3.6778 train_time:305562ms step_avg:287.45ms
step:1074/3000 train_loss:3.7406 train_time:305847ms step_avg:287.45ms
step:1075/3000 train_loss:3.6891 train_time:306132ms step_avg:287.45ms
step:1076/3000 train_loss:3.6233 train_time:306416ms step_avg:287.44ms
step:1077/3000 train_loss:4.0166 train_time:306704ms step_avg:287.44ms
step:1078/3000 train_loss:3.6953 train_time:306988ms step_avg:287.44ms
step:1079/3000 train_loss:3.3665 train_time:307271ms step_avg:287.44ms
step:1080/3000 train_loss:3.7551 train_time:307557ms step_avg:287.44ms
step:1081/3000 train_loss:3.6761 train_time:307844ms step_avg:287.44ms
step:1082/3000 train_loss:3.7385 train_time:308128ms step_avg:287.43ms
step:1083/3000 train_loss:3.8369 train_time:308414ms step_avg:287.43ms
step:1084/3000 train_loss:3.7292 train_time:308700ms step_avg:287.43ms
step:1085/3000 train_loss:3.7031 train_time:308987ms step_avg:287.43ms
step:1086/3000 train_loss:3.6728 train_time:309270ms step_avg:287.43ms
step:1087/3000 train_loss:3.8629 train_time:309556ms step_avg:287.42ms
step:1088/3000 train_loss:3.7608 train_time:309844ms step_avg:287.42ms
step:1089/3000 train_loss:3.5868 train_time:310130ms step_avg:287.42ms
step:1090/3000 train_loss:3.6126 train_time:310413ms step_avg:287.42ms
step:1091/3000 train_loss:3.7264 train_time:310699ms step_avg:287.42ms
step:1092/3000 train_loss:3.5264 train_time:310986ms step_avg:287.42ms
step:1093/3000 train_loss:3.7236 train_time:311269ms step_avg:287.41ms
step:1094/3000 train_loss:3.8570 train_time:311555ms step_avg:287.41ms
step:1095/3000 train_loss:3.6969 train_time:311842ms step_avg:287.41ms
step:1096/3000 train_loss:3.6487 train_time:312128ms step_avg:287.41ms
step:1097/3000 train_loss:3.6680 train_time:312411ms step_avg:287.41ms
step:1098/3000 train_loss:3.7143 train_time:312699ms step_avg:287.41ms
step:1099/3000 train_loss:3.7866 train_time:312986ms step_avg:287.41ms
step:1100/3000 train_loss:3.7389 train_time:313270ms step_avg:287.40ms
step:1101/3000 train_loss:3.6779 train_time:313555ms step_avg:287.40ms
step:1102/3000 train_loss:3.5314 train_time:313844ms step_avg:287.40ms
step:1103/3000 train_loss:3.6020 train_time:314129ms step_avg:287.40ms
step:1104/3000 train_loss:3.6811 train_time:314412ms step_avg:287.40ms
step:1105/3000 train_loss:3.5573 train_time:314700ms step_avg:287.40ms
step:1106/3000 train_loss:4.3094 train_time:314987ms step_avg:287.40ms
step:1107/3000 train_loss:3.4619 train_time:315270ms step_avg:287.39ms
step:1108/3000 train_loss:3.8040 train_time:315556ms step_avg:287.39ms
step:1109/3000 train_loss:3.5914 train_time:315844ms step_avg:287.39ms
step:1110/3000 train_loss:3.7331 train_time:316130ms step_avg:287.39ms
step:1111/3000 train_loss:3.6704 train_time:316412ms step_avg:287.39ms
step:1112/3000 train_loss:3.7065 train_time:316699ms step_avg:287.39ms
step:1113/3000 train_loss:3.8025 train_time:316986ms step_avg:287.39ms
step:1114/3000 train_loss:3.6626 train_time:317269ms step_avg:287.38ms
step:1115/3000 train_loss:3.6000 train_time:317553ms step_avg:287.38ms
step:1116/3000 train_loss:3.5091 train_time:317841ms step_avg:287.38ms
step:1117/3000 train_loss:3.6716 train_time:318126ms step_avg:287.38ms
step:1118/3000 train_loss:3.8199 train_time:318410ms step_avg:287.37ms
step:1119/3000 train_loss:3.8666 train_time:318697ms step_avg:287.37ms
step:1120/3000 train_loss:3.6978 train_time:318984ms step_avg:287.37ms
step:1121/3000 train_loss:3.7299 train_time:319267ms step_avg:287.37ms
step:1122/3000 train_loss:3.6261 train_time:319552ms step_avg:287.37ms
step:1123/3000 train_loss:3.6906 train_time:319840ms step_avg:287.37ms
step:1124/3000 train_loss:3.8308 train_time:320126ms step_avg:287.37ms
step:1125/3000 train_loss:3.5917 train_time:320411ms step_avg:287.36ms
step:1125/3000 val_loss:3.6568 train_time:320411ms step_avg:287.36ms
step:1126/3000 train_loss:3.4962 train_time:320700ms step_avg:287.37ms
step:1127/3000 train_loss:3.7152 train_time:320987ms step_avg:287.37ms
step:1128/3000 train_loss:3.9340 train_time:321274ms step_avg:287.37ms
step:1129/3000 train_loss:3.4771 train_time:321558ms step_avg:287.36ms
step:1130/3000 train_loss:3.7907 train_time:321843ms step_avg:287.36ms
step:1131/3000 train_loss:3.6323 train_time:322129ms step_avg:287.36ms
step:1132/3000 train_loss:3.6497 train_time:322415ms step_avg:287.36ms
step:1133/3000 train_loss:3.6102 train_time:322703ms step_avg:287.36ms
step:1134/3000 train_loss:3.7682 train_time:323171ms step_avg:287.52ms
step:1135/3000 train_loss:3.7043 train_time:323454ms step_avg:287.51ms
step:1136/3000 train_loss:3.7570 train_time:323741ms step_avg:287.51ms
step:1137/3000 train_loss:3.7821 train_time:324026ms step_avg:287.51ms
step:1138/3000 train_loss:3.7035 train_time:324308ms step_avg:287.51ms
step:1139/3000 train_loss:3.5922 train_time:324594ms step_avg:287.51ms
step:1140/3000 train_loss:3.9087 train_time:325063ms step_avg:287.67ms
step:1141/3000 train_loss:3.7090 train_time:325346ms step_avg:287.66ms
step:1142/3000 train_loss:3.8157 train_time:325629ms step_avg:287.66ms
step:1143/3000 train_loss:3.6939 train_time:325913ms step_avg:287.65ms
step:1144/3000 train_loss:3.6077 train_time:326199ms step_avg:287.65ms
step:1145/3000 train_loss:3.7069 train_time:326484ms step_avg:287.65ms
step:1146/3000 train_loss:3.8416 train_time:326768ms step_avg:287.65ms
step:1147/3000 train_loss:3.8036 train_time:327053ms step_avg:287.65ms
step:1148/3000 train_loss:3.7176 train_time:327340ms step_avg:287.64ms
step:1149/3000 train_loss:3.7455 train_time:327625ms step_avg:287.64ms
step:1150/3000 train_loss:3.5927 train_time:327907ms step_avg:287.64ms
step:1151/3000 train_loss:3.6084 train_time:328194ms step_avg:287.64ms
step:1152/3000 train_loss:3.5776 train_time:328482ms step_avg:287.64ms
step:1153/3000 train_loss:3.7287 train_time:328764ms step_avg:287.63ms
step:1154/3000 train_loss:3.6931 train_time:329046ms step_avg:287.63ms
step:1155/3000 train_loss:3.7572 train_time:329334ms step_avg:287.63ms
step:1156/3000 train_loss:3.6094 train_time:329621ms step_avg:287.63ms
step:1157/3000 train_loss:3.7774 train_time:329909ms step_avg:287.63ms
step:1158/3000 train_loss:3.7357 train_time:330190ms step_avg:287.62ms
step:1159/3000 train_loss:3.5543 train_time:330477ms step_avg:287.62ms
step:1160/3000 train_loss:3.5847 train_time:330763ms step_avg:287.62ms
step:1161/3000 train_loss:3.5737 train_time:331047ms step_avg:287.62ms
step:1162/3000 train_loss:3.3898 train_time:331334ms step_avg:287.62ms
step:1163/3000 train_loss:3.6874 train_time:331619ms step_avg:287.61ms
step:1164/3000 train_loss:3.6481 train_time:331904ms step_avg:287.61ms
step:1165/3000 train_loss:3.5219 train_time:332188ms step_avg:287.61ms
step:1166/3000 train_loss:3.5154 train_time:332475ms step_avg:287.61ms
step:1167/3000 train_loss:3.6202 train_time:332761ms step_avg:287.61ms
step:1168/3000 train_loss:3.6294 train_time:333046ms step_avg:287.60ms
step:1169/3000 train_loss:3.9515 train_time:333330ms step_avg:287.60ms
step:1170/3000 train_loss:3.6356 train_time:333616ms step_avg:287.60ms
step:1171/3000 train_loss:3.6455 train_time:333903ms step_avg:287.60ms
step:1172/3000 train_loss:3.5627 train_time:334187ms step_avg:287.60ms
step:1173/3000 train_loss:3.6479 train_time:334473ms step_avg:287.60ms
step:1174/3000 train_loss:3.7888 train_time:334760ms step_avg:287.59ms
step:1175/3000 train_loss:3.6279 train_time:335044ms step_avg:287.59ms
step:1176/3000 train_loss:3.6502 train_time:335329ms step_avg:287.59ms
step:1177/3000 train_loss:3.6978 train_time:335614ms step_avg:287.59ms
step:1178/3000 train_loss:3.6819 train_time:335902ms step_avg:287.59ms
step:1179/3000 train_loss:3.7375 train_time:336188ms step_avg:287.59ms
step:1180/3000 train_loss:3.6528 train_time:336471ms step_avg:287.58ms
step:1181/3000 train_loss:3.6492 train_time:336756ms step_avg:287.58ms
step:1182/3000 train_loss:3.5996 train_time:337044ms step_avg:287.58ms
step:1183/3000 train_loss:3.6461 train_time:337328ms step_avg:287.58ms
step:1184/3000 train_loss:3.5808 train_time:337613ms step_avg:287.57ms
step:1185/3000 train_loss:3.7474 train_time:337900ms step_avg:287.57ms
step:1186/3000 train_loss:3.8069 train_time:338184ms step_avg:287.57ms
step:1187/3000 train_loss:3.6026 train_time:338468ms step_avg:287.57ms
step:1188/3000 train_loss:3.6621 train_time:338753ms step_avg:287.57ms
step:1189/3000 train_loss:3.6864 train_time:339042ms step_avg:287.57ms
step:1190/3000 train_loss:3.5204 train_time:339329ms step_avg:287.57ms
step:1191/3000 train_loss:3.6986 train_time:339615ms step_avg:287.57ms
step:1192/3000 train_loss:3.8429 train_time:339902ms step_avg:287.57ms
step:1193/3000 train_loss:3.6420 train_time:340186ms step_avg:287.56ms
step:1194/3000 train_loss:3.5287 train_time:340469ms step_avg:287.56ms
step:1195/3000 train_loss:3.8227 train_time:340755ms step_avg:287.56ms
step:1196/3000 train_loss:3.6297 train_time:341042ms step_avg:287.56ms
step:1197/3000 train_loss:3.6311 train_time:341328ms step_avg:287.56ms
step:1198/3000 train_loss:3.5256 train_time:341612ms step_avg:287.55ms
step:1199/3000 train_loss:3.5442 train_time:341900ms step_avg:287.55ms
step:1200/3000 train_loss:3.5932 train_time:342184ms step_avg:287.55ms
step:1201/3000 train_loss:3.6806 train_time:342467ms step_avg:287.55ms
step:1202/3000 train_loss:3.7471 train_time:342753ms step_avg:287.54ms
step:1203/3000 train_loss:3.8563 train_time:343042ms step_avg:287.55ms
step:1204/3000 train_loss:3.6699 train_time:343326ms step_avg:287.54ms
step:1205/3000 train_loss:3.5839 train_time:343609ms step_avg:287.54ms
step:1206/3000 train_loss:3.6715 train_time:343895ms step_avg:287.54ms
step:1207/3000 train_loss:3.7172 train_time:344183ms step_avg:287.54ms
step:1208/3000 train_loss:3.7703 train_time:344465ms step_avg:287.53ms
step:1209/3000 train_loss:3.6566 train_time:344750ms step_avg:287.53ms
step:1210/3000 train_loss:3.5104 train_time:345038ms step_avg:287.53ms
step:1211/3000 train_loss:3.5576 train_time:345324ms step_avg:287.53ms
step:1212/3000 train_loss:3.6544 train_time:345608ms step_avg:287.53ms
step:1213/3000 train_loss:3.6688 train_time:345894ms step_avg:287.53ms
step:1214/3000 train_loss:3.6999 train_time:346182ms step_avg:287.53ms
step:1215/3000 train_loss:3.5897 train_time:346468ms step_avg:287.53ms
step:1216/3000 train_loss:3.6552 train_time:346750ms step_avg:287.52ms
step:1217/3000 train_loss:3.5930 train_time:347038ms step_avg:287.52ms
step:1218/3000 train_loss:3.5927 train_time:347324ms step_avg:287.52ms
step:1219/3000 train_loss:3.6885 train_time:347609ms step_avg:287.52ms
step:1220/3000 train_loss:3.5282 train_time:347896ms step_avg:287.52ms
step:1221/3000 train_loss:3.7450 train_time:348183ms step_avg:287.52ms
step:1222/3000 train_loss:3.7763 train_time:348467ms step_avg:287.51ms
step:1223/3000 train_loss:3.7089 train_time:348752ms step_avg:287.51ms
step:1224/3000 train_loss:3.5524 train_time:349040ms step_avg:287.51ms
step:1225/3000 train_loss:3.5523 train_time:349324ms step_avg:287.51ms
step:1226/3000 train_loss:3.6244 train_time:349607ms step_avg:287.51ms
step:1227/3000 train_loss:3.6095 train_time:349894ms step_avg:287.51ms
step:1228/3000 train_loss:3.5372 train_time:350182ms step_avg:287.51ms
step:1229/3000 train_loss:3.7175 train_time:350465ms step_avg:287.50ms
step:1230/3000 train_loss:3.6341 train_time:350748ms step_avg:287.50ms
step:1231/3000 train_loss:3.6952 train_time:351038ms step_avg:287.50ms
step:1232/3000 train_loss:3.8488 train_time:351324ms step_avg:287.50ms
step:1233/3000 train_loss:3.7493 train_time:351608ms step_avg:287.50ms
step:1234/3000 train_loss:3.6900 train_time:351894ms step_avg:287.50ms
step:1235/3000 train_loss:3.8417 train_time:352181ms step_avg:287.49ms
step:1236/3000 train_loss:3.5976 train_time:352466ms step_avg:287.49ms
step:1237/3000 train_loss:3.5630 train_time:352749ms step_avg:287.49ms
step:1238/3000 train_loss:3.5167 train_time:353037ms step_avg:287.49ms
step:1239/3000 train_loss:3.5915 train_time:353323ms step_avg:287.49ms
step:1240/3000 train_loss:3.5978 train_time:353607ms step_avg:287.49ms
step:1241/3000 train_loss:3.6456 train_time:353893ms step_avg:287.48ms
step:1242/3000 train_loss:3.6906 train_time:354178ms step_avg:287.48ms
step:1243/3000 train_loss:3.5669 train_time:354464ms step_avg:287.48ms
step:1244/3000 train_loss:3.6601 train_time:354748ms step_avg:287.48ms
step:1245/3000 train_loss:3.6809 train_time:355035ms step_avg:287.48ms
step:1246/3000 train_loss:3.6808 train_time:355320ms step_avg:287.48ms
step:1247/3000 train_loss:3.5047 train_time:355605ms step_avg:287.47ms
step:1248/3000 train_loss:3.6458 train_time:355889ms step_avg:287.47ms
step:1249/3000 train_loss:3.7131 train_time:356176ms step_avg:287.47ms
step:1250/3000 train_loss:3.6735 train_time:356461ms step_avg:287.47ms
step:1250/3000 val_loss:3.6276 train_time:356462ms step_avg:287.47ms
step:1251/3000 train_loss:3.5764 train_time:356751ms step_avg:287.47ms
step:1252/3000 train_loss:3.7829 train_time:357042ms step_avg:287.47ms
step:1253/3000 train_loss:3.6461 train_time:357328ms step_avg:287.47ms
step:1254/3000 train_loss:3.5789 train_time:357612ms step_avg:287.47ms
step:1255/3000 train_loss:3.7127 train_time:357898ms step_avg:287.47ms
step:1256/3000 train_loss:3.7729 train_time:358184ms step_avg:287.47ms
step:1257/3000 train_loss:3.5833 train_time:358468ms step_avg:287.46ms
step:1258/3000 train_loss:3.6069 train_time:358750ms step_avg:287.46ms
step:1259/3000 train_loss:3.6399 train_time:359039ms step_avg:287.46ms
step:1260/3000 train_loss:3.6133 train_time:359327ms step_avg:287.46ms
step:1261/3000 train_loss:3.4633 train_time:359612ms step_avg:287.46ms
step:1262/3000 train_loss:3.5727 train_time:359897ms step_avg:287.46ms
step:1263/3000 train_loss:3.6428 train_time:360184ms step_avg:287.46ms
step:1264/3000 train_loss:3.4842 train_time:360467ms step_avg:287.45ms
step:1265/3000 train_loss:3.7092 train_time:360750ms step_avg:287.45ms
step:1266/3000 train_loss:3.6909 train_time:361038ms step_avg:287.45ms
step:1267/3000 train_loss:3.6963 train_time:361324ms step_avg:287.45ms
step:1268/3000 train_loss:3.6385 train_time:361610ms step_avg:287.45ms
step:1269/3000 train_loss:3.6731 train_time:361895ms step_avg:287.45ms
step:1270/3000 train_loss:3.5280 train_time:362182ms step_avg:287.45ms
step:1271/3000 train_loss:3.3747 train_time:362467ms step_avg:287.44ms
step:1272/3000 train_loss:3.6583 train_time:362753ms step_avg:287.44ms
step:1273/3000 train_loss:3.6249 train_time:363040ms step_avg:287.44ms
step:1274/3000 train_loss:3.6849 train_time:363326ms step_avg:287.44ms
step:1275/3000 train_loss:3.6227 train_time:363610ms step_avg:287.44ms
step:1276/3000 train_loss:3.7122 train_time:363897ms step_avg:287.44ms
step:1277/3000 train_loss:3.7392 train_time:364183ms step_avg:287.44ms
step:1278/3000 train_loss:3.6955 train_time:364467ms step_avg:287.43ms
step:1279/3000 train_loss:3.6849 train_time:364750ms step_avg:287.43ms
step:1280/3000 train_loss:3.5184 train_time:365038ms step_avg:287.43ms
step:1281/3000 train_loss:3.6437 train_time:365325ms step_avg:287.43ms
step:1282/3000 train_loss:3.7036 train_time:365609ms step_avg:287.43ms
step:1283/3000 train_loss:3.7423 train_time:365894ms step_avg:287.43ms
step:1284/3000 train_loss:3.6195 train_time:366182ms step_avg:287.43ms
step:1285/3000 train_loss:3.6473 train_time:366467ms step_avg:287.43ms
step:1286/3000 train_loss:3.6305 train_time:366751ms step_avg:287.42ms
step:1287/3000 train_loss:3.6096 train_time:367038ms step_avg:287.42ms
step:1288/3000 train_loss:3.7399 train_time:367326ms step_avg:287.42ms
step:1289/3000 train_loss:3.5755 train_time:367609ms step_avg:287.42ms
step:1290/3000 train_loss:3.6556 train_time:367893ms step_avg:287.42ms
step:1291/3000 train_loss:3.7281 train_time:368179ms step_avg:287.42ms
step:1292/3000 train_loss:3.6601 train_time:368464ms step_avg:287.41ms
step:1293/3000 train_loss:3.7555 train_time:368749ms step_avg:287.41ms
step:1294/3000 train_loss:3.7848 train_time:369036ms step_avg:287.41ms
step:1295/3000 train_loss:3.7464 train_time:369320ms step_avg:287.41ms
step:1296/3000 train_loss:3.5536 train_time:369607ms step_avg:287.41ms
step:1297/3000 train_loss:3.6301 train_time:369891ms step_avg:287.41ms
step:1298/3000 train_loss:3.5325 train_time:370176ms step_avg:287.40ms
step:1299/3000 train_loss:3.6007 train_time:370461ms step_avg:287.40ms
step:1300/3000 train_loss:3.6683 train_time:370748ms step_avg:287.40ms
step:1301/3000 train_loss:3.6757 train_time:371032ms step_avg:287.40ms
step:1302/3000 train_loss:3.6837 train_time:371318ms step_avg:287.40ms
step:1303/3000 train_loss:3.8344 train_time:371606ms step_avg:287.40ms
step:1304/3000 train_loss:3.6064 train_time:371891ms step_avg:287.40ms
step:1305/3000 train_loss:3.8152 train_time:372177ms step_avg:287.40ms
step:1306/3000 train_loss:3.5425 train_time:372461ms step_avg:287.39ms
step:1307/3000 train_loss:3.7302 train_time:372748ms step_avg:287.39ms
step:1308/3000 train_loss:3.7324 train_time:373033ms step_avg:287.39ms
step:1309/3000 train_loss:3.5944 train_time:373318ms step_avg:287.39ms
step:1310/3000 train_loss:3.5618 train_time:373606ms step_avg:287.39ms
step:1311/3000 train_loss:3.5896 train_time:373890ms step_avg:287.39ms
step:1312/3000 train_loss:3.5618 train_time:374176ms step_avg:287.39ms
step:1313/3000 train_loss:3.6858 train_time:374461ms step_avg:287.38ms
step:1314/3000 train_loss:3.6238 train_time:374747ms step_avg:287.38ms
step:1315/3000 train_loss:3.3430 train_time:375034ms step_avg:287.38ms
step:1316/3000 train_loss:3.5773 train_time:375318ms step_avg:287.38ms
step:1317/3000 train_loss:3.6519 train_time:375605ms step_avg:287.38ms
step:1318/3000 train_loss:3.6829 train_time:375889ms step_avg:287.38ms
step:1319/3000 train_loss:3.5564 train_time:376174ms step_avg:287.37ms
step:1320/3000 train_loss:3.6978 train_time:376460ms step_avg:287.37ms
step:1321/3000 train_loss:3.7480 train_time:376748ms step_avg:287.37ms
step:1322/3000 train_loss:3.6367 train_time:377033ms step_avg:287.37ms
step:1323/3000 train_loss:3.5825 train_time:377503ms step_avg:287.51ms
step:1324/3000 train_loss:3.6190 train_time:377788ms step_avg:287.51ms
step:1325/3000 train_loss:3.7047 train_time:378072ms step_avg:287.51ms
step:1326/3000 train_loss:3.7606 train_time:378357ms step_avg:287.51ms
step:1327/3000 train_loss:3.5218 train_time:378645ms step_avg:287.51ms
step:1328/3000 train_loss:3.4404 train_time:378930ms step_avg:287.50ms
step:1329/3000 train_loss:3.7469 train_time:379212ms step_avg:287.50ms
step:1330/3000 train_loss:3.5950 train_time:379680ms step_avg:287.64ms
step:1331/3000 train_loss:3.7228 train_time:379962ms step_avg:287.63ms
step:1332/3000 train_loss:3.6292 train_time:380248ms step_avg:287.63ms
step:1333/3000 train_loss:4.0364 train_time:380532ms step_avg:287.63ms
step:1334/3000 train_loss:3.7250 train_time:380816ms step_avg:287.63ms
step:1335/3000 train_loss:3.6373 train_time:381103ms step_avg:287.62ms
step:1336/3000 train_loss:3.5874 train_time:381388ms step_avg:287.62ms
step:1337/3000 train_loss:3.5744 train_time:381672ms step_avg:287.62ms
step:1338/3000 train_loss:3.8366 train_time:381956ms step_avg:287.62ms
step:1339/3000 train_loss:3.7724 train_time:382243ms step_avg:287.62ms
step:1340/3000 train_loss:3.6213 train_time:382528ms step_avg:287.62ms
step:1341/3000 train_loss:3.5742 train_time:382812ms step_avg:287.61ms
step:1342/3000 train_loss:3.8842 train_time:383099ms step_avg:287.61ms
step:1343/3000 train_loss:3.6486 train_time:383385ms step_avg:287.61ms
step:1344/3000 train_loss:3.6461 train_time:383668ms step_avg:287.61ms
step:1345/3000 train_loss:3.7015 train_time:383951ms step_avg:287.60ms
step:1346/3000 train_loss:3.6661 train_time:384238ms step_avg:287.60ms
step:1347/3000 train_loss:3.5683 train_time:384523ms step_avg:287.60ms
step:1348/3000 train_loss:3.5159 train_time:384809ms step_avg:287.60ms
step:1349/3000 train_loss:3.6165 train_time:385093ms step_avg:287.60ms
step:1350/3000 train_loss:3.5467 train_time:385379ms step_avg:287.60ms
step:1351/3000 train_loss:3.6826 train_time:385664ms step_avg:287.59ms
step:1352/3000 train_loss:3.5320 train_time:385949ms step_avg:287.59ms
step:1353/3000 train_loss:3.5941 train_time:386233ms step_avg:287.59ms
step:1354/3000 train_loss:3.7008 train_time:386519ms step_avg:287.59ms
step:1355/3000 train_loss:3.5359 train_time:386807ms step_avg:287.59ms
step:1356/3000 train_loss:3.4651 train_time:387091ms step_avg:287.59ms
step:1357/3000 train_loss:3.8147 train_time:387377ms step_avg:287.58ms
step:1358/3000 train_loss:3.7374 train_time:387662ms step_avg:287.58ms
step:1359/3000 train_loss:3.4502 train_time:387948ms step_avg:287.58ms
step:1360/3000 train_loss:3.7458 train_time:388234ms step_avg:287.58ms
step:1361/3000 train_loss:3.6220 train_time:388519ms step_avg:287.58ms
step:1362/3000 train_loss:3.4827 train_time:388807ms step_avg:287.58ms
step:1363/3000 train_loss:3.6647 train_time:389092ms step_avg:287.58ms
step:1364/3000 train_loss:3.5530 train_time:389377ms step_avg:287.58ms
step:1365/3000 train_loss:3.5780 train_time:389663ms step_avg:287.57ms
step:1366/3000 train_loss:3.6021 train_time:389949ms step_avg:287.57ms
step:1367/3000 train_loss:3.7063 train_time:390234ms step_avg:287.57ms
step:1368/3000 train_loss:3.6898 train_time:390518ms step_avg:287.57ms
step:1369/3000 train_loss:3.6394 train_time:390807ms step_avg:287.57ms
step:1370/3000 train_loss:3.5396 train_time:391091ms step_avg:287.57ms
step:1371/3000 train_loss:3.8724 train_time:391377ms step_avg:287.57ms
step:1372/3000 train_loss:3.6195 train_time:391662ms step_avg:287.56ms
step:1373/3000 train_loss:3.6496 train_time:391949ms step_avg:287.56ms
step:1374/3000 train_loss:3.6537 train_time:392235ms step_avg:287.56ms
step:1375/3000 train_loss:3.4454 train_time:392520ms step_avg:287.56ms
step:1375/3000 val_loss:3.6052 train_time:392521ms step_avg:287.56ms
step:1376/3000 train_loss:3.8498 train_time:392805ms step_avg:287.56ms
step:1377/3000 train_loss:3.6212 train_time:393090ms step_avg:287.56ms
step:1378/3000 train_loss:3.7705 train_time:393378ms step_avg:287.56ms
step:1379/3000 train_loss:3.8145 train_time:393665ms step_avg:287.56ms
step:1380/3000 train_loss:3.4726 train_time:393949ms step_avg:287.55ms
step:1381/3000 train_loss:3.6139 train_time:394232ms step_avg:287.55ms
step:1382/3000 train_loss:4.0563 train_time:394517ms step_avg:287.55ms
step:1383/3000 train_loss:3.5257 train_time:394805ms step_avg:287.55ms
step:1384/3000 train_loss:3.6801 train_time:395090ms step_avg:287.55ms
step:1385/3000 train_loss:3.7571 train_time:395377ms step_avg:287.55ms
step:1386/3000 train_loss:3.6699 train_time:395660ms step_avg:287.54ms
step:1387/3000 train_loss:3.6660 train_time:395946ms step_avg:287.54ms
step:1388/3000 train_loss:3.4862 train_time:396231ms step_avg:287.54ms
step:1389/3000 train_loss:3.6305 train_time:396515ms step_avg:287.54ms
step:1390/3000 train_loss:3.5973 train_time:396801ms step_avg:287.54ms
step:1391/3000 train_loss:3.8683 train_time:397085ms step_avg:287.53ms
step:1392/3000 train_loss:3.5812 train_time:397372ms step_avg:287.53ms
step:1393/3000 train_loss:3.5737 train_time:397656ms step_avg:287.53ms
step:1394/3000 train_loss:3.5428 train_time:397941ms step_avg:287.53ms
step:1395/3000 train_loss:3.8271 train_time:398227ms step_avg:287.53ms
step:1396/3000 train_loss:3.7204 train_time:398514ms step_avg:287.53ms
step:1397/3000 train_loss:3.7234 train_time:398799ms step_avg:287.53ms
step:1398/3000 train_loss:3.5846 train_time:399082ms step_avg:287.52ms
step:1399/3000 train_loss:3.5608 train_time:399370ms step_avg:287.52ms
step:1400/3000 train_loss:3.6251 train_time:399656ms step_avg:287.52ms
step:1401/3000 train_loss:3.5980 train_time:399941ms step_avg:287.52ms
step:1402/3000 train_loss:3.6227 train_time:400225ms step_avg:287.52ms
step:1403/3000 train_loss:3.5853 train_time:400513ms step_avg:287.52ms
step:1404/3000 train_loss:3.8223 train_time:400797ms step_avg:287.52ms
step:1405/3000 train_loss:3.5591 train_time:401079ms step_avg:287.51ms
step:1406/3000 train_loss:3.6073 train_time:401367ms step_avg:287.51ms
step:1407/3000 train_loss:3.6025 train_time:401654ms step_avg:287.51ms
step:1408/3000 train_loss:3.4713 train_time:401939ms step_avg:287.51ms
step:1409/3000 train_loss:3.5889 train_time:402224ms step_avg:287.51ms
step:1410/3000 train_loss:3.5691 train_time:402513ms step_avg:287.51ms
step:1411/3000 train_loss:3.5704 train_time:402800ms step_avg:287.51ms
step:1412/3000 train_loss:3.6609 train_time:403084ms step_avg:287.51ms
step:1413/3000 train_loss:3.5970 train_time:403370ms step_avg:287.51ms
step:1414/3000 train_loss:3.6490 train_time:403654ms step_avg:287.50ms
step:1415/3000 train_loss:3.6356 train_time:403939ms step_avg:287.50ms
step:1416/3000 train_loss:3.7162 train_time:404225ms step_avg:287.50ms
step:1417/3000 train_loss:3.5113 train_time:404514ms step_avg:287.50ms
step:1418/3000 train_loss:3.5816 train_time:404799ms step_avg:287.50ms
step:1419/3000 train_loss:3.6659 train_time:405084ms step_avg:287.50ms
step:1420/3000 train_loss:3.6963 train_time:405372ms step_avg:287.50ms
step:1421/3000 train_loss:3.6759 train_time:405657ms step_avg:287.50ms
step:1422/3000 train_loss:3.6621 train_time:405943ms step_avg:287.49ms
step:1423/3000 train_loss:3.6509 train_time:406227ms step_avg:287.49ms
step:1424/3000 train_loss:3.6355 train_time:406514ms step_avg:287.49ms
step:1425/3000 train_loss:3.6311 train_time:406798ms step_avg:287.49ms
step:1426/3000 train_loss:3.4926 train_time:407083ms step_avg:287.49ms
step:1427/3000 train_loss:3.6200 train_time:407370ms step_avg:287.49ms
step:1428/3000 train_loss:3.5544 train_time:407655ms step_avg:287.49ms
step:1429/3000 train_loss:3.6686 train_time:407938ms step_avg:287.48ms
step:1430/3000 train_loss:3.6348 train_time:408224ms step_avg:287.48ms
step:1431/3000 train_loss:3.5625 train_time:408513ms step_avg:287.48ms
step:1432/3000 train_loss:3.6106 train_time:408797ms step_avg:287.48ms
step:1433/3000 train_loss:3.6465 train_time:409082ms step_avg:287.48ms
step:1434/3000 train_loss:3.5247 train_time:409369ms step_avg:287.48ms
step:1435/3000 train_loss:3.6138 train_time:409655ms step_avg:287.48ms
step:1436/3000 train_loss:3.4479 train_time:409940ms step_avg:287.48ms
step:1437/3000 train_loss:3.5127 train_time:410224ms step_avg:287.47ms
step:1438/3000 train_loss:3.6969 train_time:410511ms step_avg:287.47ms
step:1439/3000 train_loss:3.6611 train_time:410795ms step_avg:287.47ms
step:1440/3000 train_loss:3.6140 train_time:411079ms step_avg:287.47ms
step:1441/3000 train_loss:3.4637 train_time:411366ms step_avg:287.47ms
step:1442/3000 train_loss:3.6359 train_time:411654ms step_avg:287.47ms
step:1443/3000 train_loss:3.6984 train_time:411938ms step_avg:287.47ms
step:1444/3000 train_loss:3.7660 train_time:412224ms step_avg:287.46ms
step:1445/3000 train_loss:3.7375 train_time:412511ms step_avg:287.46ms
step:1446/3000 train_loss:3.6263 train_time:412796ms step_avg:287.46ms
step:1447/3000 train_loss:3.4981 train_time:413079ms step_avg:287.46ms
step:1448/3000 train_loss:3.5726 train_time:413366ms step_avg:287.46ms
step:1449/3000 train_loss:3.5844 train_time:413654ms step_avg:287.46ms
step:1450/3000 train_loss:3.7172 train_time:413936ms step_avg:287.46ms
step:1451/3000 train_loss:3.6939 train_time:414220ms step_avg:287.45ms
step:1452/3000 train_loss:3.5216 train_time:414509ms step_avg:287.45ms
step:1453/3000 train_loss:3.6235 train_time:414795ms step_avg:287.45ms
step:1454/3000 train_loss:3.5478 train_time:415078ms step_avg:287.45ms
step:1455/3000 train_loss:3.5745 train_time:415365ms step_avg:287.45ms
step:1456/3000 train_loss:3.6234 train_time:415651ms step_avg:287.45ms
step:1457/3000 train_loss:3.5568 train_time:415935ms step_avg:287.45ms
step:1458/3000 train_loss:3.4570 train_time:416218ms step_avg:287.44ms
step:1459/3000 train_loss:3.6948 train_time:416507ms step_avg:287.44ms
step:1460/3000 train_loss:3.5692 train_time:416793ms step_avg:287.44ms
step:1461/3000 train_loss:3.6181 train_time:417077ms step_avg:287.44ms
step:1462/3000 train_loss:3.7458 train_time:417362ms step_avg:287.44ms
step:1463/3000 train_loss:3.5599 train_time:417650ms step_avg:287.44ms
step:1464/3000 train_loss:3.7544 train_time:417935ms step_avg:287.44ms
step:1465/3000 train_loss:3.6399 train_time:418218ms step_avg:287.44ms
step:1466/3000 train_loss:3.6490 train_time:418505ms step_avg:287.43ms
step:1467/3000 train_loss:3.5727 train_time:418792ms step_avg:287.43ms
step:1468/3000 train_loss:3.7315 train_time:419076ms step_avg:287.43ms
step:1469/3000 train_loss:3.5870 train_time:419361ms step_avg:287.43ms
step:1470/3000 train_loss:3.5606 train_time:419647ms step_avg:287.43ms
step:1471/3000 train_loss:3.6133 train_time:419935ms step_avg:287.43ms
step:1472/3000 train_loss:3.5367 train_time:420219ms step_avg:287.43ms
step:1473/3000 train_loss:3.6301 train_time:420506ms step_avg:287.43ms
step:1474/3000 train_loss:3.7237 train_time:420790ms step_avg:287.42ms
step:1475/3000 train_loss:3.6029 train_time:421076ms step_avg:287.42ms
step:1476/3000 train_loss:3.4267 train_time:421359ms step_avg:287.42ms
step:1477/3000 train_loss:3.5467 train_time:421645ms step_avg:287.42ms
step:1478/3000 train_loss:3.5288 train_time:421930ms step_avg:287.42ms
step:1479/3000 train_loss:3.6129 train_time:422216ms step_avg:287.42ms
step:1480/3000 train_loss:3.6941 train_time:422503ms step_avg:287.42ms
step:1481/3000 train_loss:3.5661 train_time:422785ms step_avg:287.41ms
step:1482/3000 train_loss:3.7395 train_time:423073ms step_avg:287.41ms
step:1483/3000 train_loss:3.6608 train_time:423357ms step_avg:287.41ms
step:1484/3000 train_loss:3.5630 train_time:423642ms step_avg:287.41ms
step:1485/3000 train_loss:3.5555 train_time:423929ms step_avg:287.41ms
step:1486/3000 train_loss:3.5496 train_time:424216ms step_avg:287.41ms
step:1487/3000 train_loss:3.5298 train_time:424500ms step_avg:287.41ms
step:1488/3000 train_loss:3.6177 train_time:424785ms step_avg:287.41ms
step:1489/3000 train_loss:3.5264 train_time:425072ms step_avg:287.41ms
step:1490/3000 train_loss:3.6158 train_time:425357ms step_avg:287.40ms
step:1491/3000 train_loss:3.5526 train_time:425642ms step_avg:287.40ms
step:1492/3000 train_loss:3.4802 train_time:425929ms step_avg:287.40ms
step:1493/3000 train_loss:3.5500 train_time:426216ms step_avg:287.40ms
step:1494/3000 train_loss:3.7262 train_time:426503ms step_avg:287.40ms
step:1495/3000 train_loss:3.5863 train_time:426787ms step_avg:287.40ms
step:1496/3000 train_loss:3.3352 train_time:427074ms step_avg:287.40ms
step:1497/3000 train_loss:3.6423 train_time:427358ms step_avg:287.40ms
step:1498/3000 train_loss:3.6051 train_time:427645ms step_avg:287.40ms
step:1499/3000 train_loss:3.6477 train_time:427931ms step_avg:287.39ms
step:1500/3000 train_loss:3.6088 train_time:428218ms step_avg:287.39ms
step:1500/3000 val_loss:3.5820 train_time:428218ms step_avg:287.39ms
step:1501/3000 train_loss:3.5886 train_time:428501ms step_avg:287.39ms
step:1502/3000 train_loss:3.3811 train_time:428791ms step_avg:287.39ms
step:1503/3000 train_loss:3.6608 train_time:429076ms step_avg:287.39ms
step:1504/3000 train_loss:3.5358 train_time:429362ms step_avg:287.39ms
step:1505/3000 train_loss:3.5437 train_time:429647ms step_avg:287.39ms
step:1506/3000 train_loss:3.4990 train_time:429933ms step_avg:287.39ms
step:1507/3000 train_loss:3.5858 train_time:430219ms step_avg:287.39ms
step:1508/3000 train_loss:3.4952 train_time:430502ms step_avg:287.38ms
step:1509/3000 train_loss:3.8151 train_time:430789ms step_avg:287.38ms
step:1510/3000 train_loss:3.5460 train_time:431076ms step_avg:287.38ms
step:1511/3000 train_loss:3.5642 train_time:431361ms step_avg:287.38ms
step:1512/3000 train_loss:3.6850 train_time:431898ms step_avg:287.55ms
step:1513/3000 train_loss:3.7159 train_time:432182ms step_avg:287.55ms
step:1514/3000 train_loss:3.5680 train_time:432464ms step_avg:287.54ms
step:1515/3000 train_loss:3.4059 train_time:432751ms step_avg:287.54ms
step:1516/3000 train_loss:3.5295 train_time:433037ms step_avg:287.54ms
step:1517/3000 train_loss:3.5395 train_time:433321ms step_avg:287.54ms
step:1518/3000 train_loss:3.6198 train_time:433604ms step_avg:287.54ms
step:1519/3000 train_loss:3.5093 train_time:433894ms step_avg:287.54ms
step:1520/3000 train_loss:3.8016 train_time:434358ms step_avg:287.65ms
step:1521/3000 train_loss:3.4667 train_time:434640ms step_avg:287.65ms
step:1522/3000 train_loss:3.5243 train_time:434922ms step_avg:287.65ms
step:1523/3000 train_loss:3.6679 train_time:435204ms step_avg:287.64ms
step:1524/3000 train_loss:3.5270 train_time:435493ms step_avg:287.64ms
step:1525/3000 train_loss:3.6206 train_time:435780ms step_avg:287.64ms
step:1526/3000 train_loss:3.6110 train_time:436063ms step_avg:287.64ms
step:1527/3000 train_loss:3.5807 train_time:436347ms step_avg:287.64ms
step:1528/3000 train_loss:3.5789 train_time:436633ms step_avg:287.64ms
step:1529/3000 train_loss:3.7301 train_time:436918ms step_avg:287.63ms
step:1530/3000 train_loss:3.6957 train_time:437204ms step_avg:287.63ms
step:1531/3000 train_loss:3.5343 train_time:437488ms step_avg:287.63ms
step:1532/3000 train_loss:3.4907 train_time:437773ms step_avg:287.63ms
step:1533/3000 train_loss:3.6471 train_time:438056ms step_avg:287.63ms
step:1534/3000 train_loss:3.6029 train_time:438340ms step_avg:287.62ms
step:1535/3000 train_loss:3.5861 train_time:438626ms step_avg:287.62ms
step:1536/3000 train_loss:3.5825 train_time:438910ms step_avg:287.62ms
step:1537/3000 train_loss:3.5189 train_time:439197ms step_avg:287.62ms
step:1538/3000 train_loss:3.5828 train_time:439481ms step_avg:287.62ms
step:1539/3000 train_loss:3.7535 train_time:439764ms step_avg:287.62ms
step:1540/3000 train_loss:3.6862 train_time:440051ms step_avg:287.61ms
step:1541/3000 train_loss:3.5907 train_time:440338ms step_avg:287.61ms
step:1542/3000 train_loss:3.5441 train_time:440620ms step_avg:287.61ms
step:1543/3000 train_loss:3.5469 train_time:440905ms step_avg:287.61ms
step:1544/3000 train_loss:3.5098 train_time:441193ms step_avg:287.61ms
step:1545/3000 train_loss:3.6030 train_time:441479ms step_avg:287.61ms
step:1546/3000 train_loss:3.5682 train_time:441762ms step_avg:287.61ms
step:1547/3000 train_loss:3.5430 train_time:442049ms step_avg:287.61ms
step:1548/3000 train_loss:3.5032 train_time:442336ms step_avg:287.60ms
step:1549/3000 train_loss:3.5409 train_time:442619ms step_avg:287.60ms
step:1550/3000 train_loss:3.6521 train_time:442903ms step_avg:287.60ms
step:1551/3000 train_loss:3.5809 train_time:443190ms step_avg:287.60ms
step:1552/3000 train_loss:3.5174 train_time:443475ms step_avg:287.60ms
step:1553/3000 train_loss:3.5168 train_time:443761ms step_avg:287.60ms
step:1554/3000 train_loss:3.5008 train_time:444046ms step_avg:287.59ms
step:1555/3000 train_loss:3.6337 train_time:444332ms step_avg:287.59ms
step:1556/3000 train_loss:3.6396 train_time:444617ms step_avg:287.59ms
step:1557/3000 train_loss:3.5720 train_time:444900ms step_avg:287.59ms
step:1558/3000 train_loss:3.6256 train_time:445187ms step_avg:287.59ms
step:1559/3000 train_loss:3.5447 train_time:445473ms step_avg:287.59ms
step:1560/3000 train_loss:3.4651 train_time:445760ms step_avg:287.59ms
step:1561/3000 train_loss:3.7042 train_time:446044ms step_avg:287.58ms
step:1562/3000 train_loss:3.5244 train_time:446330ms step_avg:287.58ms
step:1563/3000 train_loss:3.5057 train_time:446614ms step_avg:287.58ms
step:1564/3000 train_loss:3.6297 train_time:446899ms step_avg:287.58ms
step:1565/3000 train_loss:3.4581 train_time:447185ms step_avg:287.58ms
step:1566/3000 train_loss:3.5206 train_time:447471ms step_avg:287.58ms
step:1567/3000 train_loss:3.6647 train_time:447760ms step_avg:287.58ms
step:1568/3000 train_loss:3.5453 train_time:448045ms step_avg:287.58ms
step:1569/3000 train_loss:3.5283 train_time:448329ms step_avg:287.57ms
step:1570/3000 train_loss:3.6290 train_time:448614ms step_avg:287.57ms
step:1571/3000 train_loss:3.6347 train_time:448901ms step_avg:287.57ms
step:1572/3000 train_loss:3.4609 train_time:449187ms step_avg:287.57ms
step:1573/3000 train_loss:3.4919 train_time:449473ms step_avg:287.57ms
step:1574/3000 train_loss:3.6117 train_time:449759ms step_avg:287.57ms
step:1575/3000 train_loss:3.4781 train_time:450043ms step_avg:287.57ms
step:1576/3000 train_loss:3.6224 train_time:450330ms step_avg:287.57ms
step:1577/3000 train_loss:3.5248 train_time:450617ms step_avg:287.57ms
step:1578/3000 train_loss:3.5812 train_time:450901ms step_avg:287.56ms
step:1579/3000 train_loss:3.5569 train_time:451185ms step_avg:287.56ms
step:1580/3000 train_loss:3.5240 train_time:451471ms step_avg:287.56ms
step:1581/3000 train_loss:3.4967 train_time:451759ms step_avg:287.56ms
step:1582/3000 train_loss:3.7375 train_time:452043ms step_avg:287.56ms
step:1583/3000 train_loss:3.5064 train_time:452329ms step_avg:287.56ms
step:1584/3000 train_loss:3.6647 train_time:452615ms step_avg:287.56ms
step:1585/3000 train_loss:3.4986 train_time:452900ms step_avg:287.56ms
step:1586/3000 train_loss:3.6520 train_time:453186ms step_avg:287.55ms
step:1587/3000 train_loss:3.4421 train_time:453470ms step_avg:287.55ms
step:1588/3000 train_loss:3.6387 train_time:453758ms step_avg:287.55ms
step:1589/3000 train_loss:3.5481 train_time:454042ms step_avg:287.55ms
step:1590/3000 train_loss:3.7089 train_time:454327ms step_avg:287.55ms
step:1591/3000 train_loss:3.5183 train_time:454612ms step_avg:287.55ms
step:1592/3000 train_loss:3.5426 train_time:454898ms step_avg:287.55ms
step:1593/3000 train_loss:3.6083 train_time:455184ms step_avg:287.54ms
step:1594/3000 train_loss:3.5867 train_time:455468ms step_avg:287.54ms
step:1595/3000 train_loss:3.5587 train_time:455756ms step_avg:287.54ms
step:1596/3000 train_loss:3.7015 train_time:456041ms step_avg:287.54ms
step:1597/3000 train_loss:3.4344 train_time:456325ms step_avg:287.54ms
step:1598/3000 train_loss:3.5926 train_time:456609ms step_avg:287.54ms
step:1599/3000 train_loss:3.6274 train_time:456897ms step_avg:287.54ms
step:1600/3000 train_loss:3.6806 train_time:457182ms step_avg:287.54ms
step:1601/3000 train_loss:3.5270 train_time:457466ms step_avg:287.53ms
step:1602/3000 train_loss:3.8250 train_time:457752ms step_avg:287.53ms
step:1603/3000 train_loss:3.7168 train_time:458039ms step_avg:287.53ms
step:1604/3000 train_loss:3.4981 train_time:458322ms step_avg:287.53ms
step:1605/3000 train_loss:3.5367 train_time:458607ms step_avg:287.53ms
step:1606/3000 train_loss:3.4172 train_time:458895ms step_avg:287.53ms
step:1607/3000 train_loss:3.7403 train_time:459180ms step_avg:287.53ms
step:1608/3000 train_loss:3.5437 train_time:459463ms step_avg:287.52ms
step:1609/3000 train_loss:3.5709 train_time:459750ms step_avg:287.52ms
step:1610/3000 train_loss:3.5128 train_time:460036ms step_avg:287.52ms
step:1611/3000 train_loss:4.1193 train_time:460320ms step_avg:287.52ms
step:1612/3000 train_loss:3.7440 train_time:460604ms step_avg:287.52ms
step:1613/3000 train_loss:3.6589 train_time:460893ms step_avg:287.52ms
step:1614/3000 train_loss:3.5301 train_time:461179ms step_avg:287.52ms
step:1615/3000 train_loss:3.5752 train_time:461463ms step_avg:287.52ms
step:1616/3000 train_loss:3.5632 train_time:461749ms step_avg:287.51ms
step:1617/3000 train_loss:3.5262 train_time:462036ms step_avg:287.51ms
step:1618/3000 train_loss:3.6021 train_time:462320ms step_avg:287.51ms
step:1619/3000 train_loss:3.5586 train_time:462603ms step_avg:287.51ms
step:1620/3000 train_loss:3.4536 train_time:462892ms step_avg:287.51ms
step:1621/3000 train_loss:3.7178 train_time:463179ms step_avg:287.51ms
step:1622/3000 train_loss:3.6198 train_time:463463ms step_avg:287.51ms
step:1623/3000 train_loss:3.4125 train_time:463749ms step_avg:287.51ms
step:1624/3000 train_loss:3.5294 train_time:464037ms step_avg:287.51ms
step:1625/3000 train_loss:3.4947 train_time:464320ms step_avg:287.50ms
step:1625/3000 val_loss:3.5601 train_time:464320ms step_avg:287.50ms
step:1626/3000 train_loss:3.5679 train_time:464603ms step_avg:287.50ms
step:1627/3000 train_loss:3.5304 train_time:464891ms step_avg:287.50ms
step:1628/3000 train_loss:3.4983 train_time:465175ms step_avg:287.50ms
step:1629/3000 train_loss:3.6053 train_time:465459ms step_avg:287.50ms
step:1630/3000 train_loss:3.5048 train_time:465746ms step_avg:287.50ms
step:1631/3000 train_loss:3.5606 train_time:466030ms step_avg:287.50ms
step:1632/3000 train_loss:3.4351 train_time:466315ms step_avg:287.49ms
step:1633/3000 train_loss:3.4045 train_time:466600ms step_avg:287.49ms
step:1634/3000 train_loss:3.5759 train_time:466887ms step_avg:287.49ms
step:1635/3000 train_loss:3.5533 train_time:467171ms step_avg:287.49ms
step:1636/3000 train_loss:3.4905 train_time:467455ms step_avg:287.49ms
step:1637/3000 train_loss:3.5793 train_time:467743ms step_avg:287.49ms
step:1638/3000 train_loss:3.6357 train_time:468028ms step_avg:287.49ms
step:1639/3000 train_loss:3.6663 train_time:468313ms step_avg:287.48ms
step:1640/3000 train_loss:3.8241 train_time:468597ms step_avg:287.48ms
step:1641/3000 train_loss:3.6485 train_time:468883ms step_avg:287.48ms
step:1642/3000 train_loss:3.5575 train_time:469169ms step_avg:287.48ms
step:1643/3000 train_loss:3.6429 train_time:469454ms step_avg:287.48ms
step:1644/3000 train_loss:3.5441 train_time:469740ms step_avg:287.48ms
step:1645/3000 train_loss:3.5588 train_time:470027ms step_avg:287.48ms
step:1646/3000 train_loss:3.5609 train_time:470312ms step_avg:287.48ms
step:1647/3000 train_loss:3.3389 train_time:470595ms step_avg:287.47ms
step:1648/3000 train_loss:3.5972 train_time:470882ms step_avg:287.47ms
step:1649/3000 train_loss:3.4637 train_time:471167ms step_avg:287.47ms
step:1650/3000 train_loss:3.5384 train_time:471453ms step_avg:287.47ms
step:1651/3000 train_loss:3.5086 train_time:471738ms step_avg:287.47ms
step:1652/3000 train_loss:3.5818 train_time:472024ms step_avg:287.47ms
step:1653/3000 train_loss:3.5183 train_time:472310ms step_avg:287.47ms
step:1654/3000 train_loss:3.6436 train_time:472594ms step_avg:287.47ms
step:1655/3000 train_loss:3.6326 train_time:472880ms step_avg:287.47ms
step:1656/3000 train_loss:3.4493 train_time:473166ms step_avg:287.46ms
step:1657/3000 train_loss:3.6090 train_time:473452ms step_avg:287.46ms
step:1658/3000 train_loss:3.5047 train_time:473738ms step_avg:287.46ms
step:1659/3000 train_loss:3.4825 train_time:474023ms step_avg:287.46ms
step:1660/3000 train_loss:3.5744 train_time:474310ms step_avg:287.46ms
step:1661/3000 train_loss:3.5892 train_time:474594ms step_avg:287.46ms
step:1662/3000 train_loss:3.5122 train_time:474879ms step_avg:287.46ms
step:1663/3000 train_loss:3.6015 train_time:475165ms step_avg:287.46ms
step:1664/3000 train_loss:3.6091 train_time:475452ms step_avg:287.46ms
step:1665/3000 train_loss:3.6347 train_time:475737ms step_avg:287.45ms
step:1666/3000 train_loss:3.6131 train_time:476021ms step_avg:287.45ms
step:1667/3000 train_loss:3.7511 train_time:476308ms step_avg:287.45ms
step:1668/3000 train_loss:3.4652 train_time:476593ms step_avg:287.45ms
step:1669/3000 train_loss:3.5415 train_time:476876ms step_avg:287.45ms
step:1670/3000 train_loss:3.4623 train_time:477160ms step_avg:287.45ms
step:1671/3000 train_loss:3.4703 train_time:477448ms step_avg:287.45ms
step:1672/3000 train_loss:3.6300 train_time:477733ms step_avg:287.44ms
step:1673/3000 train_loss:3.8063 train_time:478017ms step_avg:287.44ms
step:1674/3000 train_loss:3.5280 train_time:478304ms step_avg:287.44ms
step:1675/3000 train_loss:3.5150 train_time:478592ms step_avg:287.44ms
step:1676/3000 train_loss:3.4008 train_time:478875ms step_avg:287.44ms
step:1677/3000 train_loss:3.6020 train_time:479161ms step_avg:287.44ms
step:1678/3000 train_loss:3.5206 train_time:479448ms step_avg:287.44ms
step:1679/3000 train_loss:3.5438 train_time:479734ms step_avg:287.44ms
step:1680/3000 train_loss:3.5339 train_time:480017ms step_avg:287.44ms
step:1681/3000 train_loss:3.3513 train_time:480304ms step_avg:287.43ms
step:1682/3000 train_loss:3.5402 train_time:480591ms step_avg:287.43ms
step:1683/3000 train_loss:3.5539 train_time:480873ms step_avg:287.43ms
step:1684/3000 train_loss:3.5857 train_time:481158ms step_avg:287.43ms
step:1685/3000 train_loss:3.5923 train_time:481446ms step_avg:287.43ms
step:1686/3000 train_loss:3.5040 train_time:481731ms step_avg:287.43ms
step:1687/3000 train_loss:3.6047 train_time:482015ms step_avg:287.43ms
step:1688/3000 train_loss:3.4886 train_time:482302ms step_avg:287.43ms
step:1689/3000 train_loss:3.5769 train_time:482590ms step_avg:287.43ms
step:1690/3000 train_loss:3.4887 train_time:482873ms step_avg:287.42ms
step:1691/3000 train_loss:3.3880 train_time:483157ms step_avg:287.42ms
step:1692/3000 train_loss:3.5393 train_time:483446ms step_avg:287.42ms
step:1693/3000 train_loss:3.5336 train_time:483732ms step_avg:287.42ms
step:1694/3000 train_loss:3.4510 train_time:484016ms step_avg:287.42ms
step:1695/3000 train_loss:3.8962 train_time:484302ms step_avg:287.42ms
step:1696/3000 train_loss:3.6125 train_time:484589ms step_avg:287.42ms
step:1697/3000 train_loss:3.5916 train_time:484872ms step_avg:287.42ms
step:1698/3000 train_loss:3.4972 train_time:485157ms step_avg:287.42ms
step:1699/3000 train_loss:3.4146 train_time:485445ms step_avg:287.42ms
step:1700/3000 train_loss:3.5018 train_time:485731ms step_avg:287.41ms
step:1701/3000 train_loss:3.4948 train_time:486272ms step_avg:287.56ms
step:1702/3000 train_loss:3.5681 train_time:486557ms step_avg:287.56ms
step:1703/3000 train_loss:3.4924 train_time:486841ms step_avg:287.56ms
step:1704/3000 train_loss:3.6932 train_time:487126ms step_avg:287.56ms
step:1705/3000 train_loss:3.4605 train_time:487412ms step_avg:287.56ms
step:1706/3000 train_loss:3.6903 train_time:487696ms step_avg:287.56ms
step:1707/3000 train_loss:3.5294 train_time:487981ms step_avg:287.55ms
step:1708/3000 train_loss:3.3033 train_time:488266ms step_avg:287.55ms
step:1709/3000 train_loss:3.6378 train_time:488553ms step_avg:287.55ms
step:1710/3000 train_loss:3.5553 train_time:489015ms step_avg:287.66ms
step:1711/3000 train_loss:3.5403 train_time:489298ms step_avg:287.65ms
step:1712/3000 train_loss:3.6283 train_time:489584ms step_avg:287.65ms
step:1713/3000 train_loss:3.4322 train_time:489867ms step_avg:287.65ms
step:1714/3000 train_loss:3.5607 train_time:490152ms step_avg:287.65ms
step:1715/3000 train_loss:3.5343 train_time:490438ms step_avg:287.65ms
step:1716/3000 train_loss:3.6440 train_time:490722ms step_avg:287.64ms
step:1717/3000 train_loss:3.5048 train_time:491009ms step_avg:287.64ms
step:1718/3000 train_loss:3.5474 train_time:491292ms step_avg:287.64ms
step:1719/3000 train_loss:3.5110 train_time:491576ms step_avg:287.64ms
step:1720/3000 train_loss:3.6958 train_time:491861ms step_avg:287.64ms
step:1721/3000 train_loss:3.5922 train_time:492147ms step_avg:287.64ms
step:1722/3000 train_loss:3.5560 train_time:492433ms step_avg:287.64ms
step:1723/3000 train_loss:3.6536 train_time:492717ms step_avg:287.63ms
step:1724/3000 train_loss:3.4266 train_time:493003ms step_avg:287.63ms
step:1725/3000 train_loss:3.5165 train_time:493292ms step_avg:287.63ms
step:1726/3000 train_loss:3.5176 train_time:493572ms step_avg:287.63ms
step:1727/3000 train_loss:3.5763 train_time:493857ms step_avg:287.63ms
step:1728/3000 train_loss:3.6187 train_time:494147ms step_avg:287.63ms
step:1729/3000 train_loss:3.5096 train_time:494434ms step_avg:287.63ms
step:1730/3000 train_loss:3.6175 train_time:494715ms step_avg:287.63ms
step:1731/3000 train_loss:3.4296 train_time:495001ms step_avg:287.62ms
step:1732/3000 train_loss:3.5133 train_time:495287ms step_avg:287.62ms
step:1733/3000 train_loss:3.5581 train_time:495571ms step_avg:287.62ms
step:1734/3000 train_loss:3.5699 train_time:495855ms step_avg:287.62ms
step:1735/3000 train_loss:3.7836 train_time:496143ms step_avg:287.62ms
step:1736/3000 train_loss:3.5391 train_time:496428ms step_avg:287.62ms
step:1737/3000 train_loss:3.5933 train_time:496715ms step_avg:287.62ms
step:1738/3000 train_loss:3.6038 train_time:496999ms step_avg:287.62ms
step:1739/3000 train_loss:3.4912 train_time:497285ms step_avg:287.61ms
step:1740/3000 train_loss:3.5748 train_time:497572ms step_avg:287.61ms
step:1741/3000 train_loss:3.4762 train_time:497856ms step_avg:287.61ms
step:1742/3000 train_loss:3.4889 train_time:498143ms step_avg:287.61ms
step:1743/3000 train_loss:3.5011 train_time:498429ms step_avg:287.61ms
step:1744/3000 train_loss:3.4837 train_time:498714ms step_avg:287.61ms
step:1745/3000 train_loss:3.5926 train_time:498999ms step_avg:287.61ms
step:1746/3000 train_loss:3.5805 train_time:499286ms step_avg:287.61ms
step:1747/3000 train_loss:3.6262 train_time:499571ms step_avg:287.61ms
step:1748/3000 train_loss:3.6532 train_time:499856ms step_avg:287.60ms
step:1749/3000 train_loss:3.5243 train_time:500141ms step_avg:287.60ms
step:1750/3000 train_loss:3.5022 train_time:500427ms step_avg:287.60ms
step:1750/3000 val_loss:3.5303 train_time:500427ms step_avg:287.60ms
step:1751/3000 train_loss:3.5065 train_time:500710ms step_avg:287.60ms
step:1752/3000 train_loss:3.4763 train_time:500994ms step_avg:287.60ms
step:1753/3000 train_loss:3.5255 train_time:501283ms step_avg:287.60ms
step:1754/3000 train_loss:3.5972 train_time:501567ms step_avg:287.60ms
step:1755/3000 train_loss:3.5494 train_time:501851ms step_avg:287.59ms
step:1756/3000 train_loss:3.5539 train_time:502135ms step_avg:287.59ms
step:1757/3000 train_loss:3.5330 train_time:502423ms step_avg:287.59ms
step:1758/3000 train_loss:3.4270 train_time:502709ms step_avg:287.59ms
step:1759/3000 train_loss:3.5000 train_time:502991ms step_avg:287.59ms
step:1760/3000 train_loss:3.5247 train_time:503277ms step_avg:287.59ms
step:1761/3000 train_loss:3.6174 train_time:503564ms step_avg:287.59ms
step:1762/3000 train_loss:3.5437 train_time:503847ms step_avg:287.58ms
step:1763/3000 train_loss:3.5046 train_time:504132ms step_avg:287.58ms
step:1764/3000 train_loss:3.6939 train_time:504421ms step_avg:287.58ms
step:1765/3000 train_loss:3.4680 train_time:504707ms step_avg:287.58ms
step:1766/3000 train_loss:3.7952 train_time:504990ms step_avg:287.58ms
step:1767/3000 train_loss:3.4459 train_time:505276ms step_avg:287.58ms
step:1768/3000 train_loss:3.3949 train_time:505563ms step_avg:287.58ms
step:1769/3000 train_loss:3.4095 train_time:505848ms step_avg:287.58ms
step:1770/3000 train_loss:3.4842 train_time:506131ms step_avg:287.57ms
step:1771/3000 train_loss:3.5704 train_time:506418ms step_avg:287.57ms
step:1772/3000 train_loss:3.4406 train_time:506703ms step_avg:287.57ms
step:1773/3000 train_loss:3.5415 train_time:506988ms step_avg:287.57ms
step:1774/3000 train_loss:3.5888 train_time:507272ms step_avg:287.57ms
step:1775/3000 train_loss:3.3645 train_time:507558ms step_avg:287.57ms
step:1776/3000 train_loss:3.4478 train_time:507844ms step_avg:287.57ms
step:1777/3000 train_loss:3.4838 train_time:508128ms step_avg:287.57ms
step:1778/3000 train_loss:3.5067 train_time:508413ms step_avg:287.56ms
step:1779/3000 train_loss:3.6335 train_time:508698ms step_avg:287.56ms
step:1780/3000 train_loss:3.4139 train_time:508986ms step_avg:287.56ms
step:1781/3000 train_loss:3.5142 train_time:509270ms step_avg:287.56ms
step:1782/3000 train_loss:3.5514 train_time:509556ms step_avg:287.56ms
step:1783/3000 train_loss:3.4783 train_time:509841ms step_avg:287.56ms
step:1784/3000 train_loss:3.3991 train_time:510128ms step_avg:287.56ms
step:1785/3000 train_loss:3.5835 train_time:510413ms step_avg:287.56ms
step:1786/3000 train_loss:3.4015 train_time:510698ms step_avg:287.56ms
step:1787/3000 train_loss:3.4704 train_time:510985ms step_avg:287.55ms
step:1788/3000 train_loss:3.5898 train_time:511269ms step_avg:287.55ms
step:1789/3000 train_loss:3.9663 train_time:511554ms step_avg:287.55ms
step:1790/3000 train_loss:3.4333 train_time:511840ms step_avg:287.55ms
step:1791/3000 train_loss:3.4999 train_time:512128ms step_avg:287.55ms
step:1792/3000 train_loss:3.4433 train_time:512413ms step_avg:287.55ms
step:1793/3000 train_loss:3.5518 train_time:512698ms step_avg:287.55ms
step:1794/3000 train_loss:3.5064 train_time:512986ms step_avg:287.55ms
step:1795/3000 train_loss:3.5228 train_time:513269ms step_avg:287.55ms
step:1796/3000 train_loss:3.4644 train_time:513554ms step_avg:287.54ms
step:1797/3000 train_loss:3.6482 train_time:513840ms step_avg:287.54ms
step:1798/3000 train_loss:3.5537 train_time:514127ms step_avg:287.54ms
step:1799/3000 train_loss:3.4299 train_time:514414ms step_avg:287.54ms
step:1800/3000 train_loss:3.4797 train_time:514698ms step_avg:287.54ms
step:1801/3000 train_loss:3.4484 train_time:514985ms step_avg:287.54ms
step:1802/3000 train_loss:3.4931 train_time:515270ms step_avg:287.54ms
step:1803/3000 train_loss:3.5905 train_time:515555ms step_avg:287.54ms
step:1804/3000 train_loss:3.4668 train_time:515842ms step_avg:287.54ms
step:1805/3000 train_loss:3.5702 train_time:516127ms step_avg:287.54ms
step:1806/3000 train_loss:3.6139 train_time:516412ms step_avg:287.53ms
step:1807/3000 train_loss:3.5273 train_time:516698ms step_avg:287.53ms
step:1808/3000 train_loss:3.4925 train_time:516986ms step_avg:287.53ms
step:1809/3000 train_loss:3.5455 train_time:517271ms step_avg:287.53ms
step:1810/3000 train_loss:3.5331 train_time:517557ms step_avg:287.53ms
step:1811/3000 train_loss:3.6499 train_time:517841ms step_avg:287.53ms
step:1812/3000 train_loss:3.4802 train_time:518128ms step_avg:287.53ms
step:1813/3000 train_loss:3.6476 train_time:518413ms step_avg:287.53ms
step:1814/3000 train_loss:3.4341 train_time:518698ms step_avg:287.53ms
step:1815/3000 train_loss:3.6011 train_time:518985ms step_avg:287.53ms
step:1816/3000 train_loss:3.4776 train_time:519270ms step_avg:287.52ms
step:1817/3000 train_loss:3.3820 train_time:519555ms step_avg:287.52ms
step:1818/3000 train_loss:3.4510 train_time:519841ms step_avg:287.52ms
step:1819/3000 train_loss:3.4169 train_time:520127ms step_avg:287.52ms
step:1820/3000 train_loss:3.4383 train_time:520413ms step_avg:287.52ms
step:1821/3000 train_loss:3.4861 train_time:520699ms step_avg:287.52ms
step:1822/3000 train_loss:3.4108 train_time:520987ms step_avg:287.52ms
step:1823/3000 train_loss:3.6049 train_time:521272ms step_avg:287.52ms
step:1824/3000 train_loss:3.4910 train_time:521558ms step_avg:287.52ms
step:1825/3000 train_loss:3.4488 train_time:521843ms step_avg:287.52ms
step:1826/3000 train_loss:3.5017 train_time:522128ms step_avg:287.52ms
step:1827/3000 train_loss:3.5757 train_time:522414ms step_avg:287.51ms
step:1828/3000 train_loss:3.4386 train_time:522698ms step_avg:287.51ms
step:1829/3000 train_loss:3.6904 train_time:522986ms step_avg:287.51ms
step:1830/3000 train_loss:3.5392 train_time:523270ms step_avg:287.51ms
step:1831/3000 train_loss:3.3377 train_time:523556ms step_avg:287.51ms
step:1832/3000 train_loss:3.4133 train_time:523840ms step_avg:287.51ms
step:1833/3000 train_loss:3.5609 train_time:524127ms step_avg:287.51ms
step:1834/3000 train_loss:3.3986 train_time:524411ms step_avg:287.51ms
step:1835/3000 train_loss:3.6743 train_time:524698ms step_avg:287.51ms
step:1836/3000 train_loss:3.5861 train_time:524984ms step_avg:287.50ms
step:1837/3000 train_loss:3.5543 train_time:525269ms step_avg:287.50ms
step:1838/3000 train_loss:3.5070 train_time:525552ms step_avg:287.50ms
step:1839/3000 train_loss:3.5270 train_time:525838ms step_avg:287.50ms
step:1840/3000 train_loss:3.8154 train_time:526127ms step_avg:287.50ms
step:1841/3000 train_loss:3.4792 train_time:526410ms step_avg:287.50ms
step:1842/3000 train_loss:3.5237 train_time:526694ms step_avg:287.50ms
step:1843/3000 train_loss:3.4932 train_time:526982ms step_avg:287.50ms
step:1844/3000 train_loss:3.5934 train_time:527268ms step_avg:287.50ms
step:1845/3000 train_loss:3.4252 train_time:527552ms step_avg:287.49ms
step:1846/3000 train_loss:3.6205 train_time:527837ms step_avg:287.49ms
step:1847/3000 train_loss:3.3660 train_time:528124ms step_avg:287.49ms
step:1848/3000 train_loss:3.5578 train_time:528409ms step_avg:287.49ms
step:1849/3000 train_loss:3.4683 train_time:528692ms step_avg:287.49ms
step:1850/3000 train_loss:3.5724 train_time:528979ms step_avg:287.49ms
step:1851/3000 train_loss:3.6860 train_time:529266ms step_avg:287.49ms
step:1852/3000 train_loss:3.5195 train_time:529550ms step_avg:287.49ms
step:1853/3000 train_loss:3.4409 train_time:529834ms step_avg:287.48ms
step:1854/3000 train_loss:3.5280 train_time:530121ms step_avg:287.48ms
step:1855/3000 train_loss:3.5644 train_time:530407ms step_avg:287.48ms
step:1856/3000 train_loss:3.5276 train_time:530691ms step_avg:287.48ms
step:1857/3000 train_loss:3.3675 train_time:530979ms step_avg:287.48ms
step:1858/3000 train_loss:3.5360 train_time:531266ms step_avg:287.48ms
step:1859/3000 train_loss:3.5921 train_time:531549ms step_avg:287.48ms
step:1860/3000 train_loss:3.4758 train_time:531833ms step_avg:287.48ms
step:1861/3000 train_loss:3.6479 train_time:532121ms step_avg:287.48ms
step:1862/3000 train_loss:3.4755 train_time:532408ms step_avg:287.48ms
step:1863/3000 train_loss:3.5152 train_time:532690ms step_avg:287.47ms
step:1864/3000 train_loss:3.5844 train_time:532977ms step_avg:287.47ms
step:1865/3000 train_loss:3.6374 train_time:533263ms step_avg:287.47ms
step:1866/3000 train_loss:3.4739 train_time:533547ms step_avg:287.47ms
step:1867/3000 train_loss:3.6263 train_time:533831ms step_avg:287.47ms
step:1868/3000 train_loss:3.6467 train_time:534120ms step_avg:287.47ms
step:1869/3000 train_loss:3.4926 train_time:534405ms step_avg:287.47ms
step:1870/3000 train_loss:3.5678 train_time:534690ms step_avg:287.47ms
step:1871/3000 train_loss:3.3682 train_time:534976ms step_avg:287.47ms
step:1872/3000 train_loss:3.6567 train_time:535263ms step_avg:287.47ms
step:1873/3000 train_loss:3.6126 train_time:535547ms step_avg:287.46ms
step:1874/3000 train_loss:3.6110 train_time:535830ms step_avg:287.46ms
step:1875/3000 train_loss:3.4598 train_time:536118ms step_avg:287.46ms
step:1875/3000 val_loss:3.5046 train_time:536119ms step_avg:287.46ms
step:1876/3000 train_loss:3.5770 train_time:536407ms step_avg:287.46ms
step:1877/3000 train_loss:3.5599 train_time:536696ms step_avg:287.46ms
step:1878/3000 train_loss:3.4618 train_time:536984ms step_avg:287.46ms
step:1879/3000 train_loss:3.5329 train_time:537266ms step_avg:287.46ms
step:1880/3000 train_loss:3.4532 train_time:537552ms step_avg:287.46ms
step:1881/3000 train_loss:3.3010 train_time:537837ms step_avg:287.46ms
step:1882/3000 train_loss:3.5000 train_time:538125ms step_avg:287.46ms
step:1883/3000 train_loss:3.5267 train_time:538410ms step_avg:287.46ms
step:1884/3000 train_loss:3.5580 train_time:538696ms step_avg:287.46ms
step:1885/3000 train_loss:3.7179 train_time:538982ms step_avg:287.46ms
step:1886/3000 train_loss:3.5252 train_time:539266ms step_avg:287.46ms
step:1887/3000 train_loss:3.4197 train_time:539551ms step_avg:287.45ms
step:1888/3000 train_loss:3.3908 train_time:539836ms step_avg:287.45ms
step:1889/3000 train_loss:3.5564 train_time:540123ms step_avg:287.45ms
step:1890/3000 train_loss:3.4341 train_time:540599ms step_avg:287.55ms
step:1891/3000 train_loss:3.4581 train_time:540884ms step_avg:287.55ms
step:1892/3000 train_loss:3.6251 train_time:541167ms step_avg:287.55ms
step:1893/3000 train_loss:3.4576 train_time:541453ms step_avg:287.55ms
step:1894/3000 train_loss:3.4057 train_time:541737ms step_avg:287.55ms
step:1895/3000 train_loss:3.4628 train_time:542023ms step_avg:287.55ms
step:1896/3000 train_loss:3.5492 train_time:542309ms step_avg:287.54ms
step:1897/3000 train_loss:3.5513 train_time:542593ms step_avg:287.54ms
step:1898/3000 train_loss:3.5465 train_time:542879ms step_avg:287.54ms
step:1899/3000 train_loss:3.5080 train_time:543165ms step_avg:287.54ms
step:1900/3000 train_loss:3.4650 train_time:543635ms step_avg:287.64ms
step:1901/3000 train_loss:3.5251 train_time:543922ms step_avg:287.64ms
step:1902/3000 train_loss:3.4624 train_time:544204ms step_avg:287.63ms
step:1903/3000 train_loss:3.4151 train_time:544489ms step_avg:287.63ms
step:1904/3000 train_loss:3.6251 train_time:544774ms step_avg:287.63ms
step:1905/3000 train_loss:3.5297 train_time:545061ms step_avg:287.63ms
step:1906/3000 train_loss:3.7019 train_time:545344ms step_avg:287.63ms
step:1907/3000 train_loss:3.5274 train_time:545628ms step_avg:287.63ms
step:1908/3000 train_loss:3.4155 train_time:545915ms step_avg:287.63ms
step:1909/3000 train_loss:3.5618 train_time:546200ms step_avg:287.63ms
step:1910/3000 train_loss:3.4296 train_time:546487ms step_avg:287.62ms
step:1911/3000 train_loss:3.4773 train_time:546771ms step_avg:287.62ms
step:1912/3000 train_loss:3.3680 train_time:547058ms step_avg:287.62ms
step:1913/3000 train_loss:3.6245 train_time:547343ms step_avg:287.62ms
step:1914/3000 train_loss:3.4446 train_time:547626ms step_avg:287.62ms
step:1915/3000 train_loss:3.6066 train_time:547912ms step_avg:287.62ms
step:1916/3000 train_loss:3.6191 train_time:548196ms step_avg:287.62ms
step:1917/3000 train_loss:3.3509 train_time:548484ms step_avg:287.62ms
step:1918/3000 train_loss:3.4704 train_time:548769ms step_avg:287.61ms
step:1919/3000 train_loss:3.5346 train_time:549055ms step_avg:287.61ms
step:1920/3000 train_loss:3.6296 train_time:549339ms step_avg:287.61ms
step:1921/3000 train_loss:3.5767 train_time:549624ms step_avg:287.61ms
step:1922/3000 train_loss:3.4762 train_time:549909ms step_avg:287.61ms
step:1923/3000 train_loss:3.4592 train_time:550195ms step_avg:287.61ms
step:1924/3000 train_loss:3.4603 train_time:550484ms step_avg:287.61ms
step:1925/3000 train_loss:3.5058 train_time:550769ms step_avg:287.61ms
step:1926/3000 train_loss:3.3413 train_time:551054ms step_avg:287.61ms
step:1927/3000 train_loss:3.3504 train_time:551339ms step_avg:287.60ms
step:1928/3000 train_loss:3.3841 train_time:551625ms step_avg:287.60ms
step:1929/3000 train_loss:3.5261 train_time:551910ms step_avg:287.60ms
step:1930/3000 train_loss:3.4853 train_time:552195ms step_avg:287.60ms
step:1931/3000 train_loss:3.5093 train_time:552482ms step_avg:287.60ms
step:1932/3000 train_loss:3.5163 train_time:552766ms step_avg:287.60ms
step:1933/3000 train_loss:3.4064 train_time:553051ms step_avg:287.60ms
step:1934/3000 train_loss:3.3735 train_time:553337ms step_avg:287.60ms
step:1935/3000 train_loss:3.7588 train_time:553624ms step_avg:287.60ms
step:1936/3000 train_loss:3.3645 train_time:553909ms step_avg:287.60ms
step:1937/3000 train_loss:3.4324 train_time:554192ms step_avg:287.59ms
step:1938/3000 train_loss:3.3732 train_time:554480ms step_avg:287.59ms
step:1939/3000 train_loss:3.5744 train_time:554765ms step_avg:287.59ms
step:1940/3000 train_loss:3.3706 train_time:555048ms step_avg:287.59ms
step:1941/3000 train_loss:3.4618 train_time:555335ms step_avg:287.59ms
step:1942/3000 train_loss:3.3640 train_time:555622ms step_avg:287.59ms
step:1943/3000 train_loss:3.4583 train_time:555907ms step_avg:287.59ms
step:1944/3000 train_loss:3.5124 train_time:556191ms step_avg:287.59ms
step:1945/3000 train_loss:3.4932 train_time:556478ms step_avg:287.59ms
step:1946/3000 train_loss:3.4206 train_time:556764ms step_avg:287.58ms
step:1947/3000 train_loss:3.5009 train_time:557048ms step_avg:287.58ms
step:1948/3000 train_loss:3.5307 train_time:557335ms step_avg:287.58ms
step:1949/3000 train_loss:3.4171 train_time:557623ms step_avg:287.58ms
step:1950/3000 train_loss:3.5164 train_time:557908ms step_avg:287.58ms
step:1951/3000 train_loss:3.5811 train_time:558194ms step_avg:287.58ms
step:1952/3000 train_loss:3.4108 train_time:558481ms step_avg:287.58ms
step:1953/3000 train_loss:3.6185 train_time:558766ms step_avg:287.58ms
step:1954/3000 train_loss:3.4899 train_time:559048ms step_avg:287.58ms
step:1955/3000 train_loss:3.5755 train_time:559333ms step_avg:287.58ms
step:1956/3000 train_loss:3.6358 train_time:559622ms step_avg:287.58ms
step:1957/3000 train_loss:3.5163 train_time:559908ms step_avg:287.57ms
step:1958/3000 train_loss:3.4860 train_time:560193ms step_avg:287.57ms
step:1959/3000 train_loss:3.5265 train_time:560481ms step_avg:287.57ms
step:1960/3000 train_loss:3.4163 train_time:560766ms step_avg:287.57ms
step:1961/3000 train_loss:3.4800 train_time:561048ms step_avg:287.57ms
step:1962/3000 train_loss:3.5503 train_time:561334ms step_avg:287.57ms
step:1963/3000 train_loss:3.6700 train_time:561621ms step_avg:287.57ms
step:1964/3000 train_loss:3.3987 train_time:561906ms step_avg:287.57ms
step:1965/3000 train_loss:3.3813 train_time:562189ms step_avg:287.56ms
step:1966/3000 train_loss:3.5705 train_time:562477ms step_avg:287.56ms
step:1967/3000 train_loss:3.4489 train_time:562765ms step_avg:287.56ms
step:1968/3000 train_loss:3.4676 train_time:563049ms step_avg:287.56ms
step:1969/3000 train_loss:3.4791 train_time:563333ms step_avg:287.56ms
step:1970/3000 train_loss:3.5457 train_time:563621ms step_avg:287.56ms
step:1971/3000 train_loss:3.5670 train_time:563905ms step_avg:287.56ms
step:1972/3000 train_loss:3.5400 train_time:564189ms step_avg:287.56ms
step:1973/3000 train_loss:3.4897 train_time:564477ms step_avg:287.56ms
step:1974/3000 train_loss:3.3976 train_time:564764ms step_avg:287.56ms
step:1975/3000 train_loss:3.4887 train_time:565048ms step_avg:287.56ms
step:1976/3000 train_loss:3.4163 train_time:565332ms step_avg:287.55ms
step:1977/3000 train_loss:3.4213 train_time:565622ms step_avg:287.56ms
step:1978/3000 train_loss:3.4172 train_time:565905ms step_avg:287.55ms
step:1979/3000 train_loss:3.4912 train_time:566188ms step_avg:287.55ms
step:1980/3000 train_loss:3.3427 train_time:566475ms step_avg:287.55ms
step:1981/3000 train_loss:3.6158 train_time:566763ms step_avg:287.55ms
step:1982/3000 train_loss:3.4566 train_time:567044ms step_avg:287.55ms
step:1983/3000 train_loss:3.4646 train_time:567327ms step_avg:287.55ms
step:1984/3000 train_loss:3.4692 train_time:567616ms step_avg:287.55ms
step:1985/3000 train_loss:3.5573 train_time:567904ms step_avg:287.55ms
step:1986/3000 train_loss:3.5943 train_time:568193ms step_avg:287.55ms
step:1987/3000 train_loss:3.7576 train_time:568473ms step_avg:287.54ms
step:1988/3000 train_loss:3.5850 train_time:568759ms step_avg:287.54ms
step:1989/3000 train_loss:3.5602 train_time:569045ms step_avg:287.54ms
step:1990/3000 train_loss:3.5389 train_time:569329ms step_avg:287.54ms
step:1991/3000 train_loss:3.7467 train_time:569617ms step_avg:287.54ms
step:1992/3000 train_loss:3.5070 train_time:569906ms step_avg:287.54ms
step:1993/3000 train_loss:3.4583 train_time:570188ms step_avg:287.54ms
step:1994/3000 train_loss:3.4398 train_time:570474ms step_avg:287.54ms
step:1995/3000 train_loss:3.5653 train_time:570760ms step_avg:287.54ms
step:1996/3000 train_loss:3.5833 train_time:571044ms step_avg:287.53ms
step:1997/3000 train_loss:3.6398 train_time:571329ms step_avg:287.53ms
step:1998/3000 train_loss:3.4488 train_time:571617ms step_avg:287.53ms
step:1999/3000 train_loss:3.5675 train_time:571903ms step_avg:287.53ms
step:2000/3000 train_loss:3.3953 train_time:572188ms step_avg:287.53ms
step:2000/3000 val_loss:3.4838 train_time:572188ms step_avg:287.53ms
step:2001/3000 train_loss:3.4010 train_time:572476ms step_avg:287.53ms
step:2002/3000 train_loss:3.4255 train_time:572764ms step_avg:287.53ms
step:2003/3000 train_loss:3.4007 train_time:573053ms step_avg:287.53ms
step:2004/3000 train_loss:3.4481 train_time:573334ms step_avg:287.53ms
step:2005/3000 train_loss:3.4798 train_time:573618ms step_avg:287.53ms
step:2006/3000 train_loss:3.3946 train_time:573910ms step_avg:287.53ms
step:2007/3000 train_loss:3.4155 train_time:574194ms step_avg:287.53ms
step:2008/3000 train_loss:3.4269 train_time:574478ms step_avg:287.53ms
step:2009/3000 train_loss:3.5413 train_time:574763ms step_avg:287.53ms
step:2010/3000 train_loss:3.3891 train_time:575051ms step_avg:287.53ms
step:2011/3000 train_loss:3.4787 train_time:575334ms step_avg:287.52ms
step:2012/3000 train_loss:3.4966 train_time:575619ms step_avg:287.52ms
step:2013/3000 train_loss:3.5103 train_time:575908ms step_avg:287.52ms
step:2014/3000 train_loss:3.5356 train_time:576194ms step_avg:287.52ms
step:2015/3000 train_loss:3.5341 train_time:576479ms step_avg:287.52ms
step:2016/3000 train_loss:4.0167 train_time:576766ms step_avg:287.52ms
step:2017/3000 train_loss:3.5019 train_time:577052ms step_avg:287.52ms
step:2018/3000 train_loss:3.4117 train_time:577335ms step_avg:287.52ms
step:2019/3000 train_loss:3.5032 train_time:577621ms step_avg:287.52ms
step:2020/3000 train_loss:3.4549 train_time:577909ms step_avg:287.52ms
step:2021/3000 train_loss:3.6567 train_time:578195ms step_avg:287.52ms
step:2022/3000 train_loss:3.4713 train_time:578479ms step_avg:287.51ms
step:2023/3000 train_loss:3.4249 train_time:578766ms step_avg:287.51ms
step:2024/3000 train_loss:3.4417 train_time:579053ms step_avg:287.51ms
step:2025/3000 train_loss:3.6375 train_time:579335ms step_avg:287.51ms
step:2026/3000 train_loss:3.5107 train_time:579622ms step_avg:287.51ms
step:2027/3000 train_loss:3.3685 train_time:579910ms step_avg:287.51ms
step:2028/3000 train_loss:3.4587 train_time:580194ms step_avg:287.51ms
step:2029/3000 train_loss:3.5124 train_time:580479ms step_avg:287.51ms
step:2030/3000 train_loss:3.4681 train_time:580766ms step_avg:287.51ms
step:2031/3000 train_loss:3.6166 train_time:581054ms step_avg:287.51ms
step:2032/3000 train_loss:3.5379 train_time:581337ms step_avg:287.51ms
step:2033/3000 train_loss:3.5301 train_time:581623ms step_avg:287.51ms
step:2034/3000 train_loss:3.6026 train_time:581911ms step_avg:287.51ms
step:2035/3000 train_loss:3.4937 train_time:582195ms step_avg:287.50ms
step:2036/3000 train_loss:3.5854 train_time:582479ms step_avg:287.50ms
step:2037/3000 train_loss:3.4845 train_time:582765ms step_avg:287.50ms
step:2038/3000 train_loss:3.9624 train_time:583052ms step_avg:287.50ms
step:2039/3000 train_loss:3.6548 train_time:583336ms step_avg:287.50ms
step:2040/3000 train_loss:3.3849 train_time:583620ms step_avg:287.50ms
step:2041/3000 train_loss:3.3449 train_time:583909ms step_avg:287.50ms
step:2042/3000 train_loss:3.5470 train_time:584195ms step_avg:287.50ms
step:2043/3000 train_loss:3.5224 train_time:584479ms step_avg:287.50ms
step:2044/3000 train_loss:3.4631 train_time:584767ms step_avg:287.50ms
step:2045/3000 train_loss:3.4299 train_time:585054ms step_avg:287.50ms
step:2046/3000 train_loss:3.6181 train_time:585338ms step_avg:287.49ms
step:2047/3000 train_loss:3.5517 train_time:585623ms step_avg:287.49ms
step:2048/3000 train_loss:4.0267 train_time:585912ms step_avg:287.49ms
step:2049/3000 train_loss:3.5112 train_time:586197ms step_avg:287.49ms
step:2050/3000 train_loss:3.4615 train_time:586479ms step_avg:287.49ms
step:2051/3000 train_loss:3.5612 train_time:586767ms step_avg:287.49ms
step:2052/3000 train_loss:3.4495 train_time:587053ms step_avg:287.49ms
step:2053/3000 train_loss:3.4198 train_time:587340ms step_avg:287.49ms
step:2054/3000 train_loss:3.4352 train_time:587626ms step_avg:287.49ms
step:2055/3000 train_loss:3.6006 train_time:587913ms step_avg:287.49ms
step:2056/3000 train_loss:3.4253 train_time:588198ms step_avg:287.49ms
step:2057/3000 train_loss:3.3737 train_time:588485ms step_avg:287.49ms
step:2058/3000 train_loss:3.3830 train_time:588772ms step_avg:287.49ms
step:2059/3000 train_loss:3.4745 train_time:589055ms step_avg:287.48ms
step:2060/3000 train_loss:3.4460 train_time:589337ms step_avg:287.48ms
step:2061/3000 train_loss:3.2338 train_time:589626ms step_avg:287.48ms
step:2062/3000 train_loss:3.4573 train_time:589917ms step_avg:287.48ms
step:2063/3000 train_loss:3.7483 train_time:590200ms step_avg:287.48ms
step:2064/3000 train_loss:3.2783 train_time:590486ms step_avg:287.48ms
step:2065/3000 train_loss:3.5502 train_time:590774ms step_avg:287.48ms
step:2066/3000 train_loss:3.4014 train_time:591058ms step_avg:287.48ms
step:2067/3000 train_loss:3.5041 train_time:591345ms step_avg:287.48ms
step:2068/3000 train_loss:3.3552 train_time:591633ms step_avg:287.48ms
step:2069/3000 train_loss:3.4959 train_time:591917ms step_avg:287.48ms
step:2070/3000 train_loss:3.5132 train_time:592203ms step_avg:287.48ms
step:2071/3000 train_loss:3.0563 train_time:592489ms step_avg:287.48ms
step:2072/3000 train_loss:3.6151 train_time:592776ms step_avg:287.48ms
step:2073/3000 train_loss:3.5254 train_time:593062ms step_avg:287.48ms
step:2074/3000 train_loss:3.4753 train_time:593348ms step_avg:287.47ms
step:2075/3000 train_loss:3.3531 train_time:593633ms step_avg:287.47ms
step:2076/3000 train_loss:3.5584 train_time:593918ms step_avg:287.47ms
step:2077/3000 train_loss:3.4759 train_time:594206ms step_avg:287.47ms
step:2078/3000 train_loss:3.5056 train_time:594491ms step_avg:287.47ms
step:2079/3000 train_loss:3.4974 train_time:594970ms step_avg:287.56ms
step:2080/3000 train_loss:3.3907 train_time:595254ms step_avg:287.56ms
step:2081/3000 train_loss:3.4459 train_time:595537ms step_avg:287.56ms
step:2082/3000 train_loss:3.3181 train_time:595824ms step_avg:287.56ms
step:2083/3000 train_loss:3.3626 train_time:596111ms step_avg:287.56ms
step:2084/3000 train_loss:3.5625 train_time:596396ms step_avg:287.56ms
step:2085/3000 train_loss:3.4585 train_time:596679ms step_avg:287.56ms
step:2086/3000 train_loss:3.4519 train_time:596965ms step_avg:287.56ms
step:2087/3000 train_loss:3.4983 train_time:597252ms step_avg:287.56ms
step:2088/3000 train_loss:3.4557 train_time:597535ms step_avg:287.55ms
step:2089/3000 train_loss:3.4661 train_time:597819ms step_avg:287.55ms
step:2090/3000 train_loss:3.4668 train_time:598294ms step_avg:287.64ms
step:2091/3000 train_loss:3.5789 train_time:598575ms step_avg:287.64ms
step:2092/3000 train_loss:3.4741 train_time:598859ms step_avg:287.64ms
step:2093/3000 train_loss:3.4058 train_time:599145ms step_avg:287.64ms
step:2094/3000 train_loss:3.4694 train_time:599430ms step_avg:287.63ms
step:2095/3000 train_loss:3.5036 train_time:599716ms step_avg:287.63ms
step:2096/3000 train_loss:3.4482 train_time:600001ms step_avg:287.63ms
step:2097/3000 train_loss:3.5124 train_time:600285ms step_avg:287.63ms
step:2098/3000 train_loss:3.6682 train_time:600572ms step_avg:287.63ms
step:2099/3000 train_loss:3.4266 train_time:600857ms step_avg:287.63ms
step:2100/3000 train_loss:3.4284 train_time:601143ms step_avg:287.63ms
step:2101/3000 train_loss:3.5468 train_time:601426ms step_avg:287.63ms
step:2102/3000 train_loss:3.4668 train_time:601712ms step_avg:287.63ms
step:2103/3000 train_loss:3.5714 train_time:601997ms step_avg:287.62ms
step:2104/3000 train_loss:3.4339 train_time:602281ms step_avg:287.62ms
step:2105/3000 train_loss:3.5395 train_time:602568ms step_avg:287.62ms
step:2106/3000 train_loss:3.2990 train_time:602853ms step_avg:287.62ms
step:2107/3000 train_loss:3.5144 train_time:603137ms step_avg:287.62ms
step:2108/3000 train_loss:3.4896 train_time:603423ms step_avg:287.62ms
step:2109/3000 train_loss:3.5325 train_time:603710ms step_avg:287.62ms
step:2110/3000 train_loss:3.4403 train_time:603995ms step_avg:287.62ms
step:2111/3000 train_loss:3.4659 train_time:604279ms step_avg:287.61ms
step:2112/3000 train_loss:3.5892 train_time:604565ms step_avg:287.61ms
step:2113/3000 train_loss:3.4879 train_time:604852ms step_avg:287.61ms
step:2114/3000 train_loss:3.6174 train_time:605135ms step_avg:287.61ms
step:2115/3000 train_loss:3.3276 train_time:605421ms step_avg:287.61ms
step:2116/3000 train_loss:3.4609 train_time:605709ms step_avg:287.61ms
step:2117/3000 train_loss:3.7741 train_time:605993ms step_avg:287.61ms
step:2118/3000 train_loss:3.4646 train_time:606278ms step_avg:287.61ms
step:2119/3000 train_loss:3.4877 train_time:606564ms step_avg:287.61ms
step:2120/3000 train_loss:3.5069 train_time:606852ms step_avg:287.61ms
step:2121/3000 train_loss:3.4339 train_time:607135ms step_avg:287.61ms
step:2122/3000 train_loss:3.4449 train_time:607419ms step_avg:287.60ms
step:2123/3000 train_loss:3.8537 train_time:607707ms step_avg:287.60ms
step:2124/3000 train_loss:3.3007 train_time:607994ms step_avg:287.60ms
step:2125/3000 train_loss:3.6731 train_time:608279ms step_avg:287.60ms
step:2125/3000 val_loss:3.4617 train_time:608279ms step_avg:287.60ms
step:2126/3000 train_loss:3.4308 train_time:608567ms step_avg:287.60ms
step:2127/3000 train_loss:3.4400 train_time:608855ms step_avg:287.60ms
step:2128/3000 train_loss:3.6223 train_time:609143ms step_avg:287.60ms
step:2129/3000 train_loss:3.3739 train_time:609426ms step_avg:287.60ms
step:2130/3000 train_loss:3.4841 train_time:609710ms step_avg:287.60ms
step:2131/3000 train_loss:3.3650 train_time:609996ms step_avg:287.60ms
step:2132/3000 train_loss:3.3343 train_time:610282ms step_avg:287.60ms
step:2133/3000 train_loss:3.4833 train_time:610570ms step_avg:287.60ms
step:2134/3000 train_loss:3.5593 train_time:610853ms step_avg:287.60ms
step:2135/3000 train_loss:3.2966 train_time:611139ms step_avg:287.59ms
step:2136/3000 train_loss:3.4414 train_time:611423ms step_avg:287.59ms
step:2137/3000 train_loss:3.3253 train_time:611710ms step_avg:287.59ms
step:2138/3000 train_loss:3.5725 train_time:611994ms step_avg:287.59ms
step:2139/3000 train_loss:3.4806 train_time:612281ms step_avg:287.59ms
step:2140/3000 train_loss:3.4463 train_time:612568ms step_avg:287.59ms
step:2141/3000 train_loss:3.3920 train_time:612852ms step_avg:287.59ms
step:2142/3000 train_loss:3.3009 train_time:613137ms step_avg:287.59ms
step:2143/3000 train_loss:3.4521 train_time:613422ms step_avg:287.59ms
step:2144/3000 train_loss:3.4848 train_time:613709ms step_avg:287.59ms
step:2145/3000 train_loss:3.4714 train_time:613994ms step_avg:287.58ms
step:2146/3000 train_loss:3.4950 train_time:614276ms step_avg:287.58ms
step:2147/3000 train_loss:3.5339 train_time:614563ms step_avg:287.58ms
step:2148/3000 train_loss:3.3991 train_time:614850ms step_avg:287.58ms
step:2149/3000 train_loss:3.3910 train_time:615134ms step_avg:287.58ms
step:2150/3000 train_loss:3.4176 train_time:615419ms step_avg:287.58ms
step:2151/3000 train_loss:3.5920 train_time:615707ms step_avg:287.58ms
step:2152/3000 train_loss:3.4502 train_time:615991ms step_avg:287.58ms
step:2153/3000 train_loss:3.4295 train_time:616275ms step_avg:287.58ms
step:2154/3000 train_loss:3.3329 train_time:616562ms step_avg:287.58ms
step:2155/3000 train_loss:3.6286 train_time:616851ms step_avg:287.58ms
step:2156/3000 train_loss:3.5458 train_time:617136ms step_avg:287.57ms
step:2157/3000 train_loss:3.5128 train_time:617420ms step_avg:287.57ms
step:2158/3000 train_loss:3.4514 train_time:617708ms step_avg:287.57ms
step:2159/3000 train_loss:3.5661 train_time:617992ms step_avg:287.57ms
step:2160/3000 train_loss:3.4152 train_time:618276ms step_avg:287.57ms
step:2161/3000 train_loss:3.4120 train_time:618564ms step_avg:287.57ms
step:2162/3000 train_loss:3.3025 train_time:618850ms step_avg:287.57ms
step:2163/3000 train_loss:3.4124 train_time:619133ms step_avg:287.57ms
step:2164/3000 train_loss:3.3620 train_time:619417ms step_avg:287.57ms
step:2165/3000 train_loss:3.3396 train_time:619705ms step_avg:287.57ms
step:2166/3000 train_loss:3.5376 train_time:619990ms step_avg:287.57ms
step:2167/3000 train_loss:3.4471 train_time:620275ms step_avg:287.56ms
step:2168/3000 train_loss:3.4908 train_time:620560ms step_avg:287.56ms
step:2169/3000 train_loss:3.5133 train_time:620847ms step_avg:287.56ms
step:2170/3000 train_loss:3.3500 train_time:621130ms step_avg:287.56ms
step:2171/3000 train_loss:3.5020 train_time:621414ms step_avg:287.56ms
step:2172/3000 train_loss:3.4043 train_time:621702ms step_avg:287.56ms
step:2173/3000 train_loss:3.4651 train_time:621988ms step_avg:287.56ms
step:2174/3000 train_loss:3.4697 train_time:622273ms step_avg:287.56ms
step:2175/3000 train_loss:3.4277 train_time:622561ms step_avg:287.56ms
step:2176/3000 train_loss:3.4201 train_time:622846ms step_avg:287.56ms
step:2177/3000 train_loss:3.5048 train_time:623130ms step_avg:287.55ms
step:2178/3000 train_loss:3.5445 train_time:623413ms step_avg:287.55ms
step:2179/3000 train_loss:3.5085 train_time:623702ms step_avg:287.55ms
step:2180/3000 train_loss:3.4003 train_time:623988ms step_avg:287.55ms
step:2181/3000 train_loss:3.4744 train_time:624272ms step_avg:287.55ms
step:2182/3000 train_loss:3.5090 train_time:624557ms step_avg:287.55ms
step:2183/3000 train_loss:3.4989 train_time:624845ms step_avg:287.55ms
step:2184/3000 train_loss:3.4337 train_time:625130ms step_avg:287.55ms
step:2185/3000 train_loss:3.2993 train_time:625414ms step_avg:287.55ms
step:2186/3000 train_loss:3.7316 train_time:625701ms step_avg:287.55ms
step:2187/3000 train_loss:3.4623 train_time:625987ms step_avg:287.55ms
step:2188/3000 train_loss:3.3136 train_time:626272ms step_avg:287.54ms
step:2189/3000 train_loss:3.5531 train_time:626557ms step_avg:287.54ms
step:2190/3000 train_loss:3.4914 train_time:626843ms step_avg:287.54ms
step:2191/3000 train_loss:3.6567 train_time:627128ms step_avg:287.54ms
step:2192/3000 train_loss:3.4375 train_time:627412ms step_avg:287.54ms
step:2193/3000 train_loss:3.2667 train_time:627699ms step_avg:287.54ms
step:2194/3000 train_loss:3.5112 train_time:627984ms step_avg:287.54ms
step:2195/3000 train_loss:3.3807 train_time:628270ms step_avg:287.54ms
step:2196/3000 train_loss:3.3758 train_time:628556ms step_avg:287.54ms
step:2197/3000 train_loss:3.2935 train_time:628842ms step_avg:287.54ms
step:2198/3000 train_loss:3.4267 train_time:629127ms step_avg:287.54ms
step:2199/3000 train_loss:3.6078 train_time:629410ms step_avg:287.53ms
step:2200/3000 train_loss:3.4369 train_time:629695ms step_avg:287.53ms
step:2201/3000 train_loss:3.3295 train_time:629981ms step_avg:287.53ms
step:2202/3000 train_loss:3.3533 train_time:630268ms step_avg:287.53ms
step:2203/3000 train_loss:3.4568 train_time:630553ms step_avg:287.53ms
step:2204/3000 train_loss:3.3043 train_time:630838ms step_avg:287.53ms
step:2205/3000 train_loss:3.4272 train_time:631123ms step_avg:287.53ms
step:2206/3000 train_loss:3.4073 train_time:631411ms step_avg:287.53ms
step:2207/3000 train_loss:3.2236 train_time:631695ms step_avg:287.53ms
step:2208/3000 train_loss:3.4648 train_time:631982ms step_avg:287.53ms
step:2209/3000 train_loss:3.5148 train_time:632270ms step_avg:287.53ms
step:2210/3000 train_loss:3.5323 train_time:632555ms step_avg:287.53ms
step:2211/3000 train_loss:3.4762 train_time:632842ms step_avg:287.52ms
step:2212/3000 train_loss:3.5366 train_time:633126ms step_avg:287.52ms
step:2213/3000 train_loss:3.5001 train_time:633411ms step_avg:287.52ms
step:2214/3000 train_loss:3.5150 train_time:633697ms step_avg:287.52ms
step:2215/3000 train_loss:3.4130 train_time:633981ms step_avg:287.52ms
step:2216/3000 train_loss:3.5440 train_time:634268ms step_avg:287.52ms
step:2217/3000 train_loss:3.3880 train_time:634552ms step_avg:287.52ms
step:2218/3000 train_loss:3.4931 train_time:634836ms step_avg:287.52ms
step:2219/3000 train_loss:3.5707 train_time:635122ms step_avg:287.52ms
step:2220/3000 train_loss:3.4883 train_time:635409ms step_avg:287.52ms
step:2221/3000 train_loss:3.3350 train_time:635693ms step_avg:287.51ms
step:2222/3000 train_loss:3.5062 train_time:635977ms step_avg:287.51ms
step:2223/3000 train_loss:3.4452 train_time:636264ms step_avg:287.51ms
step:2224/3000 train_loss:3.4138 train_time:636550ms step_avg:287.51ms
step:2225/3000 train_loss:3.5470 train_time:636834ms step_avg:287.51ms
step:2226/3000 train_loss:3.4721 train_time:637121ms step_avg:287.51ms
step:2227/3000 train_loss:3.8196 train_time:637409ms step_avg:287.51ms
step:2228/3000 train_loss:3.4540 train_time:637694ms step_avg:287.51ms
step:2229/3000 train_loss:3.5154 train_time:637977ms step_avg:287.51ms
step:2230/3000 train_loss:3.3695 train_time:638264ms step_avg:287.51ms
step:2231/3000 train_loss:3.4306 train_time:638551ms step_avg:287.51ms
step:2232/3000 train_loss:3.4228 train_time:638836ms step_avg:287.50ms
step:2233/3000 train_loss:3.4066 train_time:639121ms step_avg:287.50ms
step:2234/3000 train_loss:4.0506 train_time:639408ms step_avg:287.50ms
step:2235/3000 train_loss:3.4733 train_time:639694ms step_avg:287.50ms
step:2236/3000 train_loss:3.4172 train_time:639979ms step_avg:287.50ms
step:2237/3000 train_loss:3.4424 train_time:640266ms step_avg:287.50ms
step:2238/3000 train_loss:3.4106 train_time:640551ms step_avg:287.50ms
step:2239/3000 train_loss:3.3716 train_time:640835ms step_avg:287.50ms
step:2240/3000 train_loss:3.5982 train_time:641120ms step_avg:287.50ms
step:2241/3000 train_loss:3.4057 train_time:641407ms step_avg:287.50ms
step:2242/3000 train_loss:3.6521 train_time:641692ms step_avg:287.50ms
step:2243/3000 train_loss:3.4757 train_time:641978ms step_avg:287.50ms
step:2244/3000 train_loss:3.3989 train_time:642266ms step_avg:287.50ms
step:2245/3000 train_loss:3.4337 train_time:642552ms step_avg:287.50ms
step:2246/3000 train_loss:3.3739 train_time:642836ms step_avg:287.49ms
step:2247/3000 train_loss:3.5086 train_time:643122ms step_avg:287.49ms
step:2248/3000 train_loss:3.4756 train_time:643409ms step_avg:287.49ms
step:2249/3000 train_loss:3.3735 train_time:643695ms step_avg:287.49ms
step:2250/3000 train_loss:3.8840 train_time:643980ms step_avg:287.49ms
step:2250/3000 val_loss:3.4434 train_time:643980ms step_avg:287.49ms
step:2251/3000 train_loss:3.4259 train_time:644269ms step_avg:287.49ms
step:2252/3000 train_loss:3.5362 train_time:644559ms step_avg:287.49ms
step:2253/3000 train_loss:3.3274 train_time:644845ms step_avg:287.49ms
step:2254/3000 train_loss:3.3354 train_time:645129ms step_avg:287.49ms
step:2255/3000 train_loss:3.3900 train_time:645413ms step_avg:287.49ms
step:2256/3000 train_loss:3.3426 train_time:645700ms step_avg:287.49ms
step:2257/3000 train_loss:3.3898 train_time:645985ms step_avg:287.49ms
step:2258/3000 train_loss:3.3812 train_time:646270ms step_avg:287.49ms
step:2259/3000 train_loss:3.3588 train_time:646556ms step_avg:287.49ms
step:2260/3000 train_loss:3.4663 train_time:646843ms step_avg:287.49ms
step:2261/3000 train_loss:3.3774 train_time:647126ms step_avg:287.48ms
step:2262/3000 train_loss:3.3864 train_time:647409ms step_avg:287.48ms
step:2263/3000 train_loss:3.6577 train_time:647696ms step_avg:287.48ms
step:2264/3000 train_loss:3.5214 train_time:647982ms step_avg:287.48ms
step:2265/3000 train_loss:3.4638 train_time:648267ms step_avg:287.48ms
step:2266/3000 train_loss:3.3654 train_time:648551ms step_avg:287.48ms
step:2267/3000 train_loss:3.4526 train_time:648837ms step_avg:287.48ms
step:2268/3000 train_loss:3.0705 train_time:649307ms step_avg:287.56ms
step:2269/3000 train_loss:3.3878 train_time:649591ms step_avg:287.56ms
step:2270/3000 train_loss:3.4109 train_time:649875ms step_avg:287.56ms
step:2271/3000 train_loss:3.4484 train_time:650162ms step_avg:287.56ms
step:2272/3000 train_loss:3.3865 train_time:650446ms step_avg:287.55ms
step:2273/3000 train_loss:3.3283 train_time:650729ms step_avg:287.55ms
step:2274/3000 train_loss:3.5267 train_time:651016ms step_avg:287.55ms
step:2275/3000 train_loss:3.3320 train_time:651303ms step_avg:287.55ms
step:2276/3000 train_loss:3.4487 train_time:651589ms step_avg:287.55ms
step:2277/3000 train_loss:3.4020 train_time:651875ms step_avg:287.55ms
step:2278/3000 train_loss:3.3760 train_time:652162ms step_avg:287.55ms
step:2279/3000 train_loss:3.4440 train_time:652445ms step_avg:287.55ms
step:2280/3000 train_loss:3.4025 train_time:652920ms step_avg:287.63ms
step:2281/3000 train_loss:3.4585 train_time:653204ms step_avg:287.63ms
step:2282/3000 train_loss:3.5212 train_time:653489ms step_avg:287.63ms
step:2283/3000 train_loss:3.5015 train_time:653771ms step_avg:287.62ms
step:2284/3000 train_loss:3.5299 train_time:654057ms step_avg:287.62ms
step:2285/3000 train_loss:3.5398 train_time:654344ms step_avg:287.62ms
step:2286/3000 train_loss:3.4968 train_time:654627ms step_avg:287.62ms
step:2287/3000 train_loss:3.5429 train_time:654910ms step_avg:287.62ms
step:2288/3000 train_loss:3.4362 train_time:655200ms step_avg:287.62ms
step:2289/3000 train_loss:3.4728 train_time:655484ms step_avg:287.62ms
step:2290/3000 train_loss:3.4445 train_time:655768ms step_avg:287.62ms
step:2291/3000 train_loss:3.3510 train_time:656053ms step_avg:287.62ms
step:2292/3000 train_loss:3.4048 train_time:656341ms step_avg:287.62ms
step:2293/3000 train_loss:3.6138 train_time:656627ms step_avg:287.62ms
step:2294/3000 train_loss:3.3924 train_time:656909ms step_avg:287.61ms
step:2295/3000 train_loss:3.3833 train_time:657197ms step_avg:287.61ms
step:2296/3000 train_loss:3.5510 train_time:657484ms step_avg:287.61ms
step:2297/3000 train_loss:3.3181 train_time:657769ms step_avg:287.61ms
step:2298/3000 train_loss:3.4515 train_time:658054ms step_avg:287.61ms
step:2299/3000 train_loss:3.4077 train_time:658341ms step_avg:287.61ms
step:2300/3000 train_loss:3.7626 train_time:658625ms step_avg:287.61ms
step:2301/3000 train_loss:3.5637 train_time:658910ms step_avg:287.61ms
step:2302/3000 train_loss:3.2939 train_time:659197ms step_avg:287.61ms
step:2303/3000 train_loss:3.3191 train_time:659483ms step_avg:287.61ms
step:2304/3000 train_loss:3.2692 train_time:659768ms step_avg:287.61ms
step:2305/3000 train_loss:3.3433 train_time:660052ms step_avg:287.60ms
step:2306/3000 train_loss:3.7270 train_time:660340ms step_avg:287.60ms
step:2307/3000 train_loss:3.4509 train_time:660624ms step_avg:287.60ms
step:2308/3000 train_loss:3.3613 train_time:660908ms step_avg:287.60ms
step:2309/3000 train_loss:3.4317 train_time:661195ms step_avg:287.60ms
step:2310/3000 train_loss:3.2754 train_time:661482ms step_avg:287.60ms
step:2311/3000 train_loss:3.3828 train_time:661767ms step_avg:287.60ms
step:2312/3000 train_loss:3.4351 train_time:662052ms step_avg:287.60ms
step:2313/3000 train_loss:3.4561 train_time:662338ms step_avg:287.60ms
step:2314/3000 train_loss:3.5721 train_time:662623ms step_avg:287.60ms
step:2315/3000 train_loss:3.4003 train_time:662908ms step_avg:287.60ms
step:2316/3000 train_loss:3.3973 train_time:663193ms step_avg:287.59ms
step:2317/3000 train_loss:3.3806 train_time:663479ms step_avg:287.59ms
step:2318/3000 train_loss:3.6309 train_time:663766ms step_avg:287.59ms
step:2319/3000 train_loss:3.4207 train_time:664049ms step_avg:287.59ms
step:2320/3000 train_loss:3.4062 train_time:664335ms step_avg:287.59ms
step:2321/3000 train_loss:3.4729 train_time:664620ms step_avg:287.59ms
step:2322/3000 train_loss:3.3914 train_time:664906ms step_avg:287.59ms
step:2323/3000 train_loss:3.4118 train_time:665191ms step_avg:287.59ms
step:2324/3000 train_loss:3.5513 train_time:665477ms step_avg:287.59ms
step:2325/3000 train_loss:3.4485 train_time:665765ms step_avg:287.59ms
step:2326/3000 train_loss:3.4836 train_time:666050ms step_avg:287.59ms
step:2327/3000 train_loss:3.4153 train_time:666336ms step_avg:287.59ms
step:2328/3000 train_loss:3.3574 train_time:666620ms step_avg:287.58ms
step:2329/3000 train_loss:3.4873 train_time:666906ms step_avg:287.58ms
step:2330/3000 train_loss:3.3248 train_time:667192ms step_avg:287.58ms
step:2331/3000 train_loss:3.3857 train_time:667477ms step_avg:287.58ms
step:2332/3000 train_loss:3.7193 train_time:667765ms step_avg:287.58ms
step:2333/3000 train_loss:3.3847 train_time:668049ms step_avg:287.58ms
step:2334/3000 train_loss:3.3789 train_time:668335ms step_avg:287.58ms
step:2335/3000 train_loss:3.4937 train_time:668619ms step_avg:287.58ms
step:2336/3000 train_loss:3.4902 train_time:668906ms step_avg:287.58ms
step:2337/3000 train_loss:3.5110 train_time:669191ms step_avg:287.58ms
step:2338/3000 train_loss:3.5366 train_time:669476ms step_avg:287.58ms
step:2339/3000 train_loss:3.5460 train_time:669763ms step_avg:287.58ms
step:2340/3000 train_loss:3.3956 train_time:670047ms step_avg:287.57ms
step:2341/3000 train_loss:3.5290 train_time:670332ms step_avg:287.57ms
step:2342/3000 train_loss:3.5258 train_time:670619ms step_avg:287.57ms
step:2343/3000 train_loss:3.4369 train_time:670905ms step_avg:287.57ms
step:2344/3000 train_loss:3.4092 train_time:671191ms step_avg:287.57ms
step:2345/3000 train_loss:3.4736 train_time:671476ms step_avg:287.57ms
step:2346/3000 train_loss:3.7296 train_time:671763ms step_avg:287.57ms
step:2347/3000 train_loss:3.3568 train_time:672048ms step_avg:287.57ms
step:2348/3000 train_loss:3.1463 train_time:672333ms step_avg:287.57ms
step:2349/3000 train_loss:3.3951 train_time:672619ms step_avg:287.57ms
step:2350/3000 train_loss:3.4310 train_time:672906ms step_avg:287.57ms
step:2351/3000 train_loss:3.3586 train_time:673191ms step_avg:287.57ms
step:2352/3000 train_loss:3.3918 train_time:673476ms step_avg:287.56ms
step:2353/3000 train_loss:3.4264 train_time:673763ms step_avg:287.56ms
step:2354/3000 train_loss:3.3770 train_time:674047ms step_avg:287.56ms
step:2355/3000 train_loss:3.3537 train_time:674333ms step_avg:287.56ms
step:2356/3000 train_loss:3.5696 train_time:674620ms step_avg:287.56ms
step:2357/3000 train_loss:3.4446 train_time:674907ms step_avg:287.56ms
step:2358/3000 train_loss:3.4789 train_time:675193ms step_avg:287.56ms
step:2359/3000 train_loss:3.5251 train_time:675477ms step_avg:287.56ms
step:2360/3000 train_loss:3.5582 train_time:675764ms step_avg:287.56ms
step:2361/3000 train_loss:3.4295 train_time:676049ms step_avg:287.56ms
step:2362/3000 train_loss:3.5577 train_time:676335ms step_avg:287.56ms
step:2363/3000 train_loss:3.3769 train_time:676620ms step_avg:287.56ms
step:2364/3000 train_loss:3.4730 train_time:676907ms step_avg:287.56ms
step:2365/3000 train_loss:3.2339 train_time:677193ms step_avg:287.56ms
step:2366/3000 train_loss:3.3828 train_time:677478ms step_avg:287.55ms
step:2367/3000 train_loss:3.3872 train_time:677765ms step_avg:287.55ms
step:2368/3000 train_loss:3.3133 train_time:678049ms step_avg:287.55ms
step:2369/3000 train_loss:3.4831 train_time:678334ms step_avg:287.55ms
step:2370/3000 train_loss:3.3781 train_time:678621ms step_avg:287.55ms
step:2371/3000 train_loss:3.4925 train_time:678908ms step_avg:287.55ms
step:2372/3000 train_loss:3.5548 train_time:679193ms step_avg:287.55ms
step:2373/3000 train_loss:3.4774 train_time:679477ms step_avg:287.55ms
step:2374/3000 train_loss:3.3635 train_time:679764ms step_avg:287.55ms
step:2375/3000 train_loss:3.4079 train_time:680049ms step_avg:287.55ms
step:2375/3000 val_loss:3.4239 train_time:680050ms step_avg:287.55ms
step:2376/3000 train_loss:3.3143 train_time:680338ms step_avg:287.55ms
step:2377/3000 train_loss:3.5779 train_time:680628ms step_avg:287.55ms
step:2378/3000 train_loss:3.4005 train_time:680913ms step_avg:287.55ms
step:2379/3000 train_loss:3.4623 train_time:681197ms step_avg:287.55ms
step:2380/3000 train_loss:3.2981 train_time:681483ms step_avg:287.55ms
step:2381/3000 train_loss:3.4191 train_time:681768ms step_avg:287.54ms
step:2382/3000 train_loss:3.3669 train_time:682056ms step_avg:287.54ms
step:2383/3000 train_loss:3.3774 train_time:682341ms step_avg:287.54ms
step:2384/3000 train_loss:3.6871 train_time:682626ms step_avg:287.54ms
step:2385/3000 train_loss:3.4375 train_time:682911ms step_avg:287.54ms
step:2386/3000 train_loss:3.5158 train_time:683197ms step_avg:287.54ms
step:2387/3000 train_loss:3.3240 train_time:683482ms step_avg:287.54ms
step:2388/3000 train_loss:3.4045 train_time:683767ms step_avg:287.54ms
step:2389/3000 train_loss:3.3713 train_time:684054ms step_avg:287.54ms
step:2390/3000 train_loss:3.5081 train_time:684339ms step_avg:287.54ms
step:2391/3000 train_loss:3.3859 train_time:684623ms step_avg:287.54ms
step:2392/3000 train_loss:3.4254 train_time:684909ms step_avg:287.54ms
step:2393/3000 train_loss:3.5105 train_time:685198ms step_avg:287.54ms
step:2394/3000 train_loss:3.5355 train_time:685483ms step_avg:287.53ms
step:2395/3000 train_loss:3.4492 train_time:685766ms step_avg:287.53ms
step:2396/3000 train_loss:3.4905 train_time:686053ms step_avg:287.53ms
step:2397/3000 train_loss:3.4443 train_time:686338ms step_avg:287.53ms
step:2398/3000 train_loss:3.4911 train_time:686622ms step_avg:287.53ms
step:2399/3000 train_loss:3.0136 train_time:686908ms step_avg:287.53ms
step:2400/3000 train_loss:3.2311 train_time:687195ms step_avg:287.53ms
step:2401/3000 train_loss:3.3662 train_time:687480ms step_avg:287.53ms
step:2402/3000 train_loss:3.2254 train_time:687762ms step_avg:287.53ms
step:2403/3000 train_loss:3.4406 train_time:688049ms step_avg:287.53ms
step:2404/3000 train_loss:3.4555 train_time:688337ms step_avg:287.53ms
step:2405/3000 train_loss:3.3594 train_time:688621ms step_avg:287.52ms
step:2406/3000 train_loss:3.3547 train_time:688905ms step_avg:287.52ms
step:2407/3000 train_loss:3.6678 train_time:689193ms step_avg:287.52ms
step:2408/3000 train_loss:3.4195 train_time:689478ms step_avg:287.52ms
step:2409/3000 train_loss:3.4671 train_time:689762ms step_avg:287.52ms
step:2410/3000 train_loss:3.5997 train_time:690048ms step_avg:287.52ms
step:2411/3000 train_loss:3.4054 train_time:690336ms step_avg:287.52ms
step:2412/3000 train_loss:3.3683 train_time:690619ms step_avg:287.52ms
step:2413/3000 train_loss:3.3420 train_time:690904ms step_avg:287.52ms
step:2414/3000 train_loss:3.3220 train_time:691192ms step_avg:287.52ms
step:2415/3000 train_loss:3.3773 train_time:691478ms step_avg:287.52ms
step:2416/3000 train_loss:3.3885 train_time:691762ms step_avg:287.52ms
step:2417/3000 train_loss:3.3932 train_time:692049ms step_avg:287.52ms
step:2418/3000 train_loss:3.4469 train_time:692334ms step_avg:287.51ms
step:2419/3000 train_loss:3.4142 train_time:692620ms step_avg:287.51ms
step:2420/3000 train_loss:3.4001 train_time:692902ms step_avg:287.51ms
step:2421/3000 train_loss:3.3568 train_time:693191ms step_avg:287.51ms
step:2422/3000 train_loss:3.4166 train_time:693478ms step_avg:287.51ms
step:2423/3000 train_loss:3.4509 train_time:693761ms step_avg:287.51ms
step:2424/3000 train_loss:3.4747 train_time:694049ms step_avg:287.51ms
step:2425/3000 train_loss:3.3860 train_time:694335ms step_avg:287.51ms
step:2426/3000 train_loss:3.3700 train_time:694618ms step_avg:287.51ms
step:2427/3000 train_loss:3.4043 train_time:694902ms step_avg:287.51ms
step:2428/3000 train_loss:3.5446 train_time:695190ms step_avg:287.51ms
step:2429/3000 train_loss:3.3983 train_time:695476ms step_avg:287.51ms
step:2430/3000 train_loss:3.4975 train_time:695760ms step_avg:287.50ms
step:2431/3000 train_loss:3.7107 train_time:696045ms step_avg:287.50ms
step:2432/3000 train_loss:3.2887 train_time:696331ms step_avg:287.50ms
step:2433/3000 train_loss:3.5423 train_time:696617ms step_avg:287.50ms
step:2434/3000 train_loss:3.5948 train_time:696901ms step_avg:287.50ms
step:2435/3000 train_loss:3.3931 train_time:697188ms step_avg:287.50ms
step:2436/3000 train_loss:3.4720 train_time:697473ms step_avg:287.50ms
step:2437/3000 train_loss:3.3405 train_time:697758ms step_avg:287.50ms
step:2438/3000 train_loss:3.4219 train_time:698042ms step_avg:287.50ms
step:2439/3000 train_loss:3.5576 train_time:698329ms step_avg:287.50ms
step:2440/3000 train_loss:3.4946 train_time:698615ms step_avg:287.50ms
step:2441/3000 train_loss:3.4978 train_time:698900ms step_avg:287.49ms
step:2442/3000 train_loss:3.3761 train_time:699183ms step_avg:287.49ms
step:2443/3000 train_loss:3.4016 train_time:699470ms step_avg:287.49ms
step:2444/3000 train_loss:3.6444 train_time:699756ms step_avg:287.49ms
step:2445/3000 train_loss:3.3767 train_time:700039ms step_avg:287.49ms
step:2446/3000 train_loss:3.4545 train_time:700327ms step_avg:287.49ms
step:2447/3000 train_loss:3.5682 train_time:700610ms step_avg:287.49ms
step:2448/3000 train_loss:3.4932 train_time:700897ms step_avg:287.49ms
step:2449/3000 train_loss:3.4327 train_time:701182ms step_avg:287.49ms
step:2450/3000 train_loss:3.3202 train_time:701467ms step_avg:287.49ms
step:2451/3000 train_loss:3.9275 train_time:701755ms step_avg:287.49ms
step:2452/3000 train_loss:3.3117 train_time:702041ms step_avg:287.49ms
step:2453/3000 train_loss:3.3767 train_time:702328ms step_avg:287.49ms
step:2454/3000 train_loss:3.4136 train_time:702612ms step_avg:287.48ms
step:2455/3000 train_loss:3.4822 train_time:702899ms step_avg:287.48ms
step:2456/3000 train_loss:3.4143 train_time:703184ms step_avg:287.48ms
step:2457/3000 train_loss:3.4401 train_time:703660ms step_avg:287.56ms
step:2458/3000 train_loss:3.4668 train_time:703948ms step_avg:287.56ms
step:2459/3000 train_loss:3.3743 train_time:704234ms step_avg:287.56ms
step:2460/3000 train_loss:3.3927 train_time:704517ms step_avg:287.56ms
step:2461/3000 train_loss:3.4107 train_time:704802ms step_avg:287.56ms
step:2462/3000 train_loss:3.3862 train_time:705090ms step_avg:287.56ms
step:2463/3000 train_loss:3.4490 train_time:705375ms step_avg:287.56ms
step:2464/3000 train_loss:3.4455 train_time:705660ms step_avg:287.56ms
step:2465/3000 train_loss:3.4368 train_time:705945ms step_avg:287.55ms
step:2466/3000 train_loss:3.5039 train_time:706231ms step_avg:287.55ms
step:2467/3000 train_loss:3.3140 train_time:706517ms step_avg:287.55ms
step:2468/3000 train_loss:3.5831 train_time:706801ms step_avg:287.55ms
step:2469/3000 train_loss:3.4699 train_time:707088ms step_avg:287.55ms
step:2470/3000 train_loss:3.4295 train_time:707565ms step_avg:287.63ms
step:2471/3000 train_loss:3.5403 train_time:707849ms step_avg:287.63ms
step:2472/3000 train_loss:3.2506 train_time:708135ms step_avg:287.63ms
step:2473/3000 train_loss:3.3838 train_time:708419ms step_avg:287.62ms
step:2474/3000 train_loss:3.4725 train_time:708702ms step_avg:287.62ms
step:2475/3000 train_loss:3.1453 train_time:708989ms step_avg:287.62ms
step:2476/3000 train_loss:3.5731 train_time:709275ms step_avg:287.62ms
step:2477/3000 train_loss:3.3909 train_time:709560ms step_avg:287.62ms
step:2478/3000 train_loss:3.3963 train_time:709846ms step_avg:287.62ms
step:2479/3000 train_loss:3.4133 train_time:710130ms step_avg:287.62ms
step:2480/3000 train_loss:3.4354 train_time:710415ms step_avg:287.62ms
step:2481/3000 train_loss:3.4812 train_time:710700ms step_avg:287.62ms
step:2482/3000 train_loss:3.7049 train_time:710984ms step_avg:287.61ms
step:2483/3000 train_loss:3.3014 train_time:711269ms step_avg:287.61ms
step:2484/3000 train_loss:3.4646 train_time:711556ms step_avg:287.61ms
step:2485/3000 train_loss:3.4683 train_time:711841ms step_avg:287.61ms
step:2486/3000 train_loss:3.4382 train_time:712127ms step_avg:287.61ms
step:2487/3000 train_loss:3.2364 train_time:712413ms step_avg:287.61ms
step:2488/3000 train_loss:3.2446 train_time:712698ms step_avg:287.61ms
step:2489/3000 train_loss:3.3212 train_time:712983ms step_avg:287.61ms
step:2490/3000 train_loss:3.4170 train_time:713267ms step_avg:287.61ms
step:2491/3000 train_loss:3.4195 train_time:713554ms step_avg:287.61ms
step:2492/3000 train_loss:3.5059 train_time:713840ms step_avg:287.61ms
step:2493/3000 train_loss:3.4281 train_time:714122ms step_avg:287.60ms
step:2494/3000 train_loss:3.3876 train_time:714409ms step_avg:287.60ms
step:2495/3000 train_loss:3.4354 train_time:714697ms step_avg:287.60ms
step:2496/3000 train_loss:3.3934 train_time:714981ms step_avg:287.60ms
step:2497/3000 train_loss:3.2866 train_time:715264ms step_avg:287.60ms
step:2498/3000 train_loss:3.5334 train_time:715550ms step_avg:287.60ms
step:2499/3000 train_loss:3.3329 train_time:715838ms step_avg:287.60ms
step:2500/3000 train_loss:3.3867 train_time:716121ms step_avg:287.60ms
step:2500/3000 val_loss:3.4075 train_time:716122ms step_avg:287.60ms
step:2501/3000 train_loss:3.4673 train_time:716410ms step_avg:287.60ms
step:2502/3000 train_loss:3.6059 train_time:716698ms step_avg:287.60ms
step:2503/3000 train_loss:3.5919 train_time:716984ms step_avg:287.60ms
step:2504/3000 train_loss:3.2638 train_time:717268ms step_avg:287.60ms
step:2505/3000 train_loss:3.4407 train_time:717556ms step_avg:287.60ms
step:2506/3000 train_loss:3.5178 train_time:717840ms step_avg:287.60ms
step:2507/3000 train_loss:3.5637 train_time:718125ms step_avg:287.60ms
step:2508/3000 train_loss:3.3637 train_time:718411ms step_avg:287.59ms
step:2509/3000 train_loss:3.5008 train_time:718698ms step_avg:287.59ms
step:2510/3000 train_loss:3.3899 train_time:718984ms step_avg:287.59ms
step:2511/3000 train_loss:3.3717 train_time:719268ms step_avg:287.59ms
step:2512/3000 train_loss:3.4585 train_time:719556ms step_avg:287.59ms
step:2513/3000 train_loss:3.3345 train_time:719840ms step_avg:287.59ms
step:2514/3000 train_loss:3.3235 train_time:720126ms step_avg:287.59ms
step:2515/3000 train_loss:3.4700 train_time:720410ms step_avg:287.59ms
step:2516/3000 train_loss:3.3533 train_time:720697ms step_avg:287.59ms
step:2517/3000 train_loss:3.4012 train_time:720982ms step_avg:287.59ms
step:2518/3000 train_loss:3.4873 train_time:721266ms step_avg:287.59ms
step:2519/3000 train_loss:3.3869 train_time:721554ms step_avg:287.59ms
step:2520/3000 train_loss:3.3426 train_time:721839ms step_avg:287.59ms
step:2521/3000 train_loss:3.4061 train_time:722123ms step_avg:287.58ms
step:2522/3000 train_loss:3.4165 train_time:722408ms step_avg:287.58ms
step:2523/3000 train_loss:3.4482 train_time:722697ms step_avg:287.58ms
step:2524/3000 train_loss:3.4647 train_time:722982ms step_avg:287.58ms
step:2525/3000 train_loss:3.4053 train_time:723266ms step_avg:287.58ms
step:2526/3000 train_loss:3.4080 train_time:723554ms step_avg:287.58ms
step:2527/3000 train_loss:3.5287 train_time:723838ms step_avg:287.58ms
step:2528/3000 train_loss:3.6040 train_time:724121ms step_avg:287.58ms
step:2529/3000 train_loss:3.3660 train_time:724408ms step_avg:287.58ms
step:2530/3000 train_loss:3.5600 train_time:724696ms step_avg:287.58ms
step:2531/3000 train_loss:3.3275 train_time:724980ms step_avg:287.58ms
step:2532/3000 train_loss:3.4091 train_time:725263ms step_avg:287.57ms
step:2533/3000 train_loss:3.5359 train_time:725549ms step_avg:287.57ms
step:2534/3000 train_loss:3.4169 train_time:725836ms step_avg:287.57ms
step:2535/3000 train_loss:3.3752 train_time:726120ms step_avg:287.57ms
step:2536/3000 train_loss:3.4622 train_time:726405ms step_avg:287.57ms
step:2537/3000 train_loss:3.3408 train_time:726693ms step_avg:287.57ms
step:2538/3000 train_loss:3.5857 train_time:726980ms step_avg:287.57ms
step:2539/3000 train_loss:3.4644 train_time:727264ms step_avg:287.57ms
step:2540/3000 train_loss:3.5047 train_time:727551ms step_avg:287.57ms
step:2541/3000 train_loss:3.3955 train_time:727836ms step_avg:287.57ms
step:2542/3000 train_loss:3.4389 train_time:728119ms step_avg:287.57ms
step:2543/3000 train_loss:3.3601 train_time:728404ms step_avg:287.57ms
step:2544/3000 train_loss:3.5055 train_time:728692ms step_avg:287.57ms
step:2545/3000 train_loss:3.3044 train_time:728977ms step_avg:287.57ms
step:2546/3000 train_loss:3.3075 train_time:729262ms step_avg:287.56ms
step:2547/3000 train_loss:3.5421 train_time:729548ms step_avg:287.56ms
step:2548/3000 train_loss:3.2342 train_time:729836ms step_avg:287.56ms
step:2549/3000 train_loss:3.4382 train_time:730119ms step_avg:287.56ms
step:2550/3000 train_loss:3.2801 train_time:730405ms step_avg:287.56ms
step:2551/3000 train_loss:3.3159 train_time:730694ms step_avg:287.56ms
step:2552/3000 train_loss:3.4149 train_time:730978ms step_avg:287.56ms
step:2553/3000 train_loss:3.4370 train_time:731263ms step_avg:287.56ms
step:2554/3000 train_loss:3.4309 train_time:731550ms step_avg:287.56ms
step:2555/3000 train_loss:3.2913 train_time:731836ms step_avg:287.56ms
step:2556/3000 train_loss:3.5172 train_time:732120ms step_avg:287.56ms
step:2557/3000 train_loss:3.3784 train_time:732407ms step_avg:287.56ms
step:2558/3000 train_loss:3.3409 train_time:732696ms step_avg:287.56ms
step:2559/3000 train_loss:3.4932 train_time:732981ms step_avg:287.56ms
step:2560/3000 train_loss:3.3389 train_time:733266ms step_avg:287.56ms
step:2561/3000 train_loss:3.3096 train_time:733553ms step_avg:287.56ms
step:2562/3000 train_loss:3.5756 train_time:733838ms step_avg:287.55ms
step:2563/3000 train_loss:3.2879 train_time:734121ms step_avg:287.55ms
step:2564/3000 train_loss:3.4207 train_time:734408ms step_avg:287.55ms
step:2565/3000 train_loss:3.4905 train_time:734696ms step_avg:287.55ms
step:2566/3000 train_loss:3.3512 train_time:734981ms step_avg:287.55ms
step:2567/3000 train_loss:3.4075 train_time:735267ms step_avg:287.55ms
step:2568/3000 train_loss:3.4655 train_time:735554ms step_avg:287.55ms
step:2569/3000 train_loss:3.3124 train_time:735839ms step_avg:287.55ms
step:2570/3000 train_loss:3.4077 train_time:736123ms step_avg:287.55ms
step:2571/3000 train_loss:3.4306 train_time:736410ms step_avg:287.55ms
step:2572/3000 train_loss:3.4799 train_time:736698ms step_avg:287.55ms
step:2573/3000 train_loss:3.4735 train_time:736982ms step_avg:287.55ms
step:2574/3000 train_loss:3.4279 train_time:737268ms step_avg:287.55ms
step:2575/3000 train_loss:3.2352 train_time:737555ms step_avg:287.55ms
step:2576/3000 train_loss:3.4459 train_time:737840ms step_avg:287.54ms
step:2577/3000 train_loss:3.7250 train_time:738125ms step_avg:287.54ms
step:2578/3000 train_loss:3.3246 train_time:738412ms step_avg:287.54ms
step:2579/3000 train_loss:3.4994 train_time:738699ms step_avg:287.54ms
step:2580/3000 train_loss:3.4740 train_time:738984ms step_avg:287.54ms
step:2581/3000 train_loss:3.3165 train_time:739269ms step_avg:287.54ms
step:2582/3000 train_loss:3.2237 train_time:739557ms step_avg:287.54ms
step:2583/3000 train_loss:3.5017 train_time:739840ms step_avg:287.54ms
step:2584/3000 train_loss:3.3081 train_time:740125ms step_avg:287.54ms
step:2585/3000 train_loss:3.1047 train_time:740412ms step_avg:287.54ms
step:2586/3000 train_loss:3.4823 train_time:740698ms step_avg:287.54ms
step:2587/3000 train_loss:3.2967 train_time:740982ms step_avg:287.54ms
step:2588/3000 train_loss:3.4735 train_time:741267ms step_avg:287.54ms
step:2589/3000 train_loss:3.3244 train_time:741554ms step_avg:287.54ms
step:2590/3000 train_loss:3.5185 train_time:741838ms step_avg:287.53ms
step:2591/3000 train_loss:3.1906 train_time:742122ms step_avg:287.53ms
step:2592/3000 train_loss:3.3168 train_time:742409ms step_avg:287.53ms
step:2593/3000 train_loss:3.5503 train_time:742697ms step_avg:287.53ms
step:2594/3000 train_loss:3.6924 train_time:742982ms step_avg:287.53ms
step:2595/3000 train_loss:3.4145 train_time:743266ms step_avg:287.53ms
step:2596/3000 train_loss:3.3588 train_time:743554ms step_avg:287.53ms
step:2597/3000 train_loss:3.4145 train_time:743838ms step_avg:287.53ms
step:2598/3000 train_loss:3.9156 train_time:744122ms step_avg:287.53ms
step:2599/3000 train_loss:3.7205 train_time:744411ms step_avg:287.53ms
step:2600/3000 train_loss:3.3761 train_time:744698ms step_avg:287.53ms
step:2601/3000 train_loss:3.3785 train_time:744982ms step_avg:287.53ms
step:2602/3000 train_loss:3.2330 train_time:745267ms step_avg:287.53ms
step:2603/3000 train_loss:3.5815 train_time:745555ms step_avg:287.53ms
step:2604/3000 train_loss:3.2781 train_time:745838ms step_avg:287.52ms
step:2605/3000 train_loss:3.5007 train_time:746122ms step_avg:287.52ms
step:2606/3000 train_loss:3.5384 train_time:746409ms step_avg:287.52ms
step:2607/3000 train_loss:3.3423 train_time:746697ms step_avg:287.52ms
step:2608/3000 train_loss:3.4170 train_time:746981ms step_avg:287.52ms
step:2609/3000 train_loss:3.4451 train_time:747266ms step_avg:287.52ms
step:2610/3000 train_loss:3.3265 train_time:747554ms step_avg:287.52ms
step:2611/3000 train_loss:3.2904 train_time:747839ms step_avg:287.52ms
step:2612/3000 train_loss:3.4721 train_time:748122ms step_avg:287.52ms
step:2613/3000 train_loss:3.4746 train_time:748408ms step_avg:287.52ms
step:2614/3000 train_loss:3.4057 train_time:748697ms step_avg:287.52ms
step:2615/3000 train_loss:3.3541 train_time:748981ms step_avg:287.52ms
step:2616/3000 train_loss:3.3442 train_time:749266ms step_avg:287.52ms
step:2617/3000 train_loss:3.5811 train_time:749553ms step_avg:287.52ms
step:2618/3000 train_loss:3.3701 train_time:749838ms step_avg:287.51ms
step:2619/3000 train_loss:3.4079 train_time:750122ms step_avg:287.51ms
step:2620/3000 train_loss:3.3271 train_time:750408ms step_avg:287.51ms
step:2621/3000 train_loss:3.3934 train_time:750697ms step_avg:287.51ms
step:2622/3000 train_loss:3.4895 train_time:750981ms step_avg:287.51ms
step:2623/3000 train_loss:3.4713 train_time:751265ms step_avg:287.51ms
step:2624/3000 train_loss:3.3400 train_time:751553ms step_avg:287.51ms
step:2625/3000 train_loss:3.5875 train_time:751838ms step_avg:287.51ms
step:2625/3000 val_loss:3.3928 train_time:751839ms step_avg:287.51ms
step:2626/3000 train_loss:3.3996 train_time:752128ms step_avg:287.51ms
step:2627/3000 train_loss:3.4829 train_time:752416ms step_avg:287.51ms
step:2628/3000 train_loss:3.4492 train_time:752704ms step_avg:287.51ms
step:2629/3000 train_loss:4.7178 train_time:752988ms step_avg:287.51ms
step:2630/3000 train_loss:3.3698 train_time:753272ms step_avg:287.51ms
step:2631/3000 train_loss:3.4523 train_time:753559ms step_avg:287.51ms
step:2632/3000 train_loss:3.4061 train_time:753843ms step_avg:287.51ms
step:2633/3000 train_loss:3.4354 train_time:754126ms step_avg:287.51ms
step:2634/3000 train_loss:3.4608 train_time:754414ms step_avg:287.51ms
step:2635/3000 train_loss:3.5533 train_time:754701ms step_avg:287.51ms
step:2636/3000 train_loss:3.5140 train_time:754986ms step_avg:287.50ms
step:2637/3000 train_loss:3.4221 train_time:755271ms step_avg:287.50ms
step:2638/3000 train_loss:3.4127 train_time:755558ms step_avg:287.50ms
step:2639/3000 train_loss:3.6669 train_time:755844ms step_avg:287.50ms
step:2640/3000 train_loss:3.4814 train_time:756128ms step_avg:287.50ms
step:2641/3000 train_loss:3.2885 train_time:756412ms step_avg:287.50ms
step:2642/3000 train_loss:3.3614 train_time:756700ms step_avg:287.50ms
step:2643/3000 train_loss:3.5154 train_time:756985ms step_avg:287.50ms
step:2644/3000 train_loss:3.2153 train_time:757268ms step_avg:287.50ms
step:2645/3000 train_loss:3.4450 train_time:757555ms step_avg:287.50ms
step:2646/3000 train_loss:3.3047 train_time:758022ms step_avg:287.57ms
step:2647/3000 train_loss:3.3832 train_time:758304ms step_avg:287.56ms
step:2648/3000 train_loss:3.4842 train_time:758588ms step_avg:287.56ms
step:2649/3000 train_loss:3.4061 train_time:758876ms step_avg:287.56ms
step:2650/3000 train_loss:3.5468 train_time:759162ms step_avg:287.56ms
step:2651/3000 train_loss:3.3404 train_time:759447ms step_avg:287.56ms
step:2652/3000 train_loss:3.4062 train_time:759731ms step_avg:287.56ms
step:2653/3000 train_loss:3.2067 train_time:760017ms step_avg:287.56ms
step:2654/3000 train_loss:3.5764 train_time:760304ms step_avg:287.56ms
step:2655/3000 train_loss:3.2837 train_time:760589ms step_avg:287.56ms
step:2656/3000 train_loss:3.2853 train_time:760873ms step_avg:287.56ms
step:2657/3000 train_loss:4.9569 train_time:761161ms step_avg:287.56ms
step:2658/3000 train_loss:3.4870 train_time:761444ms step_avg:287.55ms
step:2659/3000 train_loss:3.3679 train_time:761729ms step_avg:287.55ms
step:2660/3000 train_loss:3.2485 train_time:762197ms step_avg:287.62ms
step:2661/3000 train_loss:3.3264 train_time:762483ms step_avg:287.62ms
step:2662/3000 train_loss:3.2701 train_time:762765ms step_avg:287.62ms
step:2663/3000 train_loss:3.3599 train_time:763049ms step_avg:287.62ms
step:2664/3000 train_loss:3.4307 train_time:763335ms step_avg:287.62ms
step:2665/3000 train_loss:3.3336 train_time:763620ms step_avg:287.62ms
step:2666/3000 train_loss:3.3447 train_time:763904ms step_avg:287.61ms
step:2667/3000 train_loss:3.3097 train_time:764189ms step_avg:287.61ms
step:2668/3000 train_loss:3.3563 train_time:764474ms step_avg:287.61ms
step:2669/3000 train_loss:3.3721 train_time:764761ms step_avg:287.61ms
step:2670/3000 train_loss:3.3944 train_time:765045ms step_avg:287.61ms
step:2671/3000 train_loss:3.2843 train_time:765330ms step_avg:287.61ms
step:2672/3000 train_loss:3.5152 train_time:765618ms step_avg:287.61ms
step:2673/3000 train_loss:3.4600 train_time:765904ms step_avg:287.61ms
step:2674/3000 train_loss:3.2730 train_time:766188ms step_avg:287.61ms
step:2675/3000 train_loss:3.3342 train_time:766474ms step_avg:287.61ms
step:2676/3000 train_loss:3.3564 train_time:766762ms step_avg:287.61ms
step:2677/3000 train_loss:3.5723 train_time:767046ms step_avg:287.61ms
step:2678/3000 train_loss:3.3979 train_time:767333ms step_avg:287.61ms
step:2679/3000 train_loss:3.3823 train_time:767617ms step_avg:287.60ms
step:2680/3000 train_loss:3.4537 train_time:767904ms step_avg:287.60ms
step:2681/3000 train_loss:3.2599 train_time:768188ms step_avg:287.60ms
step:2682/3000 train_loss:3.4094 train_time:768474ms step_avg:287.60ms
step:2683/3000 train_loss:3.3351 train_time:768763ms step_avg:287.60ms
step:2684/3000 train_loss:3.4061 train_time:769045ms step_avg:287.60ms
step:2685/3000 train_loss:3.4741 train_time:769330ms step_avg:287.60ms
step:2686/3000 train_loss:3.3504 train_time:769615ms step_avg:287.60ms
step:2687/3000 train_loss:3.5573 train_time:769903ms step_avg:287.60ms
step:2688/3000 train_loss:3.4421 train_time:770189ms step_avg:287.60ms
step:2689/3000 train_loss:3.2433 train_time:770474ms step_avg:287.60ms
step:2690/3000 train_loss:3.5241 train_time:770761ms step_avg:287.60ms
step:2691/3000 train_loss:3.2923 train_time:771045ms step_avg:287.60ms
step:2692/3000 train_loss:3.4583 train_time:771329ms step_avg:287.59ms
step:2693/3000 train_loss:3.4192 train_time:771617ms step_avg:287.59ms
step:2694/3000 train_loss:3.3983 train_time:771904ms step_avg:287.59ms
step:2695/3000 train_loss:3.3907 train_time:772191ms step_avg:287.59ms
step:2696/3000 train_loss:3.4593 train_time:772475ms step_avg:287.59ms
step:2697/3000 train_loss:3.2961 train_time:772763ms step_avg:287.59ms
step:2698/3000 train_loss:3.3695 train_time:773047ms step_avg:287.59ms
step:2699/3000 train_loss:3.3312 train_time:773332ms step_avg:287.59ms
step:2700/3000 train_loss:3.3010 train_time:773620ms step_avg:287.59ms
step:2701/3000 train_loss:3.5476 train_time:773905ms step_avg:287.59ms
step:2702/3000 train_loss:3.3450 train_time:774190ms step_avg:287.59ms
step:2703/3000 train_loss:3.3300 train_time:774476ms step_avg:287.59ms
step:2704/3000 train_loss:3.3717 train_time:774764ms step_avg:287.59ms
step:2705/3000 train_loss:3.4780 train_time:775048ms step_avg:287.59ms
step:2706/3000 train_loss:3.4100 train_time:775333ms step_avg:287.59ms
step:2707/3000 train_loss:3.3439 train_time:775619ms step_avg:287.59ms
step:2708/3000 train_loss:3.6530 train_time:775904ms step_avg:287.59ms
step:2709/3000 train_loss:3.3417 train_time:776191ms step_avg:287.58ms
step:2710/3000 train_loss:3.4655 train_time:776476ms step_avg:287.58ms
step:2711/3000 train_loss:3.3421 train_time:776763ms step_avg:287.58ms
step:2712/3000 train_loss:3.3713 train_time:777047ms step_avg:287.58ms
step:2713/3000 train_loss:3.2580 train_time:777334ms step_avg:287.58ms
step:2714/3000 train_loss:3.4503 train_time:777618ms step_avg:287.58ms
step:2715/3000 train_loss:3.4905 train_time:777904ms step_avg:287.58ms
step:2716/3000 train_loss:3.2765 train_time:778190ms step_avg:287.58ms
step:2717/3000 train_loss:3.3610 train_time:778476ms step_avg:287.58ms
step:2718/3000 train_loss:3.3147 train_time:778764ms step_avg:287.58ms
step:2719/3000 train_loss:3.4387 train_time:779048ms step_avg:287.58ms
step:2720/3000 train_loss:3.5535 train_time:779334ms step_avg:287.58ms
step:2721/3000 train_loss:3.4504 train_time:779619ms step_avg:287.58ms
step:2722/3000 train_loss:3.4232 train_time:779904ms step_avg:287.58ms
step:2723/3000 train_loss:3.2784 train_time:780189ms step_avg:287.57ms
step:2724/3000 train_loss:3.4139 train_time:780474ms step_avg:287.57ms
step:2725/3000 train_loss:3.5135 train_time:780762ms step_avg:287.57ms
step:2726/3000 train_loss:3.2388 train_time:781046ms step_avg:287.57ms
step:2727/3000 train_loss:3.3024 train_time:781332ms step_avg:287.57ms
step:2728/3000 train_loss:3.2831 train_time:781617ms step_avg:287.57ms
step:2729/3000 train_loss:3.2775 train_time:781904ms step_avg:287.57ms
step:2730/3000 train_loss:3.4096 train_time:782189ms step_avg:287.57ms
step:2731/3000 train_loss:3.2978 train_time:782474ms step_avg:287.57ms
step:2732/3000 train_loss:3.2624 train_time:782760ms step_avg:287.57ms
step:2733/3000 train_loss:3.3629 train_time:783046ms step_avg:287.57ms
step:2734/3000 train_loss:3.3824 train_time:783330ms step_avg:287.57ms
step:2735/3000 train_loss:3.3856 train_time:783616ms step_avg:287.57ms
step:2736/3000 train_loss:3.3790 train_time:783903ms step_avg:287.57ms
step:2737/3000 train_loss:3.5271 train_time:784188ms step_avg:287.56ms
step:2738/3000 train_loss:3.2283 train_time:784474ms step_avg:287.56ms
step:2739/3000 train_loss:3.2978 train_time:784761ms step_avg:287.56ms
step:2740/3000 train_loss:3.2128 train_time:785045ms step_avg:287.56ms
step:2741/3000 train_loss:3.4240 train_time:785329ms step_avg:287.56ms
step:2742/3000 train_loss:3.3854 train_time:785615ms step_avg:287.56ms
step:2743/3000 train_loss:3.5808 train_time:785903ms step_avg:287.56ms
step:2744/3000 train_loss:3.3862 train_time:786188ms step_avg:287.56ms
step:2745/3000 train_loss:3.2858 train_time:786474ms step_avg:287.56ms
step:2746/3000 train_loss:3.3329 train_time:786761ms step_avg:287.56ms
step:2747/3000 train_loss:3.3861 train_time:787045ms step_avg:287.56ms
step:2748/3000 train_loss:3.6977 train_time:787328ms step_avg:287.56ms
step:2749/3000 train_loss:3.5124 train_time:787616ms step_avg:287.56ms
step:2750/3000 train_loss:3.4193 train_time:787904ms step_avg:287.56ms
step:2750/3000 val_loss:3.3786 train_time:787905ms step_avg:287.56ms
step:2751/3000 train_loss:3.3094 train_time:788192ms step_avg:287.56ms
step:2752/3000 train_loss:3.3937 train_time:788483ms step_avg:287.56ms
step:2753/3000 train_loss:3.4166 train_time:788769ms step_avg:287.56ms
step:2754/3000 train_loss:3.3538 train_time:789055ms step_avg:287.56ms
step:2755/3000 train_loss:3.3663 train_time:789340ms step_avg:287.56ms
step:2756/3000 train_loss:3.4255 train_time:789627ms step_avg:287.56ms
step:2757/3000 train_loss:3.3356 train_time:789910ms step_avg:287.55ms
step:2758/3000 train_loss:3.5219 train_time:790195ms step_avg:287.55ms
step:2759/3000 train_loss:3.3898 train_time:790483ms step_avg:287.55ms
step:2760/3000 train_loss:3.3156 train_time:790769ms step_avg:287.55ms
step:2761/3000 train_loss:3.2885 train_time:791053ms step_avg:287.55ms
step:2762/3000 train_loss:3.3975 train_time:791338ms step_avg:287.55ms
step:2763/3000 train_loss:3.2843 train_time:791624ms step_avg:287.55ms
step:2764/3000 train_loss:3.6105 train_time:791908ms step_avg:287.55ms
step:2765/3000 train_loss:3.4354 train_time:792195ms step_avg:287.55ms
step:2766/3000 train_loss:3.3119 train_time:792480ms step_avg:287.55ms
step:2767/3000 train_loss:3.4008 train_time:792765ms step_avg:287.55ms
step:2768/3000 train_loss:3.4813 train_time:793052ms step_avg:287.55ms
step:2769/3000 train_loss:3.1972 train_time:793335ms step_avg:287.54ms
step:2770/3000 train_loss:3.3145 train_time:793621ms step_avg:287.54ms
step:2771/3000 train_loss:3.3380 train_time:793908ms step_avg:287.54ms
step:2772/3000 train_loss:3.3063 train_time:794193ms step_avg:287.54ms
step:2773/3000 train_loss:3.2940 train_time:794479ms step_avg:287.54ms
step:2774/3000 train_loss:3.3702 train_time:794765ms step_avg:287.54ms
step:2775/3000 train_loss:3.2747 train_time:795051ms step_avg:287.54ms
step:2776/3000 train_loss:3.2904 train_time:795336ms step_avg:287.54ms
step:2777/3000 train_loss:3.3240 train_time:795623ms step_avg:287.54ms
step:2778/3000 train_loss:3.2115 train_time:795909ms step_avg:287.54ms
step:2779/3000 train_loss:3.3445 train_time:796193ms step_avg:287.54ms
step:2780/3000 train_loss:3.1934 train_time:796479ms step_avg:287.54ms
step:2781/3000 train_loss:3.4809 train_time:796766ms step_avg:287.54ms
step:2782/3000 train_loss:3.4286 train_time:797052ms step_avg:287.54ms
step:2783/3000 train_loss:3.3617 train_time:797336ms step_avg:287.54ms
step:2784/3000 train_loss:3.4269 train_time:797623ms step_avg:287.54ms
step:2785/3000 train_loss:3.3395 train_time:797908ms step_avg:287.53ms
step:2786/3000 train_loss:3.3179 train_time:798192ms step_avg:287.53ms
step:2787/3000 train_loss:3.7215 train_time:798479ms step_avg:287.53ms
step:2788/3000 train_loss:3.3333 train_time:798765ms step_avg:287.53ms
step:2789/3000 train_loss:3.0952 train_time:799052ms step_avg:287.53ms
step:2790/3000 train_loss:3.4555 train_time:799336ms step_avg:287.53ms
step:2791/3000 train_loss:3.3527 train_time:799623ms step_avg:287.53ms
step:2792/3000 train_loss:3.3992 train_time:799912ms step_avg:287.53ms
step:2793/3000 train_loss:3.5155 train_time:800195ms step_avg:287.53ms
step:2794/3000 train_loss:3.4088 train_time:800482ms step_avg:287.53ms
step:2795/3000 train_loss:3.3702 train_time:800767ms step_avg:287.53ms
step:2796/3000 train_loss:3.3619 train_time:801053ms step_avg:287.53ms
step:2797/3000 train_loss:3.5431 train_time:801338ms step_avg:287.53ms
step:2798/3000 train_loss:3.4102 train_time:801627ms step_avg:287.53ms
step:2799/3000 train_loss:3.2758 train_time:801911ms step_avg:287.53ms
step:2800/3000 train_loss:3.2903 train_time:802196ms step_avg:287.53ms
step:2801/3000 train_loss:3.4012 train_time:802483ms step_avg:287.53ms
step:2802/3000 train_loss:3.2086 train_time:802768ms step_avg:287.52ms
step:2803/3000 train_loss:3.3935 train_time:803054ms step_avg:287.52ms
step:2804/3000 train_loss:3.5291 train_time:803340ms step_avg:287.52ms
step:2805/3000 train_loss:3.3743 train_time:803627ms step_avg:287.52ms
step:2806/3000 train_loss:3.3327 train_time:803912ms step_avg:287.52ms
step:2807/3000 train_loss:3.3457 train_time:804197ms step_avg:287.52ms
step:2808/3000 train_loss:3.4001 train_time:804483ms step_avg:287.52ms
step:2809/3000 train_loss:3.4750 train_time:804770ms step_avg:287.52ms
step:2810/3000 train_loss:3.4413 train_time:805053ms step_avg:287.52ms
step:2811/3000 train_loss:3.3417 train_time:805339ms step_avg:287.52ms
step:2812/3000 train_loss:3.2185 train_time:805625ms step_avg:287.52ms
step:2813/3000 train_loss:3.2926 train_time:805910ms step_avg:287.52ms
step:2814/3000 train_loss:3.3567 train_time:806197ms step_avg:287.52ms
step:2815/3000 train_loss:3.2514 train_time:806484ms step_avg:287.52ms
step:2816/3000 train_loss:4.0156 train_time:806768ms step_avg:287.52ms
step:2817/3000 train_loss:3.1461 train_time:807053ms step_avg:287.51ms
step:2818/3000 train_loss:3.4939 train_time:807338ms step_avg:287.51ms
step:2819/3000 train_loss:3.2776 train_time:807625ms step_avg:287.51ms
step:2820/3000 train_loss:3.4247 train_time:807912ms step_avg:287.51ms
step:2821/3000 train_loss:3.3396 train_time:808196ms step_avg:287.51ms
step:2822/3000 train_loss:3.4020 train_time:808482ms step_avg:287.51ms
step:2823/3000 train_loss:3.4927 train_time:808769ms step_avg:287.51ms
step:2824/3000 train_loss:3.3344 train_time:809054ms step_avg:287.51ms
step:2825/3000 train_loss:3.3073 train_time:809339ms step_avg:287.51ms
step:2826/3000 train_loss:3.1589 train_time:809626ms step_avg:287.51ms
step:2827/3000 train_loss:3.3644 train_time:809912ms step_avg:287.51ms
step:2828/3000 train_loss:3.5009 train_time:810195ms step_avg:287.51ms
step:2829/3000 train_loss:3.5544 train_time:810484ms step_avg:287.51ms
step:2830/3000 train_loss:3.3934 train_time:810770ms step_avg:287.51ms
step:2831/3000 train_loss:3.4126 train_time:811055ms step_avg:287.51ms
step:2832/3000 train_loss:3.3239 train_time:811341ms step_avg:287.51ms
step:2833/3000 train_loss:3.3825 train_time:811628ms step_avg:287.51ms
step:2834/3000 train_loss:3.5021 train_time:811911ms step_avg:287.50ms
step:2835/3000 train_loss:3.2630 train_time:812384ms step_avg:287.57ms
step:2836/3000 train_loss:3.1654 train_time:812669ms step_avg:287.57ms
step:2837/3000 train_loss:3.3945 train_time:812954ms step_avg:287.57ms
step:2838/3000 train_loss:3.5993 train_time:813239ms step_avg:287.57ms
step:2839/3000 train_loss:3.1634 train_time:813526ms step_avg:287.57ms
step:2840/3000 train_loss:3.4880 train_time:813812ms step_avg:287.57ms
step:2841/3000 train_loss:3.3060 train_time:814096ms step_avg:287.56ms
step:2842/3000 train_loss:3.3447 train_time:814383ms step_avg:287.56ms
step:2843/3000 train_loss:3.2908 train_time:814667ms step_avg:287.56ms
step:2844/3000 train_loss:3.4336 train_time:814954ms step_avg:287.56ms
step:2845/3000 train_loss:3.3722 train_time:815238ms step_avg:287.56ms
step:2846/3000 train_loss:3.4501 train_time:815525ms step_avg:287.56ms
step:2847/3000 train_loss:3.4875 train_time:815812ms step_avg:287.56ms
step:2848/3000 train_loss:3.3817 train_time:816097ms step_avg:287.56ms
step:2849/3000 train_loss:3.2851 train_time:816383ms step_avg:287.56ms
step:2850/3000 train_loss:3.5924 train_time:816854ms step_avg:287.62ms
step:2851/3000 train_loss:3.3788 train_time:817137ms step_avg:287.62ms
step:2852/3000 train_loss:3.4983 train_time:817418ms step_avg:287.62ms
step:2853/3000 train_loss:3.3678 train_time:817702ms step_avg:287.62ms
step:2854/3000 train_loss:3.2913 train_time:817990ms step_avg:287.62ms
step:2855/3000 train_loss:3.3872 train_time:818275ms step_avg:287.62ms
step:2856/3000 train_loss:3.5032 train_time:818557ms step_avg:287.62ms
step:2857/3000 train_loss:3.5083 train_time:818844ms step_avg:287.62ms
step:2858/3000 train_loss:3.4130 train_time:819130ms step_avg:287.62ms
step:2859/3000 train_loss:3.4354 train_time:819413ms step_avg:287.61ms
step:2860/3000 train_loss:3.2663 train_time:819697ms step_avg:287.61ms
step:2861/3000 train_loss:3.3080 train_time:819985ms step_avg:287.61ms
step:2862/3000 train_loss:3.2646 train_time:820272ms step_avg:287.61ms
step:2863/3000 train_loss:3.3733 train_time:820557ms step_avg:287.61ms
step:2864/3000 train_loss:3.3860 train_time:820844ms step_avg:287.61ms
step:2865/3000 train_loss:3.4582 train_time:821132ms step_avg:287.61ms
step:2866/3000 train_loss:3.2802 train_time:821415ms step_avg:287.61ms
step:2867/3000 train_loss:3.4716 train_time:821698ms step_avg:287.61ms
step:2868/3000 train_loss:3.4181 train_time:821986ms step_avg:287.61ms
step:2869/3000 train_loss:3.2121 train_time:822271ms step_avg:287.61ms
step:2870/3000 train_loss:3.2918 train_time:822555ms step_avg:287.61ms
step:2871/3000 train_loss:3.2757 train_time:822842ms step_avg:287.61ms
step:2872/3000 train_loss:3.0402 train_time:823128ms step_avg:287.61ms
step:2873/3000 train_loss:3.3657 train_time:823412ms step_avg:287.60ms
step:2874/3000 train_loss:3.3403 train_time:823695ms step_avg:287.60ms
step:2875/3000 train_loss:3.2186 train_time:823984ms step_avg:287.60ms
step:2875/3000 val_loss:3.3669 train_time:823985ms step_avg:287.60ms
step:2876/3000 train_loss:3.1782 train_time:824274ms step_avg:287.60ms
step:2877/3000 train_loss:3.3274 train_time:824563ms step_avg:287.60ms
step:2878/3000 train_loss:3.3533 train_time:824850ms step_avg:287.60ms
step:2879/3000 train_loss:3.6574 train_time:825134ms step_avg:287.60ms
step:2880/3000 train_loss:3.3230 train_time:825419ms step_avg:287.60ms
step:2881/3000 train_loss:3.3327 train_time:825705ms step_avg:287.60ms
step:2882/3000 train_loss:3.2203 train_time:825990ms step_avg:287.60ms
step:2883/3000 train_loss:3.3578 train_time:826275ms step_avg:287.60ms
step:2884/3000 train_loss:3.4624 train_time:826560ms step_avg:287.60ms
step:2885/3000 train_loss:3.3229 train_time:826848ms step_avg:287.60ms
step:2886/3000 train_loss:3.3215 train_time:827132ms step_avg:287.60ms
step:2887/3000 train_loss:3.3872 train_time:827418ms step_avg:287.60ms
step:2888/3000 train_loss:3.3812 train_time:827703ms step_avg:287.60ms
step:2889/3000 train_loss:3.4350 train_time:827989ms step_avg:287.60ms
step:2890/3000 train_loss:3.3252 train_time:828273ms step_avg:287.59ms
step:2891/3000 train_loss:3.3212 train_time:828556ms step_avg:287.59ms
step:2892/3000 train_loss:3.2890 train_time:828844ms step_avg:287.59ms
step:2893/3000 train_loss:3.3132 train_time:829130ms step_avg:287.59ms
step:2894/3000 train_loss:3.2782 train_time:829415ms step_avg:287.59ms
step:2895/3000 train_loss:3.4486 train_time:829699ms step_avg:287.59ms
step:2896/3000 train_loss:3.4970 train_time:829987ms step_avg:287.59ms
step:2897/3000 train_loss:3.3200 train_time:830273ms step_avg:287.59ms
step:2898/3000 train_loss:3.3649 train_time:830555ms step_avg:287.59ms
step:2899/3000 train_loss:3.3726 train_time:830843ms step_avg:287.59ms
step:2900/3000 train_loss:3.2305 train_time:831131ms step_avg:287.59ms
step:2901/3000 train_loss:3.3933 train_time:831414ms step_avg:287.59ms
step:2902/3000 train_loss:3.5385 train_time:831698ms step_avg:287.59ms
step:2903/3000 train_loss:3.3403 train_time:831986ms step_avg:287.59ms
step:2904/3000 train_loss:3.2221 train_time:832271ms step_avg:287.58ms
step:2905/3000 train_loss:3.5229 train_time:832555ms step_avg:287.58ms
step:2906/3000 train_loss:3.3062 train_time:832841ms step_avg:287.58ms
step:2907/3000 train_loss:3.3376 train_time:833127ms step_avg:287.58ms
step:2908/3000 train_loss:3.2330 train_time:833410ms step_avg:287.58ms
step:2909/3000 train_loss:3.2534 train_time:833697ms step_avg:287.58ms
step:2910/3000 train_loss:3.2954 train_time:833984ms step_avg:287.58ms
step:2911/3000 train_loss:3.3922 train_time:834270ms step_avg:287.58ms
step:2912/3000 train_loss:3.4404 train_time:834553ms step_avg:287.58ms
step:2913/3000 train_loss:3.5464 train_time:834840ms step_avg:287.58ms
step:2914/3000 train_loss:3.3585 train_time:835127ms step_avg:287.58ms
step:2915/3000 train_loss:3.2684 train_time:835411ms step_avg:287.58ms
step:2916/3000 train_loss:3.3963 train_time:835695ms step_avg:287.58ms
step:2917/3000 train_loss:3.4127 train_time:835986ms step_avg:287.58ms
step:2918/3000 train_loss:3.4630 train_time:836270ms step_avg:287.58ms
step:2919/3000 train_loss:3.3439 train_time:836554ms step_avg:287.57ms
step:2920/3000 train_loss:3.2263 train_time:836841ms step_avg:287.57ms
step:2921/3000 train_loss:3.2565 train_time:837128ms step_avg:287.57ms
step:2922/3000 train_loss:3.3467 train_time:837412ms step_avg:287.57ms
step:2923/3000 train_loss:3.3760 train_time:837696ms step_avg:287.57ms
step:2924/3000 train_loss:3.3877 train_time:837984ms step_avg:287.57ms
step:2925/3000 train_loss:3.2258 train_time:838271ms step_avg:287.57ms
step:2926/3000 train_loss:3.3523 train_time:838554ms step_avg:287.57ms
step:2927/3000 train_loss:3.2899 train_time:838841ms step_avg:287.57ms
step:2928/3000 train_loss:3.2713 train_time:839129ms step_avg:287.57ms
step:2929/3000 train_loss:3.3655 train_time:839412ms step_avg:287.57ms
step:2930/3000 train_loss:3.2010 train_time:839696ms step_avg:287.57ms
step:2931/3000 train_loss:3.4474 train_time:839984ms step_avg:287.57ms
step:2932/3000 train_loss:3.4656 train_time:840270ms step_avg:287.57ms
step:2933/3000 train_loss:3.3685 train_time:840554ms step_avg:287.57ms
step:2934/3000 train_loss:3.2670 train_time:840842ms step_avg:287.57ms
step:2935/3000 train_loss:3.2247 train_time:841128ms step_avg:287.56ms
step:2936/3000 train_loss:3.3150 train_time:841411ms step_avg:287.56ms
step:2937/3000 train_loss:3.3084 train_time:841694ms step_avg:287.56ms
step:2938/3000 train_loss:3.2554 train_time:841984ms step_avg:287.56ms
step:2939/3000 train_loss:3.4124 train_time:842270ms step_avg:287.56ms
step:2940/3000 train_loss:3.3308 train_time:842553ms step_avg:287.56ms
step:2941/3000 train_loss:3.3807 train_time:842839ms step_avg:287.56ms
step:2942/3000 train_loss:3.5377 train_time:843127ms step_avg:287.56ms
step:2943/3000 train_loss:3.4558 train_time:843410ms step_avg:287.56ms
step:2944/3000 train_loss:3.3894 train_time:843694ms step_avg:287.56ms
step:2945/3000 train_loss:3.5337 train_time:843982ms step_avg:287.56ms
step:2946/3000 train_loss:3.2780 train_time:844268ms step_avg:287.56ms
step:2947/3000 train_loss:3.2628 train_time:844553ms step_avg:287.56ms
step:2948/3000 train_loss:3.2218 train_time:844840ms step_avg:287.56ms
step:2949/3000 train_loss:3.2602 train_time:845126ms step_avg:287.56ms
step:2950/3000 train_loss:3.3109 train_time:845410ms step_avg:287.55ms
step:2951/3000 train_loss:3.3438 train_time:845694ms step_avg:287.55ms
step:2952/3000 train_loss:3.3894 train_time:845983ms step_avg:287.55ms
step:2953/3000 train_loss:3.2735 train_time:846269ms step_avg:287.55ms
step:2954/3000 train_loss:3.3693 train_time:846553ms step_avg:287.55ms
step:2955/3000 train_loss:3.3686 train_time:846839ms step_avg:287.55ms
step:2956/3000 train_loss:3.3766 train_time:847126ms step_avg:287.55ms
step:2957/3000 train_loss:3.2097 train_time:847410ms step_avg:287.55ms
step:2958/3000 train_loss:3.3420 train_time:847692ms step_avg:287.55ms
step:2959/3000 train_loss:3.3806 train_time:847981ms step_avg:287.55ms
step:2960/3000 train_loss:3.3830 train_time:848267ms step_avg:287.55ms
step:2961/3000 train_loss:3.2871 train_time:848552ms step_avg:287.55ms
step:2962/3000 train_loss:3.4655 train_time:848837ms step_avg:287.55ms
step:2963/3000 train_loss:3.3200 train_time:849124ms step_avg:287.55ms
step:2964/3000 train_loss:3.2838 train_time:849410ms step_avg:287.55ms
step:2965/3000 train_loss:3.4159 train_time:849694ms step_avg:287.54ms
step:2966/3000 train_loss:3.4703 train_time:849981ms step_avg:287.54ms
step:2967/3000 train_loss:3.2711 train_time:850267ms step_avg:287.54ms
step:2968/3000 train_loss:3.3427 train_time:850551ms step_avg:287.54ms
step:2969/3000 train_loss:3.3829 train_time:850835ms step_avg:287.54ms
step:2970/3000 train_loss:3.2863 train_time:851121ms step_avg:287.54ms
step:2971/3000 train_loss:3.1744 train_time:851407ms step_avg:287.54ms
step:2972/3000 train_loss:3.2918 train_time:851691ms step_avg:287.54ms
step:2973/3000 train_loss:3.3433 train_time:851977ms step_avg:287.54ms
step:2974/3000 train_loss:3.2064 train_time:852263ms step_avg:287.54ms
step:2975/3000 train_loss:3.4019 train_time:852550ms step_avg:287.54ms
step:2976/3000 train_loss:3.3849 train_time:852834ms step_avg:287.54ms
step:2977/3000 train_loss:3.3915 train_time:853120ms step_avg:287.54ms
step:2978/3000 train_loss:3.3488 train_time:853406ms step_avg:287.54ms
step:2979/3000 train_loss:3.3742 train_time:853691ms step_avg:287.53ms
step:2980/3000 train_loss:3.2250 train_time:853977ms step_avg:287.53ms
step:2981/3000 train_loss:3.0831 train_time:854263ms step_avg:287.53ms
step:2982/3000 train_loss:3.3687 train_time:854550ms step_avg:287.53ms
step:2983/3000 train_loss:3.3230 train_time:854834ms step_avg:287.53ms
step:2984/3000 train_loss:3.3553 train_time:855121ms step_avg:287.53ms
step:2985/3000 train_loss:3.3376 train_time:855406ms step_avg:287.53ms
step:2986/3000 train_loss:3.4243 train_time:855692ms step_avg:287.53ms
step:2987/3000 train_loss:3.4336 train_time:855977ms step_avg:287.53ms
step:2988/3000 train_loss:3.3956 train_time:856264ms step_avg:287.53ms
step:2989/3000 train_loss:3.3952 train_time:856550ms step_avg:287.53ms
step:2990/3000 train_loss:3.2385 train_time:856834ms step_avg:287.53ms
step:2991/3000 train_loss:3.3278 train_time:857120ms step_avg:287.53ms
step:2992/3000 train_loss:3.4052 train_time:857408ms step_avg:287.53ms
step:2993/3000 train_loss:3.4401 train_time:857694ms step_avg:287.53ms
step:2994/3000 train_loss:3.3240 train_time:857980ms step_avg:287.53ms
step:2995/3000 train_loss:3.3333 train_time:858265ms step_avg:287.53ms
step:2996/3000 train_loss:3.3380 train_time:858552ms step_avg:287.53ms
step:2997/3000 train_loss:3.3161 train_time:858838ms step_avg:287.53ms
step:2998/3000 train_loss:3.4561 train_time:859123ms step_avg:287.52ms
step:2999/3000 train_loss:3.2615 train_time:859410ms step_avg:287.52ms
step:3000/3000 train_loss:3.3648 train_time:859695ms step_avg:287.52ms
step:3000/3000 val_loss:3.3602 train_time:859695ms step_avg:287.52ms
