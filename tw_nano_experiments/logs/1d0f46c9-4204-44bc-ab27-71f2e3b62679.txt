====================================================================================================
# NOTE: record from https://github.com/KellerJordan/modded-nanogpt/blob/master/records/track_1_short/2024-10-14_ModernArch/dabaaddd-237c-4ec9-939d-6608a9ed5e27.txt
# ====================================================================================================
import os
import sys
with open(sys.argv[0]) as f:
    code = f.read() # read the code of this file ASAP, for logging
import uuid
import glob
import time
import math
import random
import argparse
from dataclasses import dataclass, field
from typing import Optional, Tuple, Dict, Any

import numpy as np
import torch
from torch import nn
import torch.nn.functional as F
import torch.distributed as dist
import torch._inductor.config as config
from torch.nn.parallel import DistributedDataParallel as DDP

# -----------------------------------------------------------------------------
# Token Importance Weighting Configuration

@dataclass
class TokenWeightingConfig:
    """Configuration for token importance weighting ablations."""
    enabled: bool = False
    function: str = "linear"  # linear, sqrt, log, focal
    clamp_min: float = 0.5
    clamp_max: float = 2.0
    schedule: str = "constant"  # constant, warmup, anneal, cyclical, adaptive
    warmup_steps: int = 1000
    anneal_final_strength: float = 0.3  # for anneal schedule
    cyclical_period: int = 500  # for cyclical schedule
    focal_gamma: float = 2.0  # for focal loss style weighting
    percentile_clamp: bool = False  # use percentile-based clamping instead of fixed bounds
    percentile_low: float = 0.05  # lower percentile for clamping
    percentile_high: float = 0.95  # upper percentile for clamping
    log_weights: bool = True  # whether to log weight statistics
    log_every: int = 50  # log weight stats every N steps

def compute_schedule_strength(
    step: int,
    total_steps: int,
    config: TokenWeightingConfig,
    val_loss: Optional[float] = None
) -> float:
    """
    Compute the weighting strength multiplier based on the schedule.
    Returns a value in [0, 1] that scales the deviation from uniform weighting.
    """
    if config.schedule == "constant":
        return 1.0
    
    elif config.schedule == "warmup":
        # Linear warmup: start uniform, gradually introduce weighting
        return min(step / config.warmup_steps, 1.0)
    
    elif config.schedule == "anneal":
        # Annealing: start with strong weighting, decay toward uniform
        # decay_ratio goes from 1.0 to anneal_final_strength
        progress = step / total_steps
        return 1.0 - progress * (1.0 - config.anneal_final_strength)
    
    elif config.schedule == "cyclical":
        # Sine wave oscillation between weak and strong weighting
        return 0.5 + 0.5 * math.sin(step / config.cyclical_period * 2 * math.pi)
    
    elif config.schedule == "adaptive":
        # Validation-loss-based: strong when loss is high, weaker as loss decreases
        if val_loss is None:
            return 1.0  # Default to full strength if no val loss available
        # Normalize by approximate initial loss (~4.0 for GPT training)
        return min(val_loss / 4.0, 1.0)
    
    else:
        raise ValueError(f"Unknown schedule: {config.schedule}")

def compute_token_weights(
    per_token_loss: torch.Tensor,
    config: TokenWeightingConfig,
    step: int,
    total_steps: int,
    val_loss: Optional[float] = None
) -> Tuple[torch.Tensor, Dict[str, float]]:
    """
    Compute importance weights for tokens based on their loss.
    
    Args:
        per_token_loss: Tensor of shape (batch_size * seq_len,) with per-token losses
        config: TokenWeightingConfig with weighting parameters
        step: Current training step
        total_steps: Total number of training steps
        val_loss: Current validation loss (for adaptive schedule)
    
    Returns:
        weights: Tensor of same shape as per_token_loss with importance weights
        stats: Dictionary with weight statistics for logging
    """
    if not config.enabled:
        return torch.ones_like(per_token_loss), {}
    
    # Detach to prevent gradient flow through weights
    loss_detached = per_token_loss.detach()
    
    # Compute raw weights based on weighting function
    if config.function == "linear":
        # Relative weighting: weight = loss / mean_loss
        mean_loss = loss_detached.mean()
        weights = loss_detached / (mean_loss + 1e-8)
    
    elif config.function == "sqrt":
        # Square root weighting: more moderate than linear
        mean_loss = loss_detached.mean()
        normalized_loss = loss_detached / (mean_loss + 1e-8)
        weights = torch.sqrt(normalized_loss)
    
    elif config.function == "log":
        # Logarithmic weighting: most conservative
        mean_loss = loss_detached.mean()
        normalized_loss = loss_detached / (mean_loss + 1e-8)
        # log1p for numerical stability (log(1 + x))
        weights = torch.log1p(normalized_loss)
    
    elif config.function == "focal":
        # Focal loss style: (loss / max_loss)^gamma
        max_loss = loss_detached.max()
        normalized_loss = loss_detached / (max_loss + 1e-8)
        weights = torch.pow(normalized_loss, config.focal_gamma)
    
    else:
        raise ValueError(f"Unknown weighting function: {config.function}")
    
    # Apply clamping
    if config.percentile_clamp:
        # Dynamic bounds based on percentiles
        p_low = torch.quantile(weights, config.percentile_low)
        p_high = torch.quantile(weights, config.percentile_high)
        weights = weights.clamp(p_low, p_high)
    else:
        # Fixed bounds
        weights = weights.clamp(config.clamp_min, config.clamp_max)
    
    # Apply schedule (interpolate between uniform and computed weights)
    strength = compute_schedule_strength(step, total_steps, config, val_loss)
    # weights = 1.0 + (weights - 1.0) * strength
    # This interpolates: at strength=0, weights=1 (uniform); at strength=1, weights=computed
    weights = 1.0 + (weights - 1.0) * strength
    
    # Normalize weights to have mean 1.0 (preserve expected gradient magnitude)
    weights = weights / (weights.mean() + 1e-8)
    
    # Compute statistics for logging
    stats = {}
    if config.log_weights:
        stats = {
            'weight_mean': weights.mean().item(),
            'weight_std': weights.std().item(),
            'weight_min': weights.min().item(),
            'weight_max': weights.max().item(),
            'weight_gt_1.5': (weights > 1.5).float().mean().item() * 100,  # percentage
            'weight_lt_0.5': (weights < 0.5).float().mean().item() * 100,  # percentage
            'schedule_strength': strength,
        }
    
    return weights, stats

# -----------------------------------------------------------------------------
# Random seed utilities for reproducibility

def set_seed(seed: int, rank: int = 0, deterministic: bool = True):
    """
    Set random seeds for reproducibility across distributed training.
    
    Args:
        seed: Base random seed
        rank: DDP rank (used to offset data sampling seeds)
        deterministic: If True, enable deterministic algorithms (may impact performance)
    """
    # Set Python random seed
    random.seed(seed)
    
    # Set NumPy seed (offset by rank for different data sampling per GPU)
    np.random.seed(seed + rank)
    
    # Set PyTorch seeds
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)  # for multi-GPU
    
    # Configure deterministic behavior
    if deterministic:
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False
        # Enable deterministic algorithms (PyTorch 1.8+)
        if hasattr(torch, 'use_deterministic_algorithms'):
            try:
                torch.use_deterministic_algorithms(True, warn_only=True)
            except Exception:
                pass  # Some operations may not have deterministic implementations
    else:
        # For maximum performance, allow non-deterministic algorithms
        torch.backends.cudnn.deterministic = False
        torch.backends.cudnn.benchmark = True

# -----------------------------------------------------------------------------
# Muon optimizer

def zeropower_via_svd(G, steps=None):
    U, S, V = G.svd()
    return U @ V.T

@torch.compile
def zeropower_via_newtonschulz5(G, steps=10, eps=1e-7):
    """
    Newton-Schulz iteration to compute the zeroth power / orthogonalization of G. We opt to use a
    quintic iteration whose coefficients are selected to maximize the slope at zero. For the purpose
    of minimizing steps, it turns out to be empirically effective to keep increasing the slope at
    zero even beyond the point where the iteration no longer converges all the way to one everywhere
    on the interval. This iteration therefore does not produce UV^T but rather something like US'V^T
    where S' is diagonal with S_{ii}' \sim Uniform(0.5, 1.5), which turns out not to hurt model
    performance at all relative to UV^T, where USV^T = G is the SVD.
    """
    assert len(G.shape) == 2
    a, b, c = (3.4445, -4.7750,  2.0315)
    X = G.bfloat16()
    X /= (X.norm() + eps) # ensure top singular value <= 1
    if G.size(0) > G.size(1):
        X = X.T
    for _ in range(steps):
        A = X @ X.T
        B = A @ X
        X = a * X + b * B + c * A @ B
    if G.size(0) > G.size(1):
        X = X.T
    return X

zeropower_backends = dict(svd=zeropower_via_svd, newtonschulz5=zeropower_via_newtonschulz5)

class Muon(torch.optim.Optimizer):
    """
    Muon - MomentUm Orthogonalized by Newton-schulz

    Muon internally runs standard SGD-momentum, and then performs an orthogonalization post-
    processing step, in which each 2D parameter's update is replaced with the nearest orthogonal
    matrix. To efficiently orthogonalize each update, we use a Newton-Schulz iteration, which has
    the advantage that it can be stably run in bfloat16 on the GPU.

    Some warnings:
    - This optimizer assumes that all parameters passed in are 2D.
    - It should not be used for the embedding layer, the final fully connected layer, or any {0,1}-D
    parameters; those should all be optimized by a standard method (e.g., AdamW).
    - To use it with 4D convolutional filters, it works well to just flatten their last 3 dimensions.
    - We believe it is unlikely to work well for training with small batch size.
    - We believe it may not work well for finetuning pretrained models, but we haven't tested this.
    - We have not yet tried this optimizer for training scenarios larger than NanoGPT (124M).

    Arguments:
        lr: The learning rate used by the internal SGD.
        momentum: The momentum used by the internal SGD.
        nesterov: Whether to use Nesterov-style momentum in the internal SGD. (recommended)
        backend: The chosen backend for the orthogonalization step. (recommended: 'newtonschulz5')
        backend_steps: The number of iteration steps to use in the backend, if it is iterative.
    """
    def __init__(self, params, lr=3e-4, momentum=0.95, nesterov=True, backend='newtonschulz5', backend_steps=5):
        defaults = dict(lr=lr, momentum=momentum, nesterov=nesterov, backend=backend, backend_steps=backend_steps)
        super().__init__(params, defaults)

    def step(self):
        for group in self.param_groups:
            lr = group['lr']
            momentum = group['momentum']
            zeropower_backend = zeropower_backends[group['backend']]
            for p in group['params']:
                g = p.grad
                if g is None:
                    continue
                state = self.state[p]
                if 'momentum_buffer' not in state:
                    state['momentum_buffer'] = torch.zeros_like(g)
                buf = state['momentum_buffer']
                buf.mul_(momentum).add_(g)
                if group['nesterov']:
                    g = g.add(buf, alpha=momentum)
                if g.size(0) == 3 * g.size(1): # split grouped QKV parameters
                    g = torch.cat([zeropower_backend(g1, steps=group['backend_steps']) for g1 in g.split(g.size(1))])
                    scale = g.size(1)**0.5
                else:
                    g = zeropower_backend(g, steps=group['backend_steps'])
                    scale = max(g.size(0), g.size(1))**0.5 # scale to have update.square().mean() == 1
                p.data.add_(g, alpha=-lr * scale)

# -----------------------------------------------------------------------------
# PyTorch nn.Module definitions for the GPT-2 model

class Rotary(torch.nn.Module):

    def __init__(self, dim, base=10000):
        super().__init__()
        self.inv_freq = 1.0 / (base ** (torch.arange(0, dim, 2).float() / dim))
        self.seq_len_cached = None
        self.cos_cached = None
        self.sin_cached = None

    def forward(self, x):
        seq_len = x.shape[1]
        if seq_len != self.seq_len_cached:
            self.seq_len_cached = seq_len
            t = torch.arange(seq_len, device=x.device).type_as(self.inv_freq)
            freqs = torch.outer(t, self.inv_freq).to(x.device)
            self.cos_cached = freqs.cos().bfloat16()
            self.sin_cached = freqs.sin().bfloat16()
        return self.cos_cached[None, :, None, :], self.sin_cached[None, :, None, :]

def apply_rotary_emb(x, cos, sin):
    assert x.ndim == 4 # multihead attention
    d = x.shape[3]//2
    x1 = x[..., :d]
    x2 = x[..., d:]
    y1 = x1 * cos + x2 * sin
    y2 = x1 * (-sin) + x2 * cos
    return torch.cat([y1, y2], 3).type_as(x)

class CausalSelfAttention(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.n_head = config.n_head
        self.n_embd = config.n_embd
        self.head_dim = self.n_embd // self.n_head
        assert self.n_embd % self.n_head == 0
        self.c_q = nn.Linear(self.n_embd, self.n_embd, bias=False)
        self.c_k = nn.Linear(self.n_embd, self.n_embd, bias=False)
        self.c_v = nn.Linear(self.n_embd, self.n_embd, bias=False)
        # output projection
        self.c_proj = nn.Linear(self.n_embd, self.n_embd, bias=False)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977
        self.rotary = Rotary(self.head_dim)

    def forward(self, x):
        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)
        q = self.c_q(x).view(B, T, self.n_head, self.head_dim)
        k = self.c_k(x).view(B, T, self.n_head, self.head_dim)
        v = self.c_v(x).view(B, T, self.n_head, self.head_dim)
        cos, sin = self.rotary(q)
        q, k = apply_rotary_emb(q, cos, sin), apply_rotary_emb(k, cos, sin)
        q, k = F.rms_norm(q, (q.size(-1),)), F.rms_norm(k, (k.size(-1),)) # QK norm suggested by @Grad62304977
        y = F.scaled_dot_product_attention(q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2), is_causal=True)
        y = y.transpose(1, 2).contiguous().view_as(x) # re-assemble all head outputs side by side
        y = self.c_proj(y)
        return y

class MLP(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.c_fc    = nn.Linear(config.n_embd, 4 * config.n_embd, bias=False)
        self.c_proj  = nn.Linear(4 * config.n_embd, config.n_embd, bias=False)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977

    def forward(self, x):
        x = self.c_fc(x)
        x = F.relu(x).square() # https://arxiv.org/abs/2109.08668v2; ~1-2% better than GELU; suggested by @SKYLINEZ007 and @Grad62304977
        x = self.c_proj(x)
        return x

class Block(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.attn = CausalSelfAttention(config)
        self.mlp = MLP(config)

    def forward(self, x):
        x = x + self.attn(F.rms_norm(x, (x.size(-1),)))
        x = x + self.mlp(F.rms_norm(x, (x.size(-1),)))
        return x

# -----------------------------------------------------------------------------
# The main GPT-2 model

@dataclass
class GPTConfig:
    vocab_size : int = 50304
    n_layer : int = 12
    n_head : int = 6 # head dim 128 suggested by @Grad62304977
    n_embd : int = 768

class GPT(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.config = config

        self.transformer = nn.ModuleDict(dict(
            wte = nn.Embedding(config.vocab_size, config.n_embd),
            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),
        ))
        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)
        self.transformer.wte.weight = self.lm_head.weight # https://paperswithcode.com/method/weight-tying

    def forward(self, idx, targets=None, return_logits=True, return_per_token_loss=False):
        """
        Forward pass through the GPT model.
        
        Args:
            idx: Input token indices of shape (batch_size, seq_len)
            targets: Target token indices of shape (batch_size, seq_len)
            return_logits: Whether to return logits
            return_per_token_loss: Whether to return per-token loss (for token weighting)
        
        Returns:
            logits: Output logits (if return_logits=True)
            loss: Scalar loss (mean) or per-token loss tensor (if return_per_token_loss=True)
        """
        # forward the GPT model itself
        x = self.transformer.wte(idx) # token embeddings of shape (b, t, n_embd)
        for block in self.transformer.h:
            x = block(x)
        x = F.rms_norm(x, (x.size(-1),))

        if targets is not None:
            # if we are given some desired targets also calculate the loss
            logits = self.lm_head(x)
            logits = logits.float() # use tf32/fp32 for logits
            
            if return_per_token_loss:
                # Return per-token loss for token importance weighting
                # Shape: (batch_size * seq_len,)
                per_token_loss = F.cross_entropy(
                    logits.view(-1, logits.size(-1)), 
                    targets.view(-1), 
                    ignore_index=-1,
                    reduction='none'
                )
                loss = per_token_loss  # Return unreduced loss
            else:
                loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)
        else:
            # inference-time mini-optimization: only forward the lm_head on the very last position
            logits = self.lm_head(x[:, [-1], :]) # note: using list [-1] to preserve the time dim
            logits = logits.float() # use tf32/fp32 for logits
            loss = None

        # there are performance reasons why not returning logits is prudent, if not needed
        if not return_logits:
            logits = None

        return logits, loss

# -----------------------------------------------------------------------------
# Our own simple Distributed Data Loader

def _peek_data_shard(filename):
    # only reads the header, returns header data
    with open(filename, "rb") as f:
        # first read the header, which is 256 int32 integers (4 bytes each)
        header = np.frombuffer(f.read(256*4), dtype=np.int32)
    if header[0] != 20240520:
        print("ERROR: magic number mismatch in the data .bin file!")
        print("---> HINT: Are you passing in a correct file with --input_bin?")
        print("---> HINT: Dataset encoding changed recently, re-run data prepro or refer again to README")
        print("---> HINT: For example re-run: `python dev/data/tinyshakespeare.py`, then re-try")
        exit(1)
    assert header[1] == 1, "unsupported version"
    ntok = header[2] # number of tokens (claimed)
    return ntok # for now just return the number of tokens

def _load_data_shard(filename):
    with open(filename, "rb") as f:
        # first read the header, which is 256 int32 integers (4 bytes each)
        header = np.frombuffer(f.read(256*4), dtype=np.int32)
        assert header[0] == 20240520, "magic number mismatch in the data .bin file"
        assert header[1] == 1, "unsupported version"
        ntok = header[2] # number of tokens (claimed)
        # the rest of it are tokens, stored as uint16
        tokens = np.frombuffer(f.read(), dtype=np.uint16)
    assert len(tokens) == ntok, "number of tokens read does not match header?"
    return tokens

class DistributedDataLoader:
    def __init__(self, filename_pattern, B, T, process_rank, num_processes, seed=None):
        self.process_rank = process_rank
        self.num_processes = num_processes
        self.B = B
        self.T = T
        self.seed = seed

        # glob files that match the pattern
        self.files = sorted(glob.glob(filename_pattern))
        assert len(self.files) > 0, f"did not find any files that match the pattern {filename_pattern}"

        # load and validate all data shards, count number of tokens in total
        ntok_total = 0
        for fname in self.files:
            shard_ntok = _peek_data_shard(fname)
            assert shard_ntok >= num_processes * B * T + 1
            ntok_total += int(shard_ntok)
        self.ntok_total = ntok_total

        # kick things off
        self.reset()

    def reset(self):
        self.current_shard = 0
        self.current_position = self.process_rank * self.B * self.T
        self.tokens = _load_data_shard(self.files[self.current_shard])

    def advance(self): # advance to next data shard
        self.current_shard = (self.current_shard + 1) % len(self.files)
        self.current_position = self.process_rank * self.B * self.T
        self.tokens = _load_data_shard(self.files[self.current_shard])

    def next_batch(self):
        B = self.B
        T = self.T
        buf = self.tokens[self.current_position : self.current_position+B*T+1]
        buf = torch.tensor(buf.astype(np.int32), dtype=torch.long)
        x = (buf[:-1]).view(B, T) # inputs
        y = (buf[1:]).view(B, T) # targets
        # advance current position and load next shard if necessary
        self.current_position += B * T * self.num_processes
        if self.current_position + (B * T * self.num_processes + 1) > len(self.tokens):
            self.advance()
        return x.cuda(), y.cuda()

# -----------------------------------------------------------------------------
# int main

@dataclass
class Hyperparameters:
    # data hyperparams
    input_bin : str = 'data/fineweb10B/fineweb_train_*.bin' # input .bin to train on
    input_val_bin : str = 'data/fineweb10B/fineweb_val_*.bin' # input .bin to eval validation loss on
    # optimization hyperparams
    batch_size : int = 8*64 # batch size, in sequences, across all devices
    device_batch_size : int = 64 # batch size, in sequences, per device
    sequence_length : int = 1024 # sequence length, in tokens
    num_iterations : int = 5100 # number of iterations to run
    learning_rate : float = 0.0036
    warmup_iters : int = 0
    warmdown_iters : int = 1450 # number of iterations of linear warmup/warmdown for triangular or trapezoidal schedule
    weight_decay : float = 0
    # evaluation and logging hyperparams
    val_loss_every : int = 125 # every how many steps to evaluate val loss? 0 for only at the end
    val_tokens : int = 10485760 # how many tokens of validation data? it's important to keep this fixed for consistent comparisons
    save_every : int = 0 # every how many steps to save the checkpoint? 0 for only at the end
    # reproducibility hyperparams
    seed : int = None # random seed for reproducibility (None = no seeding, uses system entropy)
    deterministic : bool = False # if True, use deterministic algorithms (slower but reproducible)
    # token weighting hyperparams (for ablations)
    tw_enabled : bool = False  # enable token importance weighting
    tw_function : str = "linear"  # weighting function: linear, sqrt, log, focal
    tw_clamp_min : float = 0.5  # minimum weight clamp
    tw_clamp_max : float = 2.0  # maximum weight clamp
    tw_schedule : str = "constant"  # schedule: constant, warmup, anneal, cyclical, adaptive
    tw_warmup_steps : int = 1000  # warmup steps for warmup schedule
    tw_anneal_final : float = 0.3  # final strength for anneal schedule
    tw_cyclical_period : int = 500  # period for cyclical schedule
    tw_focal_gamma : float = 2.0  # gamma for focal loss style weighting
    tw_percentile_clamp : bool = False  # use percentile-based clamping
    tw_percentile_low : float = 0.05  # lower percentile for clamping
    tw_percentile_high : float = 0.95  # upper percentile for clamping
    tw_log_weights : bool = True  # log weight statistics
    tw_log_every : int = 50  # log weight stats every N steps

def parse_args():
    """Parse command line arguments and return Hyperparameters and TokenWeightingConfig."""
    parser = argparse.ArgumentParser(description='NanoGPT Training with Token Importance Weighting')
    
    # Data hyperparams
    parser.add_argument('--input_bin', type=str, default='../fineweb10B/fineweb_train_*.bin')
    parser.add_argument('--input_val_bin', type=str, default='../fineweb10B/fineweb_val_*.bin')
    
    # Optimization hyperparams
    parser.add_argument('--batch_size', type=int, default=8*64)
    parser.add_argument('--device_batch_size', type=int, default=64)
    parser.add_argument('--sequence_length', type=int, default=1024)
    parser.add_argument('--num_iterations', type=int, default=5100)
    parser.add_argument('--learning_rate', type=float, default=0.0036)
    parser.add_argument('--warmup_iters', type=int, default=0)
    parser.add_argument('--warmdown_iters', type=int, default=1450)
    parser.add_argument('--weight_decay', type=float, default=0)
    
    # Evaluation and logging hyperparams
    parser.add_argument('--val_loss_every', type=int, default=125)
    parser.add_argument('--val_tokens', type=int, default=10485760)
    parser.add_argument('--save_every', type=int, default=0)
    
    # Reproducibility hyperparams
    parser.add_argument('--seed', type=int, default=None)
    parser.add_argument('--deterministic', action='store_true')
    
    # Token weighting hyperparams (for ablations)
    parser.add_argument('--tw_enabled', action='store_true', help='Enable token importance weighting')
    parser.add_argument('--tw_function', type=str, default='linear', 
                        choices=['linear', 'sqrt', 'log', 'focal'],
                        help='Weighting function')
    parser.add_argument('--tw_clamp_min', type=float, default=0.5, help='Minimum weight clamp')
    parser.add_argument('--tw_clamp_max', type=float, default=2.0, help='Maximum weight clamp')
    parser.add_argument('--tw_schedule', type=str, default='constant',
                        choices=['constant', 'warmup', 'anneal', 'cyclical', 'adaptive'],
                        help='Weighting schedule')
    parser.add_argument('--tw_warmup_steps', type=int, default=1000, help='Warmup steps')
    parser.add_argument('--tw_anneal_final', type=float, default=0.3, help='Final strength for anneal')
    parser.add_argument('--tw_cyclical_period', type=int, default=500, help='Period for cyclical')
    parser.add_argument('--tw_focal_gamma', type=float, default=2.0, help='Gamma for focal loss')
    parser.add_argument('--tw_percentile_clamp', action='store_true', help='Use percentile clamping')
    parser.add_argument('--tw_percentile_low', type=float, default=0.05, help='Lower percentile')
    parser.add_argument('--tw_percentile_high', type=float, default=0.95, help='Upper percentile')
    parser.add_argument('--tw_log_weights', action='store_true', help='Log weight statistics')
    parser.add_argument('--tw_log_every', type=int, default=50, help='Log weights every N steps')
    
    parsed_args = parser.parse_args()
    
    # Create Hyperparameters
    args = Hyperparameters(
        input_bin=parsed_args.input_bin,
        input_val_bin=parsed_args.input_val_bin,
        batch_size=parsed_args.batch_size,
        device_batch_size=parsed_args.device_batch_size,
        sequence_length=parsed_args.sequence_length,
        num_iterations=parsed_args.num_iterations,
        learning_rate=parsed_args.learning_rate,
        warmup_iters=parsed_args.warmup_iters,
        warmdown_iters=parsed_args.warmdown_iters,
        weight_decay=parsed_args.weight_decay,
        val_loss_every=parsed_args.val_loss_every,
        val_tokens=parsed_args.val_tokens,
        save_every=parsed_args.save_every,
        seed=parsed_args.seed,
        deterministic=parsed_args.deterministic,
        tw_enabled=parsed_args.tw_enabled,
        tw_function=parsed_args.tw_function,
        tw_clamp_min=parsed_args.tw_clamp_min,
        tw_clamp_max=parsed_args.tw_clamp_max,
        tw_schedule=parsed_args.tw_schedule,
        tw_warmup_steps=parsed_args.tw_warmup_steps,
        tw_anneal_final=parsed_args.tw_anneal_final,
        tw_cyclical_period=parsed_args.tw_cyclical_period,
        tw_focal_gamma=parsed_args.tw_focal_gamma,
        tw_percentile_clamp=parsed_args.tw_percentile_clamp,
        tw_percentile_low=parsed_args.tw_percentile_low,
        tw_percentile_high=parsed_args.tw_percentile_high,
        tw_log_weights=parsed_args.tw_log_weights,
        tw_log_every=parsed_args.tw_log_every,
    )
    
    # Create TokenWeightingConfig
    tw_config = TokenWeightingConfig(
        enabled=parsed_args.tw_enabled,
        function=parsed_args.tw_function,
        clamp_min=parsed_args.tw_clamp_min,
        clamp_max=parsed_args.tw_clamp_max,
        schedule=parsed_args.tw_schedule,
        warmup_steps=parsed_args.tw_warmup_steps,
        anneal_final_strength=parsed_args.tw_anneal_final,
        cyclical_period=parsed_args.tw_cyclical_period,
        focal_gamma=parsed_args.tw_focal_gamma,
        percentile_clamp=parsed_args.tw_percentile_clamp,
        percentile_low=parsed_args.tw_percentile_low,
        percentile_high=parsed_args.tw_percentile_high,
        log_weights=parsed_args.tw_log_weights,
        log_every=parsed_args.tw_log_every,
    )
    
    return args, tw_config

# Parse arguments
args, tw_config = parse_args()

# set up DDP (distributed data parallel). torchrun sets this env variable
assert torch.cuda.is_available()
dist.init_process_group(backend='nccl')
ddp_rank = int(os.environ['RANK'])
ddp_local_rank = int(os.environ['LOCAL_RANK'])
ddp_world_size = int(os.environ['WORLD_SIZE'])
device = f'cuda:{ddp_local_rank}'
torch.cuda.set_device(device)
print(f"using device: {device}")
master_process = (ddp_rank == 0) # this process will do logging, checkpointing etc.

# Set random seeds for reproducibility (must be done after DDP init but before model creation)
if args.seed is not None:
    set_seed(args.seed, rank=ddp_rank, deterministic=args.deterministic)
    if master_process:
        print(f"Random seed set to {args.seed} (deterministic={args.deterministic})")

# convenience variables
B, T = args.device_batch_size, args.sequence_length
# calculate the number of steps to take in the val loop.
assert args.val_tokens % (B * T * ddp_world_size) == 0
val_steps = args.val_tokens // (B * T * ddp_world_size)
# calculate the steps of gradient accumulation required to attain the desired global batch size.
assert args.batch_size % (B * ddp_world_size) == 0
train_accumulation_steps = args.batch_size // (B * ddp_world_size)

# load tokens
train_loader = DistributedDataLoader(args.input_bin, B, T, ddp_rank, ddp_world_size, seed=args.seed)
val_loader = DistributedDataLoader(args.input_val_bin, B, T, ddp_rank, ddp_world_size, seed=args.seed)
if master_process:
    print(f"Training DataLoader: total number of tokens: {train_loader.ntok_total} across {len(train_loader.files)} files")
    print(f"Validation DataLoader: total number of tokens: {val_loader.ntok_total} across {len(val_loader.files)} files")
x, y = train_loader.next_batch()

# there are only 50257 unique GPT-2 tokens; we extend to nearest multiple of 128 for efficiency. suggested to me by @Grad62304977.
# this originates from Karpathy's experiments.
num_vocab = 50304
model = GPT(GPTConfig(vocab_size=num_vocab, n_layer=12, n_head=6, n_embd=768))
model = model.cuda()
if hasattr(config, "coordinate_descent_tuning"):
    config.coordinate_descent_tuning = True # suggested by @Chillee
model = torch.compile(model)
# here we wrap model into DDP container
model = DDP(model, device_ids=[ddp_local_rank])
raw_model = model.module # always contains the "raw" unwrapped model
ctx = torch.amp.autocast(device_type='cuda', dtype=torch.bfloat16)

# init the optimizer(s)
optimizer1 = torch.optim.AdamW(raw_model.lm_head.parameters(), lr=args.learning_rate, betas=(0.9, 0.95),
                               weight_decay=args.weight_decay, fused=True)
optimizer2 = Muon(raw_model.transformer.h.parameters(), lr=0.1*args.learning_rate, momentum=0.95)
optimizers = [optimizer1, optimizer2]
# learning rate decay scheduler (linear warmup and warmdown)
def get_lr(it):
    assert it <= args.num_iterations
    # 1) linear warmup for warmup_iters steps
    if it < args.warmup_iters:
        return (it+1) / args.warmup_iters
    # 2) constant lr for a while
    elif it < args.num_iterations - args.warmdown_iters:
        return 1.0
    # 3) linear warmdown
    else:
        decay_ratio = (args.num_iterations - it) / args.warmdown_iters
        return decay_ratio
schedulers = [torch.optim.lr_scheduler.LambdaLR(opt, get_lr) for opt in optimizers]

# begin logging
if master_process:
    run_id = str(uuid.uuid4())
    logdir = 'logs/%s/' % run_id
    os.makedirs(logdir, exist_ok=True)
    logfile = 'logs/%s.txt' % run_id
    # create the log file
    with open(logfile, "w") as f:
        # begin the log by printing this file (the Python code)
        f.write('='*100 + '\n')
        f.write(code)
        f.write('='*100 + '\n')
        # log information about the hardware/software environment this is running on
        # and print the full `nvidia-smi` to file
        f.write(f"Running pytorch {torch.version.__version__} compiled for CUDA {torch.version.cuda}\nnvidia-smi:\n")
        import subprocess
        result = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
        f.write(f'{result.stdout}\n')
        f.write('='*100 + '\n')
        # log the random seed if set
        if args.seed is not None:
            f.write(f"Random seed: {args.seed} (deterministic={args.deterministic})\n")
            f.write('='*100 + '\n')
        # log token weighting configuration
        if tw_config.enabled:
            f.write(f"Token Weighting Configuration:\n")
            f.write(f"  function: {tw_config.function}\n")
            f.write(f"  clamp: [{tw_config.clamp_min}, {tw_config.clamp_max}]\n")
            f.write(f"  schedule: {tw_config.schedule}\n")
            if tw_config.schedule == 'warmup':
                f.write(f"  warmup_steps: {tw_config.warmup_steps}\n")
            elif tw_config.schedule == 'anneal':
                f.write(f"  anneal_final_strength: {tw_config.anneal_final_strength}\n")
            elif tw_config.schedule == 'cyclical':
                f.write(f"  cyclical_period: {tw_config.cyclical_period}\n")
            if tw_config.function == 'focal':
                f.write(f"  focal_gamma: {tw_config.focal_gamma}\n")
            if tw_config.percentile_clamp:
                f.write(f"  percentile_clamp: [{tw_config.percentile_low}, {tw_config.percentile_high}]\n")
            f.write('='*100 + '\n')
        else:
            f.write("Token Weighting: DISABLED (baseline run)\n")
            f.write('='*100 + '\n')
    
    # Also log token weighting config to console
    if tw_config.enabled:
        print(f"Token Weighting: ENABLED")
        print(f"  function={tw_config.function}, clamp=[{tw_config.clamp_min}, {tw_config.clamp_max}], schedule={tw_config.schedule}")
    else:
        print(f"Token Weighting: DISABLED (baseline run)")

# Track validation loss for adaptive schedule
current_val_loss = None

training_time_ms = 0
# start the clock
torch.cuda.synchronize()
t0 = time.time()
# begin training
train_loader.reset()
for step in range(args.num_iterations + 1):
    last_step = (step == args.num_iterations)
    # This effectively ignores timing first 10 steps, which are slower for weird reasons.
    # Alternately, and slightly more correctly in terms of benchmarking, we could do 10
    # steps with dummy data first, and then re-initialize the model and reset the loader.
    if step == 10:
        training_time_ms = 0
        t0 = time.time()
    timed_steps = float('nan') if step <= 11 else (step - 10) + 1 # <= 11 to avoid bug in val

    # once in a while evaluate the validation dataset
    if (last_step or (args.val_loss_every > 0 and step % args.val_loss_every == 0)):
        # stop the clock
        torch.cuda.synchronize()
        training_time_ms += 1000 * (time.time() - t0)
        # run validation batches
        model.eval()
        val_loader.reset()
        val_loss = 0.0
        for _ in range(val_steps):
            x_val, y_val = val_loader.next_batch()
            with ctx: # of course, we'd like to use no_grad() here too, but that creates a torch.compile error for some reason
                _, loss = model(x_val, y_val, return_logits=False)
                val_loss += loss.detach()
                del loss
        dist.all_reduce(val_loss, op=dist.ReduceOp.AVG)
        val_loss /= val_steps
        current_val_loss = val_loss.item()  # Store for adaptive schedule
        # log val loss to console and to logfile
        if master_process:
            print(f'step:{step}/{args.num_iterations} val_loss:{val_loss:.4f} train_time:{training_time_ms:.0f}ms step_avg:{training_time_ms/(timed_steps-1):.2f}ms')
            with open(logfile, "a") as f:
                f.write(f'step:{step}/{args.num_iterations} val_loss:{val_loss:.4f} train_time:{training_time_ms:.0f}ms step_avg:{training_time_ms/(timed_steps-1):.2f}ms\n')
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.time()

    if master_process and (last_step or (args.save_every > 0 and step % args.save_every == 0)):
        # stop the clock
        torch.cuda.synchronize()
        training_time_ms += 1000 * (time.time() - t0)
        # save the state of the training process
        log = dict(step=step, code=code, model=raw_model.state_dict(), optimizers=[opt.state_dict() for opt in optimizers])
        # also save the seed for reproducibility
        if args.seed is not None:
            log['seed'] = args.seed
        # save token weighting config
        if tw_config.enabled:
            log['tw_config'] = {
                'function': tw_config.function,
                'clamp_min': tw_config.clamp_min,
                'clamp_max': tw_config.clamp_max,
                'schedule': tw_config.schedule,
            }
        torch.save(log, 'logs/%s/state_step%06d.pt' % (run_id, step))
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.time()

    # bit confusing: we want to make sure to eval on 0th iteration
    # but also after the very last iteration. so we loop for step <= num_iterations
    # instead of just < num_iterations (one extra due to <=), only to do
    # the validation/sampling one last time, and then we break right here as we're done.
    if last_step:
        break

    # --------------- TRAINING SECTION BEGIN -----------------
    model.train()
    
    # Accumulate weight statistics across accumulation steps
    accumulated_weight_stats = {}
    
    for i in range(1, train_accumulation_steps+1):
        # forward pass
        with ctx:
            if tw_config.enabled:
                # Get per-token loss for token weighting
                _, per_token_loss = model(x, y, return_logits=False, return_per_token_loss=True)
                
                # Compute token importance weights
                weights, weight_stats = compute_token_weights(
                    per_token_loss,
                    tw_config,
                    step,
                    args.num_iterations,
                    current_val_loss
                )
                
                # Apply weights and compute mean loss
                weighted_loss = per_token_loss * weights
                loss = weighted_loss.mean()
                train_loss = per_token_loss.mean().detach()  # Log unweighted loss for fair comparison
                
                # Accumulate weight stats
                if weight_stats and (step % tw_config.log_every == 0):
                    for k, v in weight_stats.items():
                        if k not in accumulated_weight_stats:
                            accumulated_weight_stats[k] = []
                        accumulated_weight_stats[k].append(v)
            else:
                # Standard training without token weighting
                _, loss = model(x, y, return_logits=False)
                train_loss = loss.detach()
        
        # advance the dataset for the next batch
        x, y = train_loader.next_batch()
        # backward pass
        if i < train_accumulation_steps:
            with model.no_sync(): # there's no need to sync gradients every accumulation step
                loss.backward()
        else:
            loss.backward() # just sync on the last step
    for p in model.parameters():
        p.grad /= train_accumulation_steps
    # step the optimizers and schedulers
    for opt, sched in zip(optimizers, schedulers):
        opt.step()
        sched.step()
    # null the gradients
    model.zero_grad(set_to_none=True)
    # --------------- TRAINING SECTION END -------------------
    # everything that follows now is just diagnostics, prints, logging, etc.

    #dist.all_reduce(train_loss, op=dist.ReduceOp.AVG) # all-reducing the training loss would be more correct in terms of logging, but slower
    if master_process:
        approx_time = training_time_ms + 1000 * (time.time() - t0)
        
        # Build log message
        log_msg = f"step:{step+1}/{args.num_iterations} train_loss:{train_loss.item():.4f} train_time:{approx_time:.0f}ms step_avg:{approx_time/timed_steps:.2f}ms"
        
        # Add weight statistics if enabled and this is a logging step
        if tw_config.enabled and tw_config.log_weights and accumulated_weight_stats and (step % tw_config.log_every == 0):
            # Average the accumulated stats
            avg_weight_stats = {k: sum(v)/len(v) for k, v in accumulated_weight_stats.items()}
            weight_log = f" w_mean:{avg_weight_stats.get('weight_mean', 1.0):.3f} w_std:{avg_weight_stats.get('weight_std', 0.0):.3f} w_min:{avg_weight_stats.get('weight_min', 1.0):.3f} w_max:{avg_weight_stats.get('weight_max', 1.0):.3f}"
            log_msg += weight_log
        
        print(log_msg)
        with open(logfile, "a") as f:
            f.write(log_msg + "\n")

if master_process:
    print(f"peak memory consumption: {torch.cuda.max_memory_allocated() // 1024 // 1024} MiB")====================================================================================================
Running pytorch 2.8.0+cu128 compiled for CUDA 12.8
nvidia-smi:
Tue Dec  9 20:24:41 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.195.03             Driver Version: 570.195.03     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA H100 PCIe               On  |   00000000:00:08.0 Off |                    0 |
| N/A   46C    P0             83W /  310W |    2363MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA H100 PCIe               On  |   00000000:00:09.0 Off |                    0 |
| N/A   44C    P0             84W /  310W |    2363MiB /  81559MiB |     32%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA H100 PCIe               On  |   00000000:00:0A.0 Off |                    0 |
| N/A   49C    P0             89W /  310W |    2363MiB /  81559MiB |     20%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA H100 PCIe               On  |   00000000:00:0B.0 Off |                    0 |
| N/A   45C    P0             86W /  310W |    2363MiB /  81559MiB |     32%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   4  NVIDIA H100 PCIe               On  |   00000000:00:0C.0 Off |                    0 |
| N/A   44C    P0             82W /  310W |    2363MiB /  81559MiB |     35%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   5  NVIDIA H100 PCIe               On  |   00000000:00:0D.0 Off |                    0 |
| N/A   49C    P0             86W /  310W |    2363MiB /  81559MiB |     28%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   6  NVIDIA H100 PCIe               On  |   00000000:00:0E.0 Off |                    0 |
| N/A   53C    P0             88W /  310W |    2363MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   7  NVIDIA H100 PCIe               On  |   00000000:00:0F.0 Off |                    0 |
| N/A   46C    P0             84W /  310W |    2363MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A           47942      C   /usr/local/bin/python                  2354MiB |
|    1   N/A  N/A           47943      C   /usr/local/bin/python                  2354MiB |
|    2   N/A  N/A           47944      C   /usr/local/bin/python                  2354MiB |
|    3   N/A  N/A           47945      C   /usr/local/bin/python                  2354MiB |
|    4   N/A  N/A           47946      C   /usr/local/bin/python                  2354MiB |
|    5   N/A  N/A           47947      C   /usr/local/bin/python                  2354MiB |
|    6   N/A  N/A           47948      C   /usr/local/bin/python                  2354MiB |
|    7   N/A  N/A           47949      C   /usr/local/bin/python                  2354MiB |
+-----------------------------------------------------------------------------------------+

====================================================================================================
Random seed: 456 (deterministic=False)
====================================================================================================
Token Weighting: DISABLED (baseline run)
====================================================================================================
step:0/3000 val_loss:16.0011 train_time:277ms step_avg:nanms
step:1/3000 train_loss:15.9963 train_time:56637ms step_avg:nanms
step:2/3000 train_loss:9.5212 train_time:57804ms step_avg:nanms
step:3/3000 train_loss:8.6805 train_time:58089ms step_avg:nanms
step:4/3000 train_loss:7.9743 train_time:58372ms step_avg:nanms
step:5/3000 train_loss:7.4930 train_time:58656ms step_avg:nanms
step:6/3000 train_loss:7.6509 train_time:58936ms step_avg:nanms
step:7/3000 train_loss:7.1464 train_time:59225ms step_avg:nanms
step:8/3000 train_loss:7.4721 train_time:59513ms step_avg:nanms
step:9/3000 train_loss:7.1797 train_time:59795ms step_avg:nanms
step:10/3000 train_loss:6.9979 train_time:60080ms step_avg:nanms
step:11/3000 train_loss:6.9254 train_time:284ms step_avg:nanms
step:12/3000 train_loss:6.8533 train_time:568ms step_avg:nanms
step:13/3000 train_loss:6.6672 train_time:851ms step_avg:283.83ms
step:14/3000 train_loss:6.6683 train_time:1134ms step_avg:283.49ms
step:15/3000 train_loss:6.6106 train_time:1420ms step_avg:284.03ms
step:16/3000 train_loss:6.5419 train_time:1705ms step_avg:284.19ms
step:17/3000 train_loss:6.5417 train_time:1990ms step_avg:284.36ms
step:18/3000 train_loss:6.5518 train_time:2273ms step_avg:284.08ms
step:19/3000 train_loss:6.3841 train_time:2554ms step_avg:283.73ms
step:20/3000 train_loss:6.4118 train_time:2837ms step_avg:283.72ms
step:21/3000 train_loss:6.0723 train_time:3127ms step_avg:284.25ms
step:22/3000 train_loss:6.4320 train_time:3410ms step_avg:284.19ms
step:23/3000 train_loss:6.6318 train_time:3692ms step_avg:283.99ms
step:24/3000 train_loss:6.3324 train_time:3974ms step_avg:283.84ms
step:25/3000 train_loss:6.4616 train_time:4257ms step_avg:283.80ms
step:26/3000 train_loss:6.1717 train_time:4543ms step_avg:283.92ms
step:27/3000 train_loss:6.0833 train_time:4830ms step_avg:284.10ms
step:28/3000 train_loss:6.2370 train_time:5112ms step_avg:283.98ms
step:29/3000 train_loss:5.9137 train_time:5396ms step_avg:283.99ms
step:30/3000 train_loss:6.2025 train_time:5679ms step_avg:283.97ms
step:31/3000 train_loss:6.0260 train_time:5965ms step_avg:284.03ms
step:32/3000 train_loss:5.9949 train_time:6255ms step_avg:284.33ms
step:33/3000 train_loss:5.8167 train_time:6540ms step_avg:284.37ms
step:34/3000 train_loss:6.0968 train_time:6827ms step_avg:284.47ms
step:35/3000 train_loss:6.0359 train_time:7111ms step_avg:284.45ms
step:36/3000 train_loss:6.1713 train_time:7395ms step_avg:284.43ms
step:37/3000 train_loss:6.1116 train_time:7679ms step_avg:284.41ms
step:38/3000 train_loss:6.0125 train_time:7963ms step_avg:284.41ms
step:39/3000 train_loss:5.8977 train_time:8250ms step_avg:284.47ms
step:40/3000 train_loss:5.9115 train_time:8532ms step_avg:284.42ms
step:41/3000 train_loss:5.8312 train_time:8818ms step_avg:284.46ms
step:42/3000 train_loss:5.8509 train_time:9104ms step_avg:284.50ms
step:43/3000 train_loss:5.7263 train_time:9390ms step_avg:284.53ms
step:44/3000 train_loss:5.8335 train_time:9673ms step_avg:284.49ms
step:45/3000 train_loss:5.7919 train_time:9958ms step_avg:284.52ms
step:46/3000 train_loss:5.9459 train_time:10243ms step_avg:284.54ms
step:47/3000 train_loss:5.7441 train_time:10530ms step_avg:284.59ms
step:48/3000 train_loss:5.6147 train_time:10813ms step_avg:284.55ms
step:49/3000 train_loss:5.8244 train_time:11098ms step_avg:284.57ms
step:50/3000 train_loss:5.7039 train_time:11383ms step_avg:284.58ms
step:51/3000 train_loss:5.8381 train_time:11668ms step_avg:284.59ms
step:52/3000 train_loss:5.7116 train_time:11952ms step_avg:284.56ms
step:53/3000 train_loss:5.5634 train_time:12234ms step_avg:284.52ms
step:54/3000 train_loss:5.7030 train_time:12521ms step_avg:284.56ms
step:55/3000 train_loss:5.5811 train_time:12806ms step_avg:284.58ms
step:56/3000 train_loss:5.9221 train_time:13090ms step_avg:284.57ms
step:57/3000 train_loss:5.5844 train_time:13373ms step_avg:284.53ms
step:58/3000 train_loss:5.4527 train_time:13656ms step_avg:284.51ms
step:59/3000 train_loss:5.6008 train_time:13942ms step_avg:284.53ms
step:60/3000 train_loss:5.5697 train_time:14228ms step_avg:284.56ms
step:61/3000 train_loss:5.6582 train_time:14511ms step_avg:284.54ms
step:62/3000 train_loss:5.4334 train_time:14793ms step_avg:284.47ms
step:63/3000 train_loss:5.5315 train_time:15077ms step_avg:284.46ms
step:64/3000 train_loss:5.5121 train_time:15361ms step_avg:284.46ms
step:65/3000 train_loss:5.2077 train_time:15647ms step_avg:284.50ms
step:66/3000 train_loss:5.3317 train_time:15932ms step_avg:284.49ms
step:67/3000 train_loss:5.4926 train_time:16214ms step_avg:284.46ms
step:68/3000 train_loss:5.3546 train_time:16498ms step_avg:284.45ms
step:69/3000 train_loss:5.6164 train_time:16782ms step_avg:284.44ms
step:70/3000 train_loss:5.2560 train_time:17068ms step_avg:284.46ms
step:71/3000 train_loss:5.2885 train_time:17352ms step_avg:284.46ms
step:72/3000 train_loss:5.4970 train_time:17637ms step_avg:284.47ms
step:73/3000 train_loss:5.4268 train_time:17922ms step_avg:284.48ms
step:74/3000 train_loss:5.3014 train_time:18209ms step_avg:284.51ms
step:75/3000 train_loss:5.4234 train_time:18491ms step_avg:284.48ms
step:76/3000 train_loss:5.4197 train_time:18777ms step_avg:284.51ms
step:77/3000 train_loss:5.3602 train_time:19062ms step_avg:284.51ms
step:78/3000 train_loss:5.4508 train_time:19349ms step_avg:284.54ms
step:79/3000 train_loss:5.5144 train_time:19633ms step_avg:284.54ms
step:80/3000 train_loss:5.2989 train_time:19917ms step_avg:284.53ms
step:81/3000 train_loss:5.4171 train_time:20204ms step_avg:284.57ms
step:82/3000 train_loss:5.1795 train_time:20490ms step_avg:284.58ms
step:83/3000 train_loss:5.3470 train_time:20773ms step_avg:284.56ms
step:84/3000 train_loss:5.3003 train_time:21057ms step_avg:284.56ms
step:85/3000 train_loss:5.2828 train_time:21342ms step_avg:284.57ms
step:86/3000 train_loss:5.1380 train_time:21628ms step_avg:284.58ms
step:87/3000 train_loss:5.3590 train_time:21911ms step_avg:284.56ms
step:88/3000 train_loss:5.2615 train_time:22193ms step_avg:284.53ms
step:89/3000 train_loss:5.3212 train_time:22478ms step_avg:284.53ms
step:90/3000 train_loss:5.2709 train_time:22764ms step_avg:284.55ms
step:91/3000 train_loss:5.2055 train_time:23049ms step_avg:284.56ms
step:92/3000 train_loss:5.1816 train_time:23333ms step_avg:284.54ms
step:93/3000 train_loss:5.3338 train_time:23616ms step_avg:284.52ms
step:94/3000 train_loss:5.1300 train_time:23902ms step_avg:284.54ms
step:95/3000 train_loss:5.1568 train_time:24188ms step_avg:284.57ms
step:96/3000 train_loss:5.1840 train_time:24471ms step_avg:284.55ms
step:97/3000 train_loss:5.1016 train_time:24756ms step_avg:284.55ms
step:98/3000 train_loss:5.1748 train_time:25041ms step_avg:284.56ms
step:99/3000 train_loss:5.0972 train_time:25329ms step_avg:284.59ms
step:100/3000 train_loss:5.2192 train_time:25613ms step_avg:284.58ms
step:101/3000 train_loss:5.1905 train_time:25898ms step_avg:284.59ms
step:102/3000 train_loss:5.1016 train_time:26182ms step_avg:284.59ms
step:103/3000 train_loss:5.1980 train_time:26468ms step_avg:284.60ms
step:104/3000 train_loss:5.1425 train_time:26752ms step_avg:284.59ms
step:105/3000 train_loss:4.9924 train_time:27034ms step_avg:284.57ms
step:106/3000 train_loss:5.1007 train_time:27319ms step_avg:284.58ms
step:107/3000 train_loss:5.3092 train_time:27607ms step_avg:284.61ms
step:108/3000 train_loss:5.0750 train_time:27891ms step_avg:284.60ms
step:109/3000 train_loss:4.8617 train_time:28173ms step_avg:284.58ms
step:110/3000 train_loss:5.0489 train_time:28459ms step_avg:284.59ms
step:111/3000 train_loss:5.0284 train_time:28746ms step_avg:284.61ms
step:112/3000 train_loss:4.9843 train_time:29031ms step_avg:284.62ms
step:113/3000 train_loss:5.1023 train_time:29314ms step_avg:284.60ms
step:114/3000 train_loss:5.0221 train_time:29599ms step_avg:284.61ms
step:115/3000 train_loss:4.8858 train_time:29883ms step_avg:284.60ms
step:116/3000 train_loss:5.0354 train_time:30169ms step_avg:284.61ms
step:117/3000 train_loss:4.9492 train_time:30453ms step_avg:284.60ms
step:118/3000 train_loss:4.9093 train_time:30736ms step_avg:284.59ms
step:119/3000 train_loss:5.0609 train_time:31021ms step_avg:284.60ms
step:120/3000 train_loss:5.0113 train_time:31308ms step_avg:284.62ms
step:121/3000 train_loss:4.9442 train_time:31591ms step_avg:284.60ms
step:122/3000 train_loss:4.8429 train_time:31874ms step_avg:284.59ms
step:123/3000 train_loss:4.9592 train_time:32159ms step_avg:284.60ms
step:124/3000 train_loss:4.8033 train_time:32446ms step_avg:284.61ms
step:125/3000 train_loss:5.1153 train_time:32730ms step_avg:284.61ms
step:125/3000 val_loss:4.9481 train_time:32731ms step_avg:284.62ms
step:126/3000 train_loss:5.0010 train_time:33003ms step_avg:284.51ms
step:127/3000 train_loss:4.9324 train_time:33290ms step_avg:284.53ms
step:128/3000 train_loss:4.9977 train_time:33576ms step_avg:284.54ms
step:129/3000 train_loss:4.8706 train_time:33860ms step_avg:284.54ms
step:130/3000 train_loss:5.1784 train_time:34144ms step_avg:284.53ms
step:131/3000 train_loss:4.9276 train_time:34428ms step_avg:284.53ms
step:132/3000 train_loss:4.9369 train_time:34714ms step_avg:284.54ms
step:133/3000 train_loss:4.8867 train_time:35000ms step_avg:284.56ms
step:134/3000 train_loss:4.9300 train_time:35284ms step_avg:284.55ms
step:135/3000 train_loss:4.8278 train_time:35569ms step_avg:284.55ms
step:136/3000 train_loss:4.9491 train_time:35854ms step_avg:284.56ms
step:137/3000 train_loss:4.7254 train_time:36140ms step_avg:284.56ms
step:138/3000 train_loss:4.8790 train_time:36423ms step_avg:284.56ms
step:139/3000 train_loss:4.8312 train_time:36708ms step_avg:284.56ms
step:140/3000 train_loss:4.8691 train_time:36995ms step_avg:284.58ms
step:141/3000 train_loss:4.9304 train_time:37280ms step_avg:284.58ms
step:142/3000 train_loss:4.8045 train_time:37563ms step_avg:284.57ms
step:143/3000 train_loss:4.8610 train_time:37849ms step_avg:284.58ms
step:144/3000 train_loss:4.7207 train_time:38138ms step_avg:284.62ms
step:145/3000 train_loss:4.8547 train_time:38422ms step_avg:284.61ms
step:146/3000 train_loss:4.8097 train_time:38706ms step_avg:284.60ms
step:147/3000 train_loss:4.6828 train_time:38991ms step_avg:284.60ms
step:148/3000 train_loss:4.8278 train_time:39277ms step_avg:284.62ms
step:149/3000 train_loss:4.8365 train_time:39562ms step_avg:284.62ms
step:150/3000 train_loss:4.8678 train_time:39845ms step_avg:284.61ms
step:151/3000 train_loss:4.8962 train_time:40131ms step_avg:284.62ms
step:152/3000 train_loss:4.7819 train_time:40417ms step_avg:284.63ms
step:153/3000 train_loss:4.7738 train_time:40702ms step_avg:284.63ms
step:154/3000 train_loss:4.8700 train_time:40985ms step_avg:284.62ms
step:155/3000 train_loss:4.8206 train_time:41270ms step_avg:284.62ms
step:156/3000 train_loss:4.7801 train_time:41555ms step_avg:284.62ms
step:157/3000 train_loss:4.8092 train_time:41840ms step_avg:284.63ms
step:158/3000 train_loss:4.9218 train_time:42124ms step_avg:284.62ms
step:159/3000 train_loss:4.7094 train_time:42409ms step_avg:284.63ms
step:160/3000 train_loss:4.7821 train_time:42696ms step_avg:284.64ms
step:161/3000 train_loss:4.6200 train_time:42982ms step_avg:284.65ms
step:162/3000 train_loss:4.8042 train_time:43265ms step_avg:284.64ms
step:163/3000 train_loss:4.8298 train_time:43550ms step_avg:284.64ms
step:164/3000 train_loss:4.8150 train_time:43837ms step_avg:284.66ms
step:165/3000 train_loss:4.6290 train_time:44122ms step_avg:284.66ms
step:166/3000 train_loss:4.7492 train_time:44404ms step_avg:284.64ms
step:167/3000 train_loss:4.8852 train_time:44689ms step_avg:284.64ms
step:168/3000 train_loss:4.6710 train_time:44976ms step_avg:284.66ms
step:169/3000 train_loss:4.7620 train_time:45260ms step_avg:284.66ms
step:170/3000 train_loss:4.6160 train_time:45544ms step_avg:284.65ms
step:171/3000 train_loss:4.5181 train_time:45828ms step_avg:284.65ms
step:172/3000 train_loss:4.6817 train_time:46114ms step_avg:284.66ms
step:173/3000 train_loss:4.6617 train_time:46401ms step_avg:284.67ms
step:174/3000 train_loss:4.7082 train_time:46684ms step_avg:284.66ms
step:175/3000 train_loss:4.8688 train_time:46968ms step_avg:284.65ms
step:176/3000 train_loss:4.7146 train_time:47255ms step_avg:284.67ms
step:177/3000 train_loss:4.5711 train_time:47543ms step_avg:284.69ms
step:178/3000 train_loss:4.5308 train_time:47827ms step_avg:284.69ms
step:179/3000 train_loss:4.6054 train_time:48115ms step_avg:284.70ms
step:180/3000 train_loss:4.6104 train_time:48400ms step_avg:284.71ms
step:181/3000 train_loss:4.6101 train_time:48683ms step_avg:284.70ms
step:182/3000 train_loss:4.7486 train_time:48968ms step_avg:284.70ms
step:183/3000 train_loss:4.6052 train_time:49253ms step_avg:284.70ms
step:184/3000 train_loss:4.5619 train_time:49540ms step_avg:284.71ms
step:185/3000 train_loss:4.5706 train_time:49824ms step_avg:284.71ms
step:186/3000 train_loss:4.6868 train_time:50109ms step_avg:284.71ms
step:187/3000 train_loss:4.6078 train_time:50395ms step_avg:284.72ms
step:188/3000 train_loss:4.7851 train_time:50682ms step_avg:284.73ms
step:189/3000 train_loss:4.6213 train_time:51219ms step_avg:286.14ms
step:190/3000 train_loss:4.5454 train_time:51764ms step_avg:287.58ms
step:191/3000 train_loss:4.6811 train_time:52049ms step_avg:287.56ms
step:192/3000 train_loss:4.5271 train_time:52335ms step_avg:287.56ms
step:193/3000 train_loss:4.4546 train_time:52621ms step_avg:287.55ms
step:194/3000 train_loss:4.6826 train_time:52904ms step_avg:287.52ms
step:195/3000 train_loss:4.6040 train_time:53188ms step_avg:287.50ms
step:196/3000 train_loss:4.7898 train_time:53476ms step_avg:287.51ms
step:197/3000 train_loss:4.6614 train_time:53762ms step_avg:287.50ms
step:198/3000 train_loss:4.5082 train_time:54045ms step_avg:287.47ms
step:199/3000 train_loss:4.5748 train_time:54329ms step_avg:287.46ms
step:200/3000 train_loss:4.4341 train_time:54614ms step_avg:287.44ms
step:201/3000 train_loss:4.5363 train_time:54899ms step_avg:287.43ms
step:202/3000 train_loss:4.4330 train_time:55183ms step_avg:287.41ms
step:203/3000 train_loss:4.6806 train_time:55465ms step_avg:287.39ms
step:204/3000 train_loss:4.5336 train_time:55751ms step_avg:287.37ms
step:205/3000 train_loss:4.5772 train_time:56039ms step_avg:287.38ms
step:206/3000 train_loss:4.6837 train_time:56322ms step_avg:287.36ms
step:207/3000 train_loss:4.3493 train_time:56605ms step_avg:287.34ms
step:208/3000 train_loss:4.5006 train_time:56890ms step_avg:287.32ms
step:209/3000 train_loss:4.4812 train_time:57175ms step_avg:287.31ms
step:210/3000 train_loss:4.6434 train_time:57461ms step_avg:287.30ms
step:211/3000 train_loss:4.5640 train_time:57744ms step_avg:287.28ms
step:212/3000 train_loss:4.4433 train_time:58028ms step_avg:287.27ms
step:213/3000 train_loss:4.5487 train_time:58313ms step_avg:287.26ms
step:214/3000 train_loss:4.4176 train_time:58598ms step_avg:287.25ms
step:215/3000 train_loss:4.4954 train_time:58882ms step_avg:287.23ms
step:216/3000 train_loss:4.3514 train_time:59165ms step_avg:287.21ms
step:217/3000 train_loss:4.4402 train_time:59449ms step_avg:287.19ms
step:218/3000 train_loss:4.4139 train_time:59738ms step_avg:287.20ms
step:219/3000 train_loss:4.4483 train_time:60022ms step_avg:287.19ms
step:220/3000 train_loss:4.4408 train_time:60305ms step_avg:287.17ms
step:221/3000 train_loss:4.4619 train_time:60588ms step_avg:287.15ms
step:222/3000 train_loss:4.4755 train_time:60874ms step_avg:287.14ms
step:223/3000 train_loss:4.4054 train_time:61160ms step_avg:287.14ms
step:224/3000 train_loss:4.3945 train_time:61443ms step_avg:287.12ms
step:225/3000 train_loss:4.6196 train_time:61728ms step_avg:287.10ms
step:226/3000 train_loss:4.2550 train_time:62013ms step_avg:287.10ms
step:227/3000 train_loss:4.3342 train_time:62298ms step_avg:287.09ms
step:228/3000 train_loss:4.3364 train_time:62582ms step_avg:287.07ms
step:229/3000 train_loss:4.4907 train_time:62865ms step_avg:287.06ms
step:230/3000 train_loss:4.2814 train_time:63149ms step_avg:287.04ms
step:231/3000 train_loss:4.4135 train_time:63435ms step_avg:287.04ms
step:232/3000 train_loss:4.2800 train_time:63721ms step_avg:287.03ms
step:233/3000 train_loss:4.3049 train_time:64004ms step_avg:287.01ms
step:234/3000 train_loss:4.4581 train_time:64291ms step_avg:287.01ms
step:235/3000 train_loss:4.3537 train_time:64577ms step_avg:287.01ms
step:236/3000 train_loss:4.2279 train_time:64862ms step_avg:287.00ms
step:237/3000 train_loss:4.4380 train_time:65145ms step_avg:286.98ms
step:238/3000 train_loss:4.4117 train_time:65429ms step_avg:286.97ms
step:239/3000 train_loss:4.2774 train_time:65715ms step_avg:286.97ms
step:240/3000 train_loss:4.4231 train_time:66000ms step_avg:286.96ms
step:241/3000 train_loss:4.4300 train_time:66283ms step_avg:286.94ms
step:242/3000 train_loss:4.3010 train_time:66566ms step_avg:286.92ms
step:243/3000 train_loss:4.4811 train_time:66853ms step_avg:286.92ms
step:244/3000 train_loss:4.3316 train_time:67140ms step_avg:286.92ms
step:245/3000 train_loss:4.3754 train_time:67423ms step_avg:286.91ms
step:246/3000 train_loss:4.4490 train_time:67707ms step_avg:286.89ms
step:247/3000 train_loss:4.3752 train_time:67994ms step_avg:286.89ms
step:248/3000 train_loss:4.3175 train_time:68280ms step_avg:286.89ms
step:249/3000 train_loss:4.4525 train_time:68564ms step_avg:286.88ms
step:250/3000 train_loss:4.2221 train_time:68848ms step_avg:286.87ms
step:250/3000 val_loss:4.3193 train_time:68849ms step_avg:286.87ms
step:251/3000 train_loss:4.2804 train_time:69121ms step_avg:286.81ms
step:252/3000 train_loss:4.3851 train_time:69408ms step_avg:286.81ms
step:253/3000 train_loss:4.4331 train_time:69695ms step_avg:286.81ms
step:254/3000 train_loss:4.2479 train_time:69979ms step_avg:286.80ms
step:255/3000 train_loss:4.1964 train_time:70261ms step_avg:286.78ms
step:256/3000 train_loss:4.3698 train_time:70545ms step_avg:286.77ms
step:257/3000 train_loss:4.2817 train_time:70830ms step_avg:286.76ms
step:258/3000 train_loss:4.2930 train_time:71115ms step_avg:286.75ms
step:259/3000 train_loss:4.2617 train_time:71400ms step_avg:286.75ms
step:260/3000 train_loss:4.3046 train_time:71682ms step_avg:286.73ms
step:261/3000 train_loss:4.3477 train_time:71968ms step_avg:286.73ms
step:262/3000 train_loss:4.3046 train_time:72252ms step_avg:286.71ms
step:263/3000 train_loss:4.2719 train_time:72538ms step_avg:286.71ms
step:264/3000 train_loss:4.1924 train_time:72821ms step_avg:286.70ms
step:265/3000 train_loss:4.2699 train_time:73105ms step_avg:286.68ms
step:266/3000 train_loss:4.1314 train_time:73390ms step_avg:286.68ms
step:267/3000 train_loss:4.1981 train_time:73677ms step_avg:286.68ms
step:268/3000 train_loss:4.2142 train_time:73962ms step_avg:286.67ms
step:269/3000 train_loss:4.2299 train_time:74249ms step_avg:286.67ms
step:270/3000 train_loss:4.1436 train_time:74535ms step_avg:286.67ms
step:271/3000 train_loss:4.3648 train_time:74818ms step_avg:286.66ms
step:272/3000 train_loss:4.2703 train_time:75100ms step_avg:286.64ms
step:273/3000 train_loss:4.1908 train_time:75385ms step_avg:286.63ms
step:274/3000 train_loss:4.2372 train_time:75671ms step_avg:286.63ms
step:275/3000 train_loss:4.3071 train_time:75956ms step_avg:286.63ms
step:276/3000 train_loss:4.3316 train_time:76239ms step_avg:286.61ms
step:277/3000 train_loss:4.5102 train_time:76522ms step_avg:286.60ms
step:278/3000 train_loss:4.2975 train_time:76808ms step_avg:286.60ms
step:279/3000 train_loss:4.3654 train_time:77094ms step_avg:286.60ms
step:280/3000 train_loss:4.2629 train_time:77379ms step_avg:286.59ms
step:281/3000 train_loss:4.3889 train_time:77662ms step_avg:286.58ms
step:282/3000 train_loss:4.2168 train_time:77947ms step_avg:286.57ms
step:283/3000 train_loss:4.2417 train_time:78234ms step_avg:286.57ms
step:284/3000 train_loss:4.1724 train_time:78519ms step_avg:286.56ms
step:285/3000 train_loss:4.3176 train_time:78801ms step_avg:286.55ms
step:286/3000 train_loss:4.3279 train_time:79086ms step_avg:286.54ms
step:287/3000 train_loss:4.3580 train_time:79374ms step_avg:286.55ms
step:288/3000 train_loss:4.1803 train_time:79658ms step_avg:286.54ms
step:289/3000 train_loss:4.2699 train_time:79942ms step_avg:286.53ms
step:290/3000 train_loss:4.1279 train_time:80226ms step_avg:286.52ms
step:291/3000 train_loss:4.1249 train_time:80513ms step_avg:286.52ms
step:292/3000 train_loss:4.2108 train_time:80798ms step_avg:286.52ms
step:293/3000 train_loss:4.1271 train_time:81081ms step_avg:286.51ms
step:294/3000 train_loss:4.1663 train_time:81366ms step_avg:286.50ms
step:295/3000 train_loss:4.2168 train_time:81650ms step_avg:286.49ms
step:296/3000 train_loss:4.0849 train_time:81937ms step_avg:286.49ms
step:297/3000 train_loss:4.1068 train_time:82221ms step_avg:286.48ms
step:298/3000 train_loss:4.1090 train_time:82505ms step_avg:286.48ms
step:299/3000 train_loss:4.2187 train_time:82790ms step_avg:286.47ms
step:300/3000 train_loss:4.0797 train_time:83077ms step_avg:286.47ms
step:301/3000 train_loss:4.2196 train_time:83361ms step_avg:286.47ms
step:302/3000 train_loss:4.2320 train_time:83645ms step_avg:286.46ms
step:303/3000 train_loss:4.1770 train_time:83933ms step_avg:286.46ms
step:304/3000 train_loss:4.2280 train_time:84218ms step_avg:286.46ms
step:305/3000 train_loss:4.2161 train_time:84501ms step_avg:286.45ms
step:306/3000 train_loss:4.6905 train_time:84787ms step_avg:286.44ms
step:307/3000 train_loss:4.1773 train_time:85076ms step_avg:286.45ms
step:308/3000 train_loss:4.0874 train_time:85359ms step_avg:286.44ms
step:309/3000 train_loss:4.2424 train_time:85642ms step_avg:286.43ms
step:310/3000 train_loss:4.1025 train_time:85926ms step_avg:286.42ms
step:311/3000 train_loss:4.3227 train_time:86211ms step_avg:286.41ms
step:312/3000 train_loss:4.1795 train_time:86497ms step_avg:286.41ms
step:313/3000 train_loss:4.1177 train_time:86779ms step_avg:286.40ms
step:314/3000 train_loss:4.2123 train_time:87062ms step_avg:286.39ms
step:315/3000 train_loss:4.3292 train_time:87346ms step_avg:286.38ms
step:316/3000 train_loss:4.2006 train_time:87631ms step_avg:286.38ms
step:317/3000 train_loss:4.0350 train_time:87917ms step_avg:286.38ms
step:318/3000 train_loss:4.1108 train_time:88200ms step_avg:286.36ms
step:319/3000 train_loss:4.1514 train_time:88484ms step_avg:286.36ms
step:320/3000 train_loss:4.1227 train_time:88771ms step_avg:286.36ms
step:321/3000 train_loss:4.2298 train_time:89056ms step_avg:286.35ms
step:322/3000 train_loss:4.1922 train_time:89339ms step_avg:286.34ms
step:323/3000 train_loss:4.1588 train_time:89623ms step_avg:286.33ms
step:324/3000 train_loss:4.2429 train_time:89909ms step_avg:286.33ms
step:325/3000 train_loss:4.1998 train_time:90194ms step_avg:286.33ms
step:326/3000 train_loss:4.2731 train_time:90478ms step_avg:286.32ms
step:327/3000 train_loss:4.1280 train_time:90760ms step_avg:286.31ms
step:328/3000 train_loss:4.6101 train_time:91044ms step_avg:286.30ms
step:329/3000 train_loss:4.3020 train_time:91333ms step_avg:286.31ms
step:330/3000 train_loss:4.0450 train_time:91619ms step_avg:286.31ms
step:331/3000 train_loss:3.9954 train_time:91902ms step_avg:286.30ms
step:332/3000 train_loss:4.1992 train_time:92186ms step_avg:286.29ms
step:333/3000 train_loss:4.1301 train_time:92474ms step_avg:286.30ms
step:334/3000 train_loss:4.1122 train_time:92758ms step_avg:286.29ms
step:335/3000 train_loss:4.0764 train_time:93041ms step_avg:286.28ms
step:336/3000 train_loss:4.2419 train_time:93325ms step_avg:286.27ms
step:337/3000 train_loss:4.1828 train_time:93611ms step_avg:286.27ms
step:338/3000 train_loss:4.6628 train_time:93895ms step_avg:286.26ms
step:339/3000 train_loss:4.1647 train_time:94179ms step_avg:286.26ms
step:340/3000 train_loss:4.1174 train_time:94462ms step_avg:286.25ms
step:341/3000 train_loss:4.1536 train_time:94746ms step_avg:286.24ms
step:342/3000 train_loss:4.0637 train_time:95032ms step_avg:286.24ms
step:343/3000 train_loss:4.0410 train_time:95318ms step_avg:286.24ms
step:344/3000 train_loss:4.0877 train_time:95601ms step_avg:286.23ms
step:345/3000 train_loss:4.2235 train_time:95886ms step_avg:286.23ms
step:346/3000 train_loss:4.0658 train_time:96174ms step_avg:286.23ms
step:347/3000 train_loss:4.0027 train_time:96458ms step_avg:286.22ms
step:348/3000 train_loss:4.0369 train_time:96741ms step_avg:286.21ms
step:349/3000 train_loss:4.0898 train_time:97025ms step_avg:286.21ms
step:350/3000 train_loss:4.0456 train_time:97311ms step_avg:286.21ms
step:351/3000 train_loss:3.7667 train_time:97596ms step_avg:286.21ms
step:352/3000 train_loss:4.0404 train_time:97880ms step_avg:286.20ms
step:353/3000 train_loss:4.4020 train_time:98163ms step_avg:286.19ms
step:354/3000 train_loss:3.8852 train_time:98449ms step_avg:286.19ms
step:355/3000 train_loss:4.1517 train_time:98736ms step_avg:286.19ms
step:356/3000 train_loss:4.0117 train_time:99020ms step_avg:286.19ms
step:357/3000 train_loss:4.1153 train_time:99305ms step_avg:286.18ms
step:358/3000 train_loss:4.0690 train_time:99591ms step_avg:286.18ms
step:359/3000 train_loss:4.0726 train_time:99877ms step_avg:286.18ms
step:360/3000 train_loss:4.0950 train_time:100161ms step_avg:286.17ms
step:361/3000 train_loss:3.6826 train_time:100445ms step_avg:286.17ms
step:362/3000 train_loss:4.2440 train_time:100731ms step_avg:286.17ms
step:363/3000 train_loss:4.1404 train_time:101016ms step_avg:286.17ms
step:364/3000 train_loss:4.0678 train_time:101299ms step_avg:286.15ms
step:365/3000 train_loss:3.9632 train_time:101582ms step_avg:286.15ms
step:366/3000 train_loss:4.1331 train_time:101866ms step_avg:286.14ms
step:367/3000 train_loss:4.0924 train_time:102152ms step_avg:286.14ms
step:368/3000 train_loss:4.0742 train_time:102437ms step_avg:286.14ms
step:369/3000 train_loss:4.0661 train_time:102720ms step_avg:286.13ms
step:370/3000 train_loss:3.9569 train_time:103003ms step_avg:286.12ms
step:371/3000 train_loss:4.1095 train_time:103287ms step_avg:286.11ms
step:372/3000 train_loss:3.9844 train_time:103575ms step_avg:286.12ms
step:373/3000 train_loss:3.9136 train_time:103858ms step_avg:286.11ms
step:374/3000 train_loss:4.1315 train_time:104141ms step_avg:286.10ms
step:375/3000 train_loss:4.0549 train_time:104425ms step_avg:286.10ms
step:375/3000 val_loss:4.0515 train_time:104426ms step_avg:286.10ms
step:376/3000 train_loss:4.0230 train_time:104695ms step_avg:286.05ms
step:377/3000 train_loss:4.0859 train_time:104985ms step_avg:286.06ms
step:378/3000 train_loss:4.0023 train_time:105530ms step_avg:286.77ms
step:379/3000 train_loss:4.0666 train_time:105816ms step_avg:286.77ms
step:380/3000 train_loss:4.0925 train_time:106363ms step_avg:287.47ms
step:381/3000 train_loss:4.1654 train_time:106646ms step_avg:287.45ms
step:382/3000 train_loss:4.0686 train_time:106929ms step_avg:287.44ms
step:383/3000 train_loss:4.0402 train_time:107214ms step_avg:287.44ms
step:384/3000 train_loss:3.9991 train_time:107498ms step_avg:287.43ms
step:385/3000 train_loss:4.0819 train_time:107781ms step_avg:287.42ms
step:386/3000 train_loss:3.9943 train_time:108063ms step_avg:287.40ms
step:387/3000 train_loss:4.1120 train_time:108348ms step_avg:287.40ms
step:388/3000 train_loss:4.2952 train_time:108632ms step_avg:287.39ms
step:389/3000 train_loss:4.0166 train_time:108922ms step_avg:287.39ms
step:390/3000 train_loss:4.0045 train_time:109204ms step_avg:287.38ms
step:391/3000 train_loss:4.1058 train_time:109488ms step_avg:287.37ms
step:392/3000 train_loss:4.0309 train_time:109772ms step_avg:287.36ms
step:393/3000 train_loss:4.1367 train_time:110057ms step_avg:287.35ms
step:394/3000 train_loss:3.9687 train_time:110340ms step_avg:287.34ms
step:395/3000 train_loss:4.1055 train_time:110629ms step_avg:287.35ms
step:396/3000 train_loss:3.8487 train_time:110916ms step_avg:287.35ms
step:397/3000 train_loss:4.0456 train_time:111199ms step_avg:287.34ms
step:398/3000 train_loss:4.1015 train_time:111482ms step_avg:287.32ms
step:399/3000 train_loss:4.1046 train_time:111765ms step_avg:287.31ms
step:400/3000 train_loss:4.0020 train_time:112050ms step_avg:287.31ms
step:401/3000 train_loss:4.0562 train_time:112336ms step_avg:287.30ms
step:402/3000 train_loss:4.1283 train_time:112619ms step_avg:287.29ms
step:403/3000 train_loss:4.0570 train_time:112902ms step_avg:287.28ms
step:404/3000 train_loss:4.1654 train_time:113185ms step_avg:287.27ms
step:405/3000 train_loss:3.9179 train_time:113471ms step_avg:287.27ms
step:406/3000 train_loss:4.0072 train_time:113758ms step_avg:287.27ms
step:407/3000 train_loss:4.3036 train_time:114041ms step_avg:287.26ms
step:408/3000 train_loss:4.0110 train_time:114324ms step_avg:287.25ms
step:409/3000 train_loss:4.0294 train_time:114610ms step_avg:287.24ms
step:410/3000 train_loss:4.0830 train_time:114894ms step_avg:287.24ms
step:411/3000 train_loss:3.9634 train_time:115179ms step_avg:287.23ms
step:412/3000 train_loss:3.9786 train_time:115462ms step_avg:287.22ms
step:413/3000 train_loss:4.4079 train_time:115746ms step_avg:287.21ms
step:414/3000 train_loss:3.8450 train_time:116031ms step_avg:287.21ms
step:415/3000 train_loss:4.2281 train_time:116316ms step_avg:287.20ms
step:416/3000 train_loss:3.9762 train_time:116599ms step_avg:287.19ms
step:417/3000 train_loss:3.9790 train_time:116882ms step_avg:287.18ms
step:418/3000 train_loss:4.1713 train_time:117166ms step_avg:287.17ms
step:419/3000 train_loss:3.8983 train_time:117451ms step_avg:287.17ms
step:420/3000 train_loss:4.0114 train_time:117738ms step_avg:287.17ms
step:421/3000 train_loss:3.9526 train_time:118021ms step_avg:287.16ms
step:422/3000 train_loss:3.8543 train_time:118304ms step_avg:287.15ms
step:423/3000 train_loss:3.9869 train_time:118589ms step_avg:287.14ms
step:424/3000 train_loss:4.0774 train_time:118875ms step_avg:287.14ms
step:425/3000 train_loss:3.8391 train_time:119159ms step_avg:287.13ms
step:426/3000 train_loss:4.0238 train_time:119442ms step_avg:287.12ms
step:427/3000 train_loss:3.9008 train_time:119727ms step_avg:287.11ms
step:428/3000 train_loss:4.1081 train_time:120011ms step_avg:287.11ms
step:429/3000 train_loss:4.0373 train_time:120296ms step_avg:287.10ms
step:430/3000 train_loss:3.9643 train_time:120579ms step_avg:287.09ms
step:431/3000 train_loss:3.9348 train_time:120862ms step_avg:287.08ms
step:432/3000 train_loss:3.8424 train_time:121146ms step_avg:287.08ms
step:433/3000 train_loss:3.9701 train_time:121432ms step_avg:287.07ms
step:434/3000 train_loss:4.0365 train_time:121717ms step_avg:287.07ms
step:435/3000 train_loss:3.9751 train_time:122000ms step_avg:287.06ms
step:436/3000 train_loss:4.0269 train_time:122283ms step_avg:287.05ms
step:437/3000 train_loss:4.0372 train_time:122567ms step_avg:287.04ms
step:438/3000 train_loss:3.9213 train_time:122857ms step_avg:287.05ms
step:439/3000 train_loss:3.9315 train_time:123140ms step_avg:287.04ms
step:440/3000 train_loss:3.9079 train_time:123423ms step_avg:287.03ms
step:441/3000 train_loss:4.0914 train_time:123705ms step_avg:287.02ms
step:442/3000 train_loss:3.9778 train_time:123990ms step_avg:287.01ms
step:443/3000 train_loss:3.9616 train_time:124276ms step_avg:287.01ms
step:444/3000 train_loss:3.8490 train_time:124560ms step_avg:287.00ms
step:445/3000 train_loss:4.1184 train_time:124842ms step_avg:286.99ms
step:446/3000 train_loss:4.0512 train_time:125126ms step_avg:286.99ms
step:447/3000 train_loss:4.0494 train_time:125411ms step_avg:286.98ms
step:448/3000 train_loss:3.9665 train_time:125697ms step_avg:286.98ms
step:449/3000 train_loss:4.0616 train_time:125980ms step_avg:286.97ms
step:450/3000 train_loss:3.8831 train_time:126266ms step_avg:286.97ms
step:451/3000 train_loss:3.9263 train_time:126552ms step_avg:286.97ms
step:452/3000 train_loss:3.7889 train_time:126840ms step_avg:286.97ms
step:453/3000 train_loss:3.9103 train_time:127124ms step_avg:286.96ms
step:454/3000 train_loss:3.8845 train_time:127410ms step_avg:286.96ms
step:455/3000 train_loss:3.8442 train_time:127695ms step_avg:286.95ms
step:456/3000 train_loss:4.0591 train_time:127979ms step_avg:286.95ms
step:457/3000 train_loss:3.9290 train_time:128261ms step_avg:286.94ms
step:458/3000 train_loss:4.0010 train_time:128545ms step_avg:286.93ms
step:459/3000 train_loss:4.0369 train_time:128830ms step_avg:286.93ms
step:460/3000 train_loss:3.8417 train_time:129117ms step_avg:286.93ms
step:461/3000 train_loss:4.0100 train_time:129400ms step_avg:286.92ms
step:462/3000 train_loss:3.9108 train_time:129684ms step_avg:286.91ms
step:463/3000 train_loss:3.9293 train_time:129969ms step_avg:286.91ms
step:464/3000 train_loss:3.9881 train_time:130257ms step_avg:286.91ms
step:465/3000 train_loss:3.9240 train_time:130540ms step_avg:286.90ms
step:466/3000 train_loss:3.9283 train_time:130825ms step_avg:286.90ms
step:467/3000 train_loss:4.0271 train_time:131112ms step_avg:286.90ms
step:468/3000 train_loss:4.0396 train_time:131397ms step_avg:286.89ms
step:469/3000 train_loss:4.0069 train_time:131680ms step_avg:286.88ms
step:470/3000 train_loss:3.8974 train_time:131962ms step_avg:286.87ms
step:471/3000 train_loss:3.9826 train_time:132246ms step_avg:286.87ms
step:472/3000 train_loss:4.0438 train_time:132531ms step_avg:286.86ms
step:473/3000 train_loss:3.9771 train_time:132817ms step_avg:286.86ms
step:474/3000 train_loss:3.9316 train_time:133100ms step_avg:286.85ms
step:475/3000 train_loss:3.7910 train_time:133383ms step_avg:286.84ms
step:476/3000 train_loss:4.2233 train_time:133667ms step_avg:286.84ms
step:477/3000 train_loss:3.9791 train_time:133952ms step_avg:286.84ms
step:478/3000 train_loss:3.7975 train_time:134237ms step_avg:286.83ms
step:479/3000 train_loss:4.0220 train_time:134521ms step_avg:286.83ms
step:480/3000 train_loss:3.9767 train_time:134804ms step_avg:286.82ms
step:481/3000 train_loss:4.1195 train_time:135090ms step_avg:286.81ms
step:482/3000 train_loss:3.9338 train_time:135377ms step_avg:286.82ms
step:483/3000 train_loss:3.7364 train_time:135661ms step_avg:286.81ms
step:484/3000 train_loss:4.0209 train_time:135944ms step_avg:286.80ms
step:485/3000 train_loss:3.8733 train_time:136228ms step_avg:286.80ms
step:486/3000 train_loss:3.8815 train_time:136515ms step_avg:286.80ms
step:487/3000 train_loss:3.8119 train_time:136799ms step_avg:286.79ms
step:488/3000 train_loss:3.8795 train_time:137082ms step_avg:286.78ms
step:489/3000 train_loss:4.0861 train_time:137366ms step_avg:286.78ms
step:490/3000 train_loss:3.9216 train_time:137654ms step_avg:286.78ms
step:491/3000 train_loss:3.8096 train_time:137938ms step_avg:286.77ms
step:492/3000 train_loss:3.8274 train_time:138222ms step_avg:286.77ms
step:493/3000 train_loss:3.9412 train_time:138504ms step_avg:286.76ms
step:494/3000 train_loss:3.7817 train_time:138789ms step_avg:286.75ms
step:495/3000 train_loss:3.9201 train_time:139074ms step_avg:286.75ms
step:496/3000 train_loss:3.8510 train_time:139359ms step_avg:286.75ms
step:497/3000 train_loss:3.7394 train_time:139642ms step_avg:286.74ms
step:498/3000 train_loss:3.9360 train_time:139927ms step_avg:286.74ms
step:499/3000 train_loss:4.0126 train_time:140213ms step_avg:286.73ms
step:500/3000 train_loss:4.0389 train_time:140498ms step_avg:286.73ms
step:500/3000 val_loss:3.9171 train_time:140498ms step_avg:286.73ms
step:501/3000 train_loss:3.9542 train_time:140770ms step_avg:286.70ms
step:502/3000 train_loss:4.0087 train_time:141056ms step_avg:286.70ms
step:503/3000 train_loss:3.9553 train_time:141338ms step_avg:286.69ms
step:504/3000 train_loss:3.9972 train_time:141617ms step_avg:286.67ms
step:505/3000 train_loss:3.9384 train_time:141898ms step_avg:286.66ms
step:506/3000 train_loss:4.0247 train_time:142181ms step_avg:286.66ms
step:507/3000 train_loss:3.8440 train_time:142460ms step_avg:286.64ms
step:508/3000 train_loss:3.9660 train_time:142740ms step_avg:286.63ms
step:509/3000 train_loss:4.0457 train_time:143019ms step_avg:286.61ms
step:510/3000 train_loss:3.9819 train_time:143300ms step_avg:286.60ms
step:511/3000 train_loss:3.7894 train_time:143580ms step_avg:286.59ms
step:512/3000 train_loss:3.9851 train_time:143861ms step_avg:286.58ms
step:513/3000 train_loss:3.9289 train_time:144141ms step_avg:286.56ms
step:514/3000 train_loss:3.8899 train_time:144420ms step_avg:286.55ms
step:515/3000 train_loss:3.9988 train_time:144701ms step_avg:286.54ms
step:516/3000 train_loss:3.9487 train_time:144981ms step_avg:286.52ms
step:517/3000 train_loss:4.2850 train_time:145261ms step_avg:286.51ms
step:518/3000 train_loss:3.8848 train_time:145541ms step_avg:286.50ms
step:519/3000 train_loss:3.9923 train_time:145820ms step_avg:286.48ms
step:520/3000 train_loss:3.8941 train_time:146101ms step_avg:286.47ms
step:521/3000 train_loss:3.8941 train_time:146381ms step_avg:286.46ms
step:522/3000 train_loss:3.8463 train_time:146662ms step_avg:286.45ms
step:523/3000 train_loss:3.8687 train_time:146941ms step_avg:286.44ms
step:524/3000 train_loss:4.4889 train_time:147222ms step_avg:286.42ms
step:525/3000 train_loss:3.9553 train_time:147502ms step_avg:286.41ms
step:526/3000 train_loss:3.8932 train_time:147781ms step_avg:286.40ms
step:527/3000 train_loss:3.9033 train_time:148062ms step_avg:286.39ms
step:528/3000 train_loss:3.8591 train_time:148342ms step_avg:286.37ms
step:529/3000 train_loss:3.8361 train_time:148620ms step_avg:286.36ms
step:530/3000 train_loss:4.0531 train_time:148900ms step_avg:286.35ms
step:531/3000 train_loss:3.8427 train_time:149180ms step_avg:286.33ms
step:532/3000 train_loss:4.1246 train_time:149460ms step_avg:286.32ms
step:533/3000 train_loss:3.9398 train_time:149740ms step_avg:286.31ms
step:534/3000 train_loss:3.8629 train_time:150019ms step_avg:286.29ms
step:535/3000 train_loss:3.8840 train_time:150300ms step_avg:286.28ms
step:536/3000 train_loss:3.8208 train_time:150579ms step_avg:286.27ms
step:537/3000 train_loss:3.9505 train_time:150860ms step_avg:286.26ms
step:538/3000 train_loss:3.9418 train_time:151140ms step_avg:286.25ms
step:539/3000 train_loss:3.8383 train_time:151419ms step_avg:286.24ms
step:540/3000 train_loss:4.3390 train_time:151699ms step_avg:286.23ms
step:541/3000 train_loss:3.8711 train_time:151980ms step_avg:286.21ms
step:542/3000 train_loss:3.9847 train_time:152259ms step_avg:286.20ms
step:543/3000 train_loss:3.8166 train_time:152539ms step_avg:286.19ms
step:544/3000 train_loss:3.7882 train_time:152818ms step_avg:286.18ms
step:545/3000 train_loss:3.8725 train_time:153100ms step_avg:286.17ms
step:546/3000 train_loss:3.8004 train_time:153379ms step_avg:286.16ms
step:547/3000 train_loss:3.8389 train_time:153659ms step_avg:286.14ms
step:548/3000 train_loss:3.8657 train_time:153940ms step_avg:286.13ms
step:549/3000 train_loss:3.8397 train_time:154219ms step_avg:286.12ms
step:550/3000 train_loss:3.9322 train_time:154500ms step_avg:286.11ms
step:551/3000 train_loss:3.8090 train_time:154780ms step_avg:286.10ms
step:552/3000 train_loss:3.8253 train_time:155060ms step_avg:286.09ms
step:553/3000 train_loss:4.1526 train_time:155340ms step_avg:286.08ms
step:554/3000 train_loss:3.9549 train_time:155618ms step_avg:286.06ms
step:555/3000 train_loss:3.9143 train_time:155899ms step_avg:286.05ms
step:556/3000 train_loss:3.8628 train_time:156179ms step_avg:286.04ms
step:557/3000 train_loss:3.8952 train_time:156460ms step_avg:286.03ms
step:558/3000 train_loss:3.5564 train_time:156739ms step_avg:286.02ms
step:559/3000 train_loss:3.8066 train_time:157018ms step_avg:286.01ms
step:560/3000 train_loss:3.8523 train_time:157299ms step_avg:286.00ms
step:561/3000 train_loss:3.9038 train_time:157580ms step_avg:285.99ms
step:562/3000 train_loss:3.8116 train_time:157860ms step_avg:285.98ms
step:563/3000 train_loss:3.7540 train_time:158141ms step_avg:285.97ms
step:564/3000 train_loss:3.9598 train_time:158420ms step_avg:285.96ms
step:565/3000 train_loss:3.7771 train_time:158700ms step_avg:285.95ms
step:566/3000 train_loss:3.8914 train_time:158981ms step_avg:285.94ms
step:567/3000 train_loss:3.8334 train_time:159506ms step_avg:286.37ms
step:568/3000 train_loss:3.7849 train_time:159786ms step_avg:286.35ms
step:569/3000 train_loss:3.8908 train_time:160066ms step_avg:286.34ms
step:570/3000 train_loss:3.8633 train_time:160581ms step_avg:286.75ms
step:571/3000 train_loss:3.8903 train_time:160862ms step_avg:286.74ms
step:572/3000 train_loss:3.9672 train_time:161143ms step_avg:286.73ms
step:573/3000 train_loss:3.9206 train_time:161422ms step_avg:286.72ms
step:574/3000 train_loss:3.9253 train_time:161702ms step_avg:286.71ms
step:575/3000 train_loss:3.9783 train_time:161983ms step_avg:286.70ms
step:576/3000 train_loss:3.9394 train_time:162263ms step_avg:286.68ms
step:577/3000 train_loss:3.9557 train_time:162543ms step_avg:286.67ms
step:578/3000 train_loss:3.8866 train_time:162822ms step_avg:286.66ms
step:579/3000 train_loss:3.8749 train_time:163101ms step_avg:286.65ms
step:580/3000 train_loss:3.8649 train_time:163381ms step_avg:286.63ms
step:581/3000 train_loss:3.8060 train_time:163662ms step_avg:286.62ms
step:582/3000 train_loss:3.8350 train_time:163942ms step_avg:286.61ms
step:583/3000 train_loss:4.0599 train_time:164221ms step_avg:286.60ms
step:584/3000 train_loss:3.8303 train_time:164502ms step_avg:286.59ms
step:585/3000 train_loss:3.7902 train_time:164783ms step_avg:286.58ms
step:586/3000 train_loss:3.9819 train_time:165065ms step_avg:286.57ms
step:587/3000 train_loss:3.7304 train_time:165345ms step_avg:286.56ms
step:588/3000 train_loss:3.8693 train_time:165624ms step_avg:286.55ms
step:589/3000 train_loss:3.8552 train_time:165904ms step_avg:286.54ms
step:590/3000 train_loss:4.2094 train_time:166185ms step_avg:286.53ms
step:591/3000 train_loss:3.9859 train_time:166465ms step_avg:286.51ms
step:592/3000 train_loss:3.7248 train_time:166745ms step_avg:286.50ms
step:593/3000 train_loss:3.7360 train_time:167025ms step_avg:286.49ms
step:594/3000 train_loss:3.7290 train_time:167305ms step_avg:286.48ms
step:595/3000 train_loss:3.7660 train_time:167585ms step_avg:286.47ms
step:596/3000 train_loss:4.1235 train_time:167864ms step_avg:286.46ms
step:597/3000 train_loss:3.8543 train_time:168148ms step_avg:286.45ms
step:598/3000 train_loss:3.7858 train_time:168428ms step_avg:286.44ms
step:599/3000 train_loss:3.8688 train_time:168708ms step_avg:286.43ms
step:600/3000 train_loss:3.6824 train_time:168987ms step_avg:286.42ms
step:601/3000 train_loss:3.8051 train_time:169266ms step_avg:286.41ms
step:602/3000 train_loss:3.8352 train_time:169546ms step_avg:286.40ms
step:603/3000 train_loss:3.8589 train_time:169827ms step_avg:286.39ms
step:604/3000 train_loss:3.9863 train_time:170108ms step_avg:286.38ms
step:605/3000 train_loss:3.8374 train_time:170387ms step_avg:286.37ms
step:606/3000 train_loss:3.8184 train_time:170667ms step_avg:286.35ms
step:607/3000 train_loss:3.7723 train_time:170946ms step_avg:286.34ms
step:608/3000 train_loss:4.0144 train_time:171226ms step_avg:286.33ms
step:609/3000 train_loss:3.8497 train_time:171506ms step_avg:286.32ms
step:610/3000 train_loss:3.8223 train_time:171787ms step_avg:286.31ms
step:611/3000 train_loss:3.9194 train_time:172067ms step_avg:286.30ms
step:612/3000 train_loss:3.8191 train_time:172347ms step_avg:286.29ms
step:613/3000 train_loss:3.8006 train_time:172626ms step_avg:286.28ms
step:614/3000 train_loss:3.9631 train_time:172907ms step_avg:286.27ms
step:615/3000 train_loss:3.9249 train_time:173188ms step_avg:286.26ms
step:616/3000 train_loss:3.8961 train_time:173467ms step_avg:286.25ms
step:617/3000 train_loss:3.8254 train_time:173747ms step_avg:286.24ms
step:618/3000 train_loss:3.7777 train_time:174027ms step_avg:286.23ms
step:619/3000 train_loss:3.8801 train_time:174306ms step_avg:286.22ms
step:620/3000 train_loss:3.7858 train_time:174586ms step_avg:286.21ms
step:621/3000 train_loss:3.7897 train_time:174867ms step_avg:286.20ms
step:622/3000 train_loss:4.1078 train_time:175147ms step_avg:286.19ms
step:623/3000 train_loss:3.7853 train_time:175427ms step_avg:286.18ms
step:624/3000 train_loss:3.8215 train_time:175707ms step_avg:286.17ms
step:625/3000 train_loss:3.8995 train_time:175987ms step_avg:286.16ms
step:625/3000 val_loss:3.8292 train_time:175988ms step_avg:286.16ms
step:626/3000 train_loss:3.9281 train_time:176256ms step_avg:286.13ms
step:627/3000 train_loss:3.9536 train_time:176536ms step_avg:286.12ms
step:628/3000 train_loss:3.9249 train_time:176816ms step_avg:286.11ms
step:629/3000 train_loss:3.9781 train_time:177096ms step_avg:286.10ms
step:630/3000 train_loss:3.7956 train_time:177377ms step_avg:286.09ms
step:631/3000 train_loss:3.9256 train_time:177658ms step_avg:286.08ms
step:632/3000 train_loss:3.9574 train_time:177936ms step_avg:286.07ms
step:633/3000 train_loss:3.8568 train_time:178216ms step_avg:286.06ms
step:634/3000 train_loss:3.7940 train_time:178495ms step_avg:286.05ms
step:635/3000 train_loss:3.8862 train_time:178774ms step_avg:286.04ms
step:636/3000 train_loss:4.1446 train_time:179053ms step_avg:286.03ms
step:637/3000 train_loss:3.7381 train_time:179333ms step_avg:286.02ms
step:638/3000 train_loss:3.5586 train_time:179615ms step_avg:286.01ms
step:639/3000 train_loss:3.7858 train_time:179895ms step_avg:286.00ms
step:640/3000 train_loss:3.8227 train_time:180176ms step_avg:285.99ms
step:641/3000 train_loss:3.7765 train_time:180456ms step_avg:285.98ms
step:642/3000 train_loss:3.7799 train_time:180735ms step_avg:285.97ms
step:643/3000 train_loss:3.8252 train_time:181016ms step_avg:285.97ms
step:644/3000 train_loss:3.8369 train_time:181295ms step_avg:285.95ms
step:645/3000 train_loss:3.7610 train_time:181577ms step_avg:285.95ms
step:646/3000 train_loss:3.9744 train_time:181855ms step_avg:285.94ms
step:647/3000 train_loss:3.8851 train_time:182136ms step_avg:285.93ms
step:648/3000 train_loss:3.8745 train_time:182416ms step_avg:285.92ms
step:649/3000 train_loss:3.9022 train_time:182695ms step_avg:285.91ms
step:650/3000 train_loss:3.9601 train_time:182974ms step_avg:285.90ms
step:651/3000 train_loss:3.8209 train_time:183255ms step_avg:285.89ms
step:652/3000 train_loss:3.9642 train_time:183534ms step_avg:285.88ms
step:653/3000 train_loss:3.7927 train_time:183813ms step_avg:285.87ms
step:654/3000 train_loss:3.8602 train_time:184093ms step_avg:285.86ms
step:655/3000 train_loss:3.6310 train_time:184372ms step_avg:285.85ms
step:656/3000 train_loss:3.7748 train_time:184652ms step_avg:285.84ms
step:657/3000 train_loss:3.7877 train_time:184931ms step_avg:285.83ms
step:658/3000 train_loss:3.7064 train_time:185211ms step_avg:285.82ms
step:659/3000 train_loss:3.8915 train_time:185490ms step_avg:285.81ms
step:660/3000 train_loss:3.7914 train_time:185770ms step_avg:285.80ms
step:661/3000 train_loss:3.8837 train_time:186049ms step_avg:285.79ms
step:662/3000 train_loss:3.9513 train_time:186330ms step_avg:285.78ms
step:663/3000 train_loss:3.8681 train_time:186609ms step_avg:285.77ms
step:664/3000 train_loss:3.7446 train_time:186889ms step_avg:285.76ms
step:665/3000 train_loss:3.8336 train_time:187169ms step_avg:285.75ms
step:666/3000 train_loss:3.6988 train_time:187449ms step_avg:285.75ms
step:667/3000 train_loss:3.9893 train_time:187729ms step_avg:285.74ms
step:668/3000 train_loss:3.8202 train_time:188008ms step_avg:285.73ms
step:669/3000 train_loss:3.8299 train_time:188289ms step_avg:285.72ms
step:670/3000 train_loss:3.6819 train_time:188568ms step_avg:285.71ms
step:671/3000 train_loss:3.8009 train_time:188848ms step_avg:285.70ms
step:672/3000 train_loss:3.7621 train_time:189128ms step_avg:285.69ms
step:673/3000 train_loss:3.7785 train_time:189408ms step_avg:285.68ms
step:674/3000 train_loss:4.0542 train_time:189686ms step_avg:285.67ms
step:675/3000 train_loss:3.8372 train_time:189966ms step_avg:285.66ms
step:676/3000 train_loss:3.9161 train_time:190245ms step_avg:285.65ms
step:677/3000 train_loss:3.6919 train_time:190525ms step_avg:285.64ms
step:678/3000 train_loss:3.7950 train_time:190805ms step_avg:285.64ms
step:679/3000 train_loss:3.7424 train_time:191085ms step_avg:285.63ms
step:680/3000 train_loss:3.8849 train_time:191366ms step_avg:285.62ms
step:681/3000 train_loss:3.7910 train_time:191645ms step_avg:285.61ms
step:682/3000 train_loss:3.8181 train_time:191925ms step_avg:285.60ms
step:683/3000 train_loss:3.8853 train_time:192204ms step_avg:285.59ms
step:684/3000 train_loss:3.9408 train_time:192473ms step_avg:285.57ms
step:685/3000 train_loss:3.8353 train_time:192743ms step_avg:285.54ms
step:686/3000 train_loss:3.9030 train_time:193013ms step_avg:285.52ms
step:687/3000 train_loss:3.8321 train_time:193284ms step_avg:285.50ms
step:688/3000 train_loss:3.8802 train_time:193554ms step_avg:285.48ms
step:689/3000 train_loss:3.4845 train_time:193824ms step_avg:285.45ms
step:690/3000 train_loss:3.6112 train_time:194094ms step_avg:285.43ms
step:691/3000 train_loss:3.7538 train_time:194364ms step_avg:285.41ms
step:692/3000 train_loss:3.6354 train_time:194635ms step_avg:285.39ms
step:693/3000 train_loss:3.8480 train_time:194904ms step_avg:285.36ms
step:694/3000 train_loss:3.8648 train_time:195172ms step_avg:285.34ms
step:695/3000 train_loss:3.7513 train_time:195441ms step_avg:285.32ms
step:696/3000 train_loss:3.7384 train_time:195712ms step_avg:285.29ms
step:697/3000 train_loss:4.0556 train_time:195982ms step_avg:285.27ms
step:698/3000 train_loss:3.8029 train_time:196253ms step_avg:285.25ms
step:699/3000 train_loss:3.8454 train_time:196522ms step_avg:285.23ms
step:700/3000 train_loss:3.9989 train_time:196792ms step_avg:285.21ms
step:701/3000 train_loss:3.7742 train_time:197064ms step_avg:285.19ms
step:702/3000 train_loss:3.7338 train_time:197334ms step_avg:285.16ms
step:703/3000 train_loss:3.7176 train_time:197607ms step_avg:285.15ms
step:704/3000 train_loss:3.6788 train_time:197875ms step_avg:285.12ms
step:705/3000 train_loss:3.7711 train_time:198143ms step_avg:285.10ms
step:706/3000 train_loss:3.7696 train_time:198414ms step_avg:285.08ms
step:707/3000 train_loss:3.7768 train_time:198684ms step_avg:285.06ms
step:708/3000 train_loss:3.8458 train_time:198951ms step_avg:285.03ms
step:709/3000 train_loss:3.7982 train_time:199222ms step_avg:285.01ms
step:710/3000 train_loss:3.7793 train_time:199493ms step_avg:284.99ms
step:711/3000 train_loss:3.7532 train_time:199764ms step_avg:284.97ms
step:712/3000 train_loss:3.7872 train_time:200034ms step_avg:284.95ms
step:713/3000 train_loss:3.8443 train_time:200305ms step_avg:284.93ms
step:714/3000 train_loss:3.8576 train_time:200574ms step_avg:284.91ms
step:715/3000 train_loss:3.7716 train_time:200846ms step_avg:284.89ms
step:716/3000 train_loss:3.7689 train_time:201113ms step_avg:284.86ms
step:717/3000 train_loss:3.7905 train_time:201385ms step_avg:284.84ms
step:718/3000 train_loss:3.9367 train_time:201654ms step_avg:284.82ms
step:719/3000 train_loss:3.7946 train_time:201925ms step_avg:284.80ms
step:720/3000 train_loss:3.8675 train_time:202195ms step_avg:284.78ms
step:721/3000 train_loss:4.0236 train_time:202465ms step_avg:284.76ms
step:722/3000 train_loss:3.6648 train_time:202734ms step_avg:284.74ms
step:723/3000 train_loss:3.9250 train_time:203004ms step_avg:284.72ms
step:724/3000 train_loss:3.9839 train_time:203275ms step_avg:284.70ms
step:725/3000 train_loss:3.7675 train_time:203546ms step_avg:284.68ms
step:726/3000 train_loss:3.8444 train_time:203816ms step_avg:284.66ms
step:727/3000 train_loss:3.7475 train_time:204086ms step_avg:284.64ms
step:728/3000 train_loss:3.7586 train_time:204356ms step_avg:284.62ms
step:729/3000 train_loss:3.9406 train_time:204628ms step_avg:284.60ms
step:730/3000 train_loss:3.8776 train_time:204897ms step_avg:284.58ms
step:731/3000 train_loss:3.8749 train_time:205166ms step_avg:284.56ms
step:732/3000 train_loss:3.7626 train_time:205436ms step_avg:284.54ms
step:733/3000 train_loss:3.7846 train_time:205704ms step_avg:284.51ms
step:734/3000 train_loss:4.0300 train_time:205974ms step_avg:284.49ms
step:735/3000 train_loss:3.7616 train_time:206245ms step_avg:284.48ms
step:736/3000 train_loss:3.8185 train_time:206514ms step_avg:284.45ms
step:737/3000 train_loss:3.9434 train_time:206783ms step_avg:284.43ms
step:738/3000 train_loss:3.8545 train_time:207053ms step_avg:284.41ms
step:739/3000 train_loss:3.8053 train_time:207326ms step_avg:284.40ms
step:740/3000 train_loss:3.7038 train_time:207595ms step_avg:284.38ms
step:741/3000 train_loss:4.3350 train_time:207865ms step_avg:284.36ms
step:742/3000 train_loss:3.7012 train_time:208136ms step_avg:284.34ms
step:743/3000 train_loss:3.7750 train_time:208405ms step_avg:284.32ms
step:744/3000 train_loss:3.7807 train_time:208676ms step_avg:284.30ms
step:745/3000 train_loss:3.8459 train_time:208946ms step_avg:284.28ms
step:746/3000 train_loss:3.8158 train_time:209215ms step_avg:284.26ms
step:747/3000 train_loss:3.7976 train_time:209484ms step_avg:284.24ms
step:748/3000 train_loss:3.8300 train_time:209755ms step_avg:284.22ms
step:749/3000 train_loss:3.7679 train_time:210025ms step_avg:284.20ms
step:750/3000 train_loss:3.7666 train_time:210295ms step_avg:284.18ms
step:750/3000 val_loss:3.7729 train_time:210296ms step_avg:284.18ms
step:751/3000 train_loss:3.7987 train_time:210571ms step_avg:284.17ms
step:752/3000 train_loss:3.7631 train_time:210845ms step_avg:284.16ms
step:753/3000 train_loss:3.8005 train_time:211117ms step_avg:284.14ms
step:754/3000 train_loss:3.8193 train_time:211381ms step_avg:284.11ms
step:755/3000 train_loss:3.7873 train_time:211652ms step_avg:284.10ms
step:756/3000 train_loss:3.8623 train_time:212112ms step_avg:284.33ms
step:757/3000 train_loss:3.6931 train_time:212378ms step_avg:284.31ms
step:758/3000 train_loss:3.9286 train_time:212642ms step_avg:284.28ms
step:759/3000 train_loss:3.8486 train_time:212913ms step_avg:284.26ms
step:760/3000 train_loss:3.7785 train_time:213388ms step_avg:284.52ms
step:761/3000 train_loss:3.8857 train_time:213656ms step_avg:284.50ms
step:762/3000 train_loss:3.5988 train_time:213920ms step_avg:284.47ms
step:763/3000 train_loss:3.7491 train_time:214184ms step_avg:284.44ms
step:764/3000 train_loss:3.8701 train_time:214463ms step_avg:284.43ms
step:765/3000 train_loss:3.5131 train_time:214737ms step_avg:284.42ms
step:766/3000 train_loss:3.9410 train_time:215001ms step_avg:284.39ms
step:767/3000 train_loss:3.7959 train_time:215270ms step_avg:284.37ms
step:768/3000 train_loss:3.7591 train_time:215543ms step_avg:284.36ms
step:769/3000 train_loss:3.7784 train_time:215813ms step_avg:284.34ms
step:770/3000 train_loss:3.7961 train_time:216080ms step_avg:284.32ms
step:771/3000 train_loss:3.8527 train_time:216349ms step_avg:284.30ms
step:772/3000 train_loss:4.0840 train_time:216620ms step_avg:284.28ms
step:773/3000 train_loss:3.6575 train_time:216892ms step_avg:284.26ms
step:774/3000 train_loss:3.8492 train_time:217160ms step_avg:284.24ms
step:775/3000 train_loss:3.8375 train_time:217431ms step_avg:284.22ms
step:776/3000 train_loss:3.8088 train_time:217700ms step_avg:284.20ms
step:777/3000 train_loss:3.5967 train_time:217971ms step_avg:284.19ms
step:778/3000 train_loss:3.6120 train_time:218240ms step_avg:284.17ms
step:779/3000 train_loss:3.6765 train_time:218509ms step_avg:284.15ms
step:780/3000 train_loss:3.7730 train_time:218781ms step_avg:284.13ms
step:781/3000 train_loss:3.8040 train_time:219051ms step_avg:284.11ms
step:782/3000 train_loss:3.8554 train_time:219320ms step_avg:284.09ms
step:783/3000 train_loss:3.7718 train_time:219588ms step_avg:284.07ms
step:784/3000 train_loss:3.7761 train_time:219860ms step_avg:284.06ms
step:785/3000 train_loss:3.7764 train_time:220132ms step_avg:284.04ms
step:786/3000 train_loss:3.7572 train_time:220400ms step_avg:284.02ms
step:787/3000 train_loss:3.6498 train_time:220669ms step_avg:284.00ms
step:788/3000 train_loss:3.9543 train_time:220942ms step_avg:283.99ms
step:789/3000 train_loss:3.6972 train_time:221209ms step_avg:283.97ms
step:790/3000 train_loss:3.7619 train_time:221479ms step_avg:283.95ms
step:791/3000 train_loss:3.8209 train_time:221751ms step_avg:283.93ms
step:792/3000 train_loss:3.9660 train_time:222020ms step_avg:283.91ms
step:793/3000 train_loss:3.9642 train_time:222290ms step_avg:283.90ms
step:794/3000 train_loss:3.6755 train_time:222561ms step_avg:283.88ms
step:795/3000 train_loss:3.8008 train_time:222837ms step_avg:283.87ms
step:796/3000 train_loss:3.8581 train_time:223105ms step_avg:283.85ms
step:797/3000 train_loss:3.9503 train_time:223375ms step_avg:283.83ms
step:798/3000 train_loss:3.7154 train_time:223641ms step_avg:283.81ms
step:799/3000 train_loss:3.8588 train_time:223912ms step_avg:283.79ms
step:800/3000 train_loss:3.7515 train_time:224182ms step_avg:283.77ms
step:801/3000 train_loss:3.7398 train_time:224456ms step_avg:283.76ms
step:802/3000 train_loss:3.8324 train_time:224722ms step_avg:283.74ms
step:803/3000 train_loss:3.6878 train_time:224993ms step_avg:283.72ms
step:804/3000 train_loss:3.7189 train_time:225263ms step_avg:283.71ms
step:805/3000 train_loss:3.8293 train_time:225535ms step_avg:283.69ms
step:806/3000 train_loss:3.7323 train_time:225800ms step_avg:283.67ms
step:807/3000 train_loss:3.7397 train_time:226077ms step_avg:283.66ms
step:808/3000 train_loss:3.8402 train_time:226342ms step_avg:283.64ms
step:809/3000 train_loss:3.7581 train_time:226613ms step_avg:283.62ms
step:810/3000 train_loss:3.6849 train_time:226881ms step_avg:283.60ms
step:811/3000 train_loss:3.7650 train_time:227151ms step_avg:283.58ms
step:812/3000 train_loss:3.8027 train_time:227420ms step_avg:283.57ms
step:813/3000 train_loss:3.7928 train_time:227693ms step_avg:283.55ms
step:814/3000 train_loss:3.8216 train_time:227961ms step_avg:283.53ms
step:815/3000 train_loss:3.7695 train_time:228233ms step_avg:283.52ms
step:816/3000 train_loss:3.7546 train_time:228502ms step_avg:283.50ms
step:817/3000 train_loss:3.8571 train_time:228773ms step_avg:283.49ms
step:818/3000 train_loss:3.9553 train_time:229041ms step_avg:283.47ms
step:819/3000 train_loss:3.7239 train_time:229310ms step_avg:283.45ms
step:820/3000 train_loss:3.9267 train_time:229581ms step_avg:283.43ms
step:821/3000 train_loss:3.7095 train_time:229851ms step_avg:283.42ms
step:822/3000 train_loss:3.7476 train_time:230119ms step_avg:283.40ms
step:823/3000 train_loss:3.8670 train_time:230388ms step_avg:283.38ms
step:824/3000 train_loss:3.7817 train_time:230658ms step_avg:283.36ms
step:825/3000 train_loss:3.7114 train_time:230930ms step_avg:283.35ms
step:826/3000 train_loss:3.8147 train_time:231199ms step_avg:283.33ms
step:827/3000 train_loss:3.7052 train_time:231469ms step_avg:283.32ms
step:828/3000 train_loss:3.9355 train_time:231741ms step_avg:283.30ms
step:829/3000 train_loss:3.8191 train_time:232010ms step_avg:283.28ms
step:830/3000 train_loss:3.8796 train_time:232280ms step_avg:283.27ms
step:831/3000 train_loss:3.7299 train_time:232551ms step_avg:283.25ms
step:832/3000 train_loss:3.7876 train_time:232822ms step_avg:283.24ms
step:833/3000 train_loss:3.7108 train_time:233090ms step_avg:283.22ms
step:834/3000 train_loss:3.8449 train_time:233360ms step_avg:283.20ms
step:835/3000 train_loss:3.6872 train_time:233631ms step_avg:283.19ms
step:836/3000 train_loss:3.6573 train_time:233901ms step_avg:283.17ms
step:837/3000 train_loss:3.9276 train_time:234170ms step_avg:283.16ms
step:838/3000 train_loss:3.6153 train_time:234442ms step_avg:283.14ms
step:839/3000 train_loss:3.7864 train_time:234710ms step_avg:283.12ms
step:840/3000 train_loss:3.6315 train_time:234981ms step_avg:283.11ms
step:841/3000 train_loss:3.6707 train_time:235251ms step_avg:283.09ms
step:842/3000 train_loss:3.7602 train_time:235521ms step_avg:283.08ms
step:843/3000 train_loss:3.7740 train_time:235790ms step_avg:283.06ms
step:844/3000 train_loss:3.7778 train_time:236062ms step_avg:283.05ms
step:845/3000 train_loss:3.6256 train_time:236333ms step_avg:283.03ms
step:846/3000 train_loss:3.8663 train_time:236601ms step_avg:283.02ms
step:847/3000 train_loss:3.7286 train_time:236869ms step_avg:283.00ms
step:848/3000 train_loss:3.6887 train_time:237142ms step_avg:282.99ms
step:849/3000 train_loss:3.8303 train_time:237411ms step_avg:282.97ms
step:850/3000 train_loss:3.6905 train_time:237682ms step_avg:282.95ms
step:851/3000 train_loss:3.6529 train_time:237952ms step_avg:282.94ms
step:852/3000 train_loss:3.9402 train_time:238221ms step_avg:282.92ms
step:853/3000 train_loss:3.6504 train_time:238490ms step_avg:282.91ms
step:854/3000 train_loss:3.7636 train_time:238762ms step_avg:282.89ms
step:855/3000 train_loss:3.8474 train_time:239032ms step_avg:282.88ms
step:856/3000 train_loss:3.7240 train_time:239300ms step_avg:282.86ms
step:857/3000 train_loss:3.7494 train_time:239571ms step_avg:282.85ms
step:858/3000 train_loss:3.7972 train_time:239844ms step_avg:282.83ms
step:859/3000 train_loss:3.6782 train_time:240112ms step_avg:282.82ms
step:860/3000 train_loss:3.7623 train_time:240381ms step_avg:282.80ms
step:861/3000 train_loss:3.7929 train_time:240652ms step_avg:282.79ms
step:862/3000 train_loss:3.8448 train_time:240922ms step_avg:282.77ms
step:863/3000 train_loss:3.7874 train_time:241194ms step_avg:282.76ms
step:864/3000 train_loss:3.7682 train_time:241462ms step_avg:282.74ms
step:865/3000 train_loss:3.5932 train_time:241735ms step_avg:282.73ms
step:866/3000 train_loss:3.7885 train_time:242003ms step_avg:282.71ms
step:867/3000 train_loss:4.0623 train_time:242274ms step_avg:282.70ms
step:868/3000 train_loss:3.6421 train_time:242542ms step_avg:282.68ms
step:869/3000 train_loss:3.8336 train_time:242810ms step_avg:282.67ms
step:870/3000 train_loss:3.8157 train_time:243082ms step_avg:282.65ms
step:871/3000 train_loss:3.6458 train_time:243352ms step_avg:282.64ms
step:872/3000 train_loss:3.6218 train_time:243621ms step_avg:282.62ms
step:873/3000 train_loss:3.8649 train_time:243889ms step_avg:282.61ms
step:874/3000 train_loss:3.6488 train_time:244160ms step_avg:282.59ms
step:875/3000 train_loss:3.3744 train_time:244432ms step_avg:282.58ms
step:875/3000 val_loss:3.7250 train_time:244433ms step_avg:282.58ms
step:876/3000 train_loss:3.8429 train_time:244702ms step_avg:282.57ms
step:877/3000 train_loss:3.6506 train_time:244975ms step_avg:282.56ms
step:878/3000 train_loss:3.8207 train_time:245247ms step_avg:282.54ms
step:879/3000 train_loss:3.6829 train_time:245514ms step_avg:282.52ms
step:880/3000 train_loss:3.8612 train_time:245780ms step_avg:282.51ms
step:881/3000 train_loss:3.5182 train_time:246051ms step_avg:282.49ms
step:882/3000 train_loss:3.7010 train_time:246322ms step_avg:282.48ms
step:883/3000 train_loss:3.8852 train_time:246591ms step_avg:282.46ms
step:884/3000 train_loss:4.0448 train_time:246861ms step_avg:282.45ms
step:885/3000 train_loss:3.7735 train_time:247133ms step_avg:282.44ms
step:886/3000 train_loss:3.6806 train_time:247401ms step_avg:282.42ms
step:887/3000 train_loss:3.7801 train_time:247670ms step_avg:282.41ms
step:888/3000 train_loss:4.2809 train_time:247941ms step_avg:282.39ms
step:889/3000 train_loss:4.0427 train_time:248212ms step_avg:282.38ms
step:890/3000 train_loss:3.7207 train_time:248483ms step_avg:282.37ms
step:891/3000 train_loss:3.7335 train_time:248751ms step_avg:282.35ms
step:892/3000 train_loss:3.5609 train_time:249020ms step_avg:282.34ms
step:893/3000 train_loss:3.9040 train_time:249291ms step_avg:282.32ms
step:894/3000 train_loss:3.6288 train_time:249561ms step_avg:282.31ms
step:895/3000 train_loss:3.8734 train_time:249831ms step_avg:282.30ms
step:896/3000 train_loss:3.8962 train_time:250102ms step_avg:282.28ms
step:897/3000 train_loss:3.6977 train_time:250373ms step_avg:282.27ms
step:898/3000 train_loss:3.7330 train_time:250642ms step_avg:282.25ms
step:899/3000 train_loss:3.7843 train_time:250912ms step_avg:282.24ms
step:900/3000 train_loss:3.6776 train_time:251183ms step_avg:282.23ms
step:901/3000 train_loss:3.6153 train_time:251453ms step_avg:282.21ms
step:902/3000 train_loss:3.8321 train_time:251721ms step_avg:282.20ms
step:903/3000 train_loss:3.8320 train_time:251991ms step_avg:282.18ms
step:904/3000 train_loss:3.7302 train_time:252266ms step_avg:282.18ms
step:905/3000 train_loss:3.7010 train_time:252532ms step_avg:282.16ms
step:906/3000 train_loss:3.6969 train_time:252803ms step_avg:282.15ms
step:907/3000 train_loss:3.9178 train_time:253073ms step_avg:282.13ms
step:908/3000 train_loss:3.7107 train_time:253341ms step_avg:282.12ms
step:909/3000 train_loss:3.7566 train_time:253610ms step_avg:282.10ms
step:910/3000 train_loss:3.6519 train_time:253883ms step_avg:282.09ms
step:911/3000 train_loss:3.7444 train_time:254153ms step_avg:282.08ms
step:912/3000 train_loss:3.8188 train_time:254421ms step_avg:282.06ms
step:913/3000 train_loss:3.8200 train_time:254693ms step_avg:282.05ms
step:914/3000 train_loss:3.6752 train_time:254964ms step_avg:282.04ms
step:915/3000 train_loss:3.9327 train_time:255235ms step_avg:282.03ms
step:916/3000 train_loss:3.7333 train_time:255502ms step_avg:282.01ms
step:917/3000 train_loss:3.8229 train_time:255773ms step_avg:282.00ms
step:918/3000 train_loss:3.7949 train_time:256044ms step_avg:281.99ms
step:919/3000 train_loss:5.0563 train_time:256313ms step_avg:281.97ms
step:920/3000 train_loss:3.7198 train_time:256584ms step_avg:281.96ms
step:921/3000 train_loss:3.7680 train_time:256854ms step_avg:281.95ms
step:922/3000 train_loss:3.7344 train_time:257121ms step_avg:281.93ms
step:923/3000 train_loss:3.7846 train_time:257390ms step_avg:281.92ms
step:924/3000 train_loss:3.7933 train_time:257661ms step_avg:281.90ms
step:925/3000 train_loss:3.8808 train_time:257932ms step_avg:281.89ms
step:926/3000 train_loss:3.8599 train_time:258201ms step_avg:281.88ms
step:927/3000 train_loss:3.7523 train_time:258469ms step_avg:281.86ms
step:928/3000 train_loss:3.7416 train_time:258741ms step_avg:281.85ms
step:929/3000 train_loss:3.9770 train_time:259011ms step_avg:281.84ms
step:930/3000 train_loss:3.8148 train_time:259281ms step_avg:281.83ms
step:931/3000 train_loss:3.6006 train_time:259551ms step_avg:281.81ms
step:932/3000 train_loss:3.6873 train_time:259820ms step_avg:281.80ms
step:933/3000 train_loss:3.8751 train_time:260090ms step_avg:281.79ms
step:934/3000 train_loss:3.5926 train_time:260358ms step_avg:281.77ms
step:935/3000 train_loss:3.7779 train_time:260626ms step_avg:281.76ms
step:936/3000 train_loss:3.6478 train_time:260898ms step_avg:281.75ms
step:937/3000 train_loss:3.7118 train_time:261165ms step_avg:281.73ms
step:938/3000 train_loss:3.8122 train_time:261436ms step_avg:281.72ms
step:939/3000 train_loss:3.7362 train_time:261704ms step_avg:281.71ms
step:940/3000 train_loss:3.8998 train_time:261976ms step_avg:281.69ms
step:941/3000 train_loss:3.6854 train_time:262244ms step_avg:281.68ms
step:942/3000 train_loss:3.7450 train_time:262514ms step_avg:281.67ms
step:943/3000 train_loss:3.5462 train_time:262783ms step_avg:281.65ms
step:944/3000 train_loss:3.9009 train_time:263054ms step_avg:281.64ms
step:945/3000 train_loss:3.6134 train_time:263515ms step_avg:281.83ms
step:946/3000 train_loss:3.6217 train_time:263781ms step_avg:281.82ms
step:947/3000 train_loss:5.2373 train_time:264045ms step_avg:281.80ms
step:948/3000 train_loss:3.7981 train_time:264314ms step_avg:281.79ms
step:949/3000 train_loss:3.6977 train_time:264589ms step_avg:281.78ms
step:950/3000 train_loss:3.5863 train_time:265059ms step_avg:281.98ms
step:951/3000 train_loss:3.6510 train_time:265327ms step_avg:281.96ms
step:952/3000 train_loss:3.6066 train_time:265595ms step_avg:281.95ms
step:953/3000 train_loss:3.6741 train_time:265861ms step_avg:281.93ms
step:954/3000 train_loss:3.7518 train_time:266141ms step_avg:281.93ms
step:955/3000 train_loss:3.6313 train_time:266410ms step_avg:281.92ms
step:956/3000 train_loss:3.6741 train_time:266679ms step_avg:281.90ms
step:957/3000 train_loss:3.6414 train_time:266944ms step_avg:281.88ms
step:958/3000 train_loss:3.6991 train_time:267218ms step_avg:281.88ms
step:959/3000 train_loss:3.6887 train_time:267485ms step_avg:281.86ms
step:960/3000 train_loss:3.7076 train_time:267754ms step_avg:281.85ms
step:961/3000 train_loss:3.5885 train_time:268019ms step_avg:281.83ms
step:962/3000 train_loss:3.8534 train_time:268291ms step_avg:281.82ms
step:963/3000 train_loss:3.8066 train_time:268561ms step_avg:281.81ms
step:964/3000 train_loss:3.5972 train_time:268833ms step_avg:281.80ms
step:965/3000 train_loss:3.6498 train_time:269101ms step_avg:281.78ms
step:966/3000 train_loss:3.6802 train_time:269370ms step_avg:281.77ms
step:967/3000 train_loss:3.9054 train_time:269642ms step_avg:281.76ms
step:968/3000 train_loss:3.7353 train_time:269912ms step_avg:281.75ms
step:969/3000 train_loss:3.7132 train_time:270183ms step_avg:281.73ms
step:970/3000 train_loss:3.7696 train_time:270452ms step_avg:281.72ms
step:971/3000 train_loss:3.5785 train_time:270722ms step_avg:281.71ms
step:972/3000 train_loss:3.7438 train_time:270991ms step_avg:281.70ms
step:973/3000 train_loss:3.6930 train_time:271261ms step_avg:281.68ms
step:974/3000 train_loss:3.7399 train_time:271533ms step_avg:281.67ms
step:975/3000 train_loss:3.8111 train_time:271802ms step_avg:281.66ms
step:976/3000 train_loss:3.6896 train_time:272072ms step_avg:281.65ms
step:977/3000 train_loss:3.8804 train_time:272341ms step_avg:281.64ms
step:978/3000 train_loss:3.7666 train_time:272611ms step_avg:281.62ms
step:979/3000 train_loss:3.5908 train_time:272881ms step_avg:281.61ms
step:980/3000 train_loss:3.8897 train_time:273150ms step_avg:281.60ms
step:981/3000 train_loss:3.6160 train_time:273420ms step_avg:281.59ms
step:982/3000 train_loss:3.7778 train_time:273691ms step_avg:281.57ms
step:983/3000 train_loss:3.7595 train_time:273961ms step_avg:281.56ms
step:984/3000 train_loss:3.7689 train_time:274231ms step_avg:281.55ms
step:985/3000 train_loss:3.7090 train_time:274501ms step_avg:281.54ms
step:986/3000 train_loss:3.7936 train_time:274769ms step_avg:281.53ms
step:987/3000 train_loss:3.6142 train_time:275044ms step_avg:281.52ms
step:988/3000 train_loss:3.6898 train_time:275311ms step_avg:281.50ms
step:989/3000 train_loss:3.7084 train_time:275581ms step_avg:281.49ms
step:990/3000 train_loss:3.6291 train_time:275851ms step_avg:281.48ms
step:991/3000 train_loss:3.8394 train_time:276121ms step_avg:281.47ms
step:992/3000 train_loss:3.6685 train_time:276391ms step_avg:281.46ms
step:993/3000 train_loss:3.6396 train_time:276660ms step_avg:281.44ms
step:994/3000 train_loss:3.7117 train_time:276928ms step_avg:281.43ms
step:995/3000 train_loss:3.7939 train_time:277199ms step_avg:281.42ms
step:996/3000 train_loss:3.7401 train_time:277466ms step_avg:281.41ms
step:997/3000 train_loss:3.6501 train_time:277739ms step_avg:281.40ms
step:998/3000 train_loss:4.0043 train_time:278003ms step_avg:281.38ms
step:999/3000 train_loss:3.6630 train_time:278274ms step_avg:281.37ms
step:1000/3000 train_loss:3.7883 train_time:278544ms step_avg:281.36ms
step:1000/3000 val_loss:3.6836 train_time:278545ms step_avg:281.36ms
step:1001/3000 train_loss:3.6565 train_time:278815ms step_avg:281.35ms
step:1002/3000 train_loss:3.7099 train_time:279093ms step_avg:281.34ms
step:1003/3000 train_loss:3.5932 train_time:279363ms step_avg:281.33ms
step:1004/3000 train_loss:3.7774 train_time:279632ms step_avg:281.32ms
step:1005/3000 train_loss:3.8249 train_time:279896ms step_avg:281.30ms
step:1006/3000 train_loss:3.5987 train_time:280168ms step_avg:281.29ms
step:1007/3000 train_loss:3.6820 train_time:280439ms step_avg:281.28ms
step:1008/3000 train_loss:3.6453 train_time:280710ms step_avg:281.27ms
step:1009/3000 train_loss:3.7685 train_time:280975ms step_avg:281.26ms
step:1010/3000 train_loss:3.8784 train_time:281247ms step_avg:281.25ms
step:1011/3000 train_loss:3.7700 train_time:281517ms step_avg:281.24ms
step:1012/3000 train_loss:3.7285 train_time:281787ms step_avg:281.22ms
step:1013/3000 train_loss:3.5890 train_time:282054ms step_avg:281.21ms
step:1014/3000 train_loss:3.7319 train_time:282325ms step_avg:281.20ms
step:1015/3000 train_loss:3.8449 train_time:282595ms step_avg:281.19ms
step:1016/3000 train_loss:3.5526 train_time:282865ms step_avg:281.18ms
step:1017/3000 train_loss:3.6445 train_time:283135ms step_avg:281.17ms
step:1018/3000 train_loss:3.6484 train_time:283403ms step_avg:281.15ms
step:1019/3000 train_loss:3.5859 train_time:283674ms step_avg:281.14ms
step:1020/3000 train_loss:3.7342 train_time:283943ms step_avg:281.13ms
step:1021/3000 train_loss:3.6427 train_time:284213ms step_avg:281.12ms
step:1022/3000 train_loss:3.5744 train_time:284482ms step_avg:281.11ms
step:1023/3000 train_loss:3.6884 train_time:284752ms step_avg:281.10ms
step:1024/3000 train_loss:3.7127 train_time:285019ms step_avg:281.08ms
step:1025/3000 train_loss:3.6927 train_time:285291ms step_avg:281.07ms
step:1026/3000 train_loss:3.6966 train_time:285559ms step_avg:281.06ms
step:1027/3000 train_loss:3.8737 train_time:285832ms step_avg:281.05ms
step:1028/3000 train_loss:3.5467 train_time:286097ms step_avg:281.04ms
step:1029/3000 train_loss:3.6095 train_time:286368ms step_avg:281.03ms
step:1030/3000 train_loss:3.5638 train_time:286637ms step_avg:281.02ms
step:1031/3000 train_loss:3.7296 train_time:286908ms step_avg:281.01ms
step:1032/3000 train_loss:3.7135 train_time:287177ms step_avg:281.00ms
step:1033/3000 train_loss:3.8953 train_time:287448ms step_avg:280.99ms
step:1034/3000 train_loss:3.7072 train_time:287716ms step_avg:280.97ms
step:1035/3000 train_loss:3.6291 train_time:287986ms step_avg:280.96ms
step:1036/3000 train_loss:3.6483 train_time:288257ms step_avg:280.95ms
step:1037/3000 train_loss:3.7075 train_time:288529ms step_avg:280.94ms
step:1038/3000 train_loss:4.0243 train_time:288796ms step_avg:280.93ms
step:1039/3000 train_loss:3.8397 train_time:289067ms step_avg:280.92ms
step:1040/3000 train_loss:3.7268 train_time:289337ms step_avg:280.91ms
step:1041/3000 train_loss:3.6289 train_time:289606ms step_avg:280.90ms
step:1042/3000 train_loss:3.7043 train_time:289876ms step_avg:280.89ms
step:1043/3000 train_loss:3.7355 train_time:290146ms step_avg:280.88ms
step:1044/3000 train_loss:3.6651 train_time:290416ms step_avg:280.87ms
step:1045/3000 train_loss:3.6709 train_time:290685ms step_avg:280.85ms
step:1046/3000 train_loss:3.7547 train_time:290955ms step_avg:280.84ms
step:1047/3000 train_loss:3.6566 train_time:291226ms step_avg:280.84ms
step:1048/3000 train_loss:3.8670 train_time:291495ms step_avg:280.82ms
step:1049/3000 train_loss:3.7155 train_time:291763ms step_avg:280.81ms
step:1050/3000 train_loss:3.6412 train_time:292036ms step_avg:280.80ms
step:1051/3000 train_loss:3.6092 train_time:292305ms step_avg:280.79ms
step:1052/3000 train_loss:3.7314 train_time:292574ms step_avg:280.78ms
step:1053/3000 train_loss:3.6024 train_time:292844ms step_avg:280.77ms
step:1054/3000 train_loss:3.9318 train_time:293114ms step_avg:280.76ms
step:1055/3000 train_loss:3.7567 train_time:293384ms step_avg:280.75ms
step:1056/3000 train_loss:3.6124 train_time:293655ms step_avg:280.74ms
step:1057/3000 train_loss:3.7201 train_time:293924ms step_avg:280.73ms
step:1058/3000 train_loss:3.7927 train_time:294196ms step_avg:280.72ms
step:1059/3000 train_loss:3.5180 train_time:294464ms step_avg:280.71ms
step:1060/3000 train_loss:3.6385 train_time:294736ms step_avg:280.70ms
step:1061/3000 train_loss:3.6674 train_time:295006ms step_avg:280.69ms
step:1062/3000 train_loss:3.6327 train_time:295276ms step_avg:280.68ms
step:1063/3000 train_loss:3.6101 train_time:295545ms step_avg:280.67ms
step:1064/3000 train_loss:3.7140 train_time:295814ms step_avg:280.66ms
step:1065/3000 train_loss:3.6121 train_time:296084ms step_avg:280.65ms
step:1066/3000 train_loss:3.5924 train_time:296355ms step_avg:280.64ms
step:1067/3000 train_loss:3.6182 train_time:296626ms step_avg:280.63ms
step:1068/3000 train_loss:3.5333 train_time:296896ms step_avg:280.62ms
step:1069/3000 train_loss:3.6445 train_time:297165ms step_avg:280.61ms
step:1070/3000 train_loss:3.5160 train_time:297436ms step_avg:280.60ms
step:1071/3000 train_loss:3.7750 train_time:297704ms step_avg:280.59ms
step:1072/3000 train_loss:3.7284 train_time:297974ms step_avg:280.58ms
step:1073/3000 train_loss:3.6777 train_time:298244ms step_avg:280.57ms
step:1074/3000 train_loss:3.7413 train_time:298514ms step_avg:280.56ms
step:1075/3000 train_loss:3.6890 train_time:298783ms step_avg:280.55ms
step:1076/3000 train_loss:3.6172 train_time:299055ms step_avg:280.54ms
step:1077/3000 train_loss:4.0140 train_time:299325ms step_avg:280.53ms
step:1078/3000 train_loss:3.6931 train_time:299594ms step_avg:280.52ms
step:1079/3000 train_loss:3.3735 train_time:299863ms step_avg:280.51ms
step:1080/3000 train_loss:3.7518 train_time:300134ms step_avg:280.50ms
step:1081/3000 train_loss:3.6812 train_time:300404ms step_avg:280.49ms
step:1082/3000 train_loss:3.7414 train_time:300675ms step_avg:280.48ms
step:1083/3000 train_loss:3.8333 train_time:300945ms step_avg:280.47ms
step:1084/3000 train_loss:3.7305 train_time:301214ms step_avg:280.46ms
step:1085/3000 train_loss:3.7069 train_time:301485ms step_avg:280.45ms
step:1086/3000 train_loss:3.6696 train_time:301755ms step_avg:280.44ms
step:1087/3000 train_loss:3.8641 train_time:302028ms step_avg:280.43ms
step:1088/3000 train_loss:3.7555 train_time:302296ms step_avg:280.42ms
step:1089/3000 train_loss:3.5876 train_time:302563ms step_avg:280.41ms
step:1090/3000 train_loss:3.6117 train_time:302835ms step_avg:280.40ms
step:1091/3000 train_loss:3.7279 train_time:303107ms step_avg:280.40ms
step:1092/3000 train_loss:3.5189 train_time:303377ms step_avg:280.39ms
step:1093/3000 train_loss:3.7166 train_time:303646ms step_avg:280.38ms
step:1094/3000 train_loss:3.8573 train_time:303915ms step_avg:280.36ms
step:1095/3000 train_loss:3.6898 train_time:304186ms step_avg:280.36ms
step:1096/3000 train_loss:3.6375 train_time:304456ms step_avg:280.35ms
step:1097/3000 train_loss:3.6647 train_time:304729ms step_avg:280.34ms
step:1098/3000 train_loss:3.7093 train_time:304997ms step_avg:280.33ms
step:1099/3000 train_loss:3.7870 train_time:305268ms step_avg:280.32ms
step:1100/3000 train_loss:3.7430 train_time:305537ms step_avg:280.31ms
step:1101/3000 train_loss:3.6744 train_time:305806ms step_avg:280.30ms
step:1102/3000 train_loss:3.5319 train_time:306076ms step_avg:280.29ms
step:1103/3000 train_loss:3.5959 train_time:306346ms step_avg:280.28ms
step:1104/3000 train_loss:3.6775 train_time:306615ms step_avg:280.27ms
step:1105/3000 train_loss:3.5503 train_time:306886ms step_avg:280.26ms
step:1106/3000 train_loss:4.3109 train_time:307155ms step_avg:280.25ms
step:1107/3000 train_loss:3.4620 train_time:307427ms step_avg:280.24ms
step:1108/3000 train_loss:3.8018 train_time:307696ms step_avg:280.23ms
step:1109/3000 train_loss:3.5851 train_time:307965ms step_avg:280.22ms
step:1110/3000 train_loss:3.7327 train_time:308238ms step_avg:280.22ms
step:1111/3000 train_loss:3.6628 train_time:308507ms step_avg:280.21ms
step:1112/3000 train_loss:3.7064 train_time:308777ms step_avg:280.20ms
step:1113/3000 train_loss:3.8026 train_time:309048ms step_avg:280.19ms
step:1114/3000 train_loss:3.6643 train_time:309318ms step_avg:280.18ms
step:1115/3000 train_loss:3.5987 train_time:309587ms step_avg:280.17ms
step:1116/3000 train_loss:3.5037 train_time:309857ms step_avg:280.16ms
step:1117/3000 train_loss:3.6748 train_time:310131ms step_avg:280.15ms
step:1118/3000 train_loss:3.8284 train_time:310399ms step_avg:280.14ms
step:1119/3000 train_loss:3.8649 train_time:310669ms step_avg:280.13ms
step:1120/3000 train_loss:3.6958 train_time:310936ms step_avg:280.12ms
step:1121/3000 train_loss:3.7245 train_time:311207ms step_avg:280.11ms
step:1122/3000 train_loss:3.6266 train_time:311479ms step_avg:280.11ms
step:1123/3000 train_loss:3.6869 train_time:311748ms step_avg:280.10ms
step:1124/3000 train_loss:3.8267 train_time:312015ms step_avg:280.09ms
step:1125/3000 train_loss:3.5963 train_time:312286ms step_avg:280.08ms
step:1125/3000 val_loss:3.6549 train_time:312287ms step_avg:280.08ms
step:1126/3000 train_loss:3.5029 train_time:312557ms step_avg:280.07ms
step:1127/3000 train_loss:3.7182 train_time:312832ms step_avg:280.06ms
step:1128/3000 train_loss:3.9327 train_time:313106ms step_avg:280.06ms
step:1129/3000 train_loss:3.4748 train_time:313372ms step_avg:280.05ms
step:1130/3000 train_loss:3.7950 train_time:313639ms step_avg:280.04ms
step:1131/3000 train_loss:3.6227 train_time:313910ms step_avg:280.03ms
step:1132/3000 train_loss:3.6525 train_time:314184ms step_avg:280.02ms
step:1133/3000 train_loss:3.6058 train_time:314454ms step_avg:280.01ms
step:1134/3000 train_loss:3.7722 train_time:314911ms step_avg:280.17ms
step:1135/3000 train_loss:3.7005 train_time:315176ms step_avg:280.16ms
step:1136/3000 train_loss:3.7502 train_time:315441ms step_avg:280.14ms
step:1137/3000 train_loss:3.7901 train_time:315716ms step_avg:280.14ms
step:1138/3000 train_loss:3.7004 train_time:315992ms step_avg:280.13ms
step:1139/3000 train_loss:3.5976 train_time:316260ms step_avg:280.12ms
step:1140/3000 train_loss:3.9083 train_time:316730ms step_avg:280.29ms
step:1141/3000 train_loss:3.7080 train_time:316994ms step_avg:280.28ms
step:1142/3000 train_loss:3.8099 train_time:317260ms step_avg:280.27ms
step:1143/3000 train_loss:3.6928 train_time:317529ms step_avg:280.26ms
step:1144/3000 train_loss:3.6017 train_time:317805ms step_avg:280.25ms
step:1145/3000 train_loss:3.7064 train_time:318074ms step_avg:280.24ms
step:1146/3000 train_loss:3.8347 train_time:318341ms step_avg:280.23ms
step:1147/3000 train_loss:3.8001 train_time:318609ms step_avg:280.22ms
step:1148/3000 train_loss:3.7140 train_time:318879ms step_avg:280.21ms
step:1149/3000 train_loss:3.7419 train_time:319152ms step_avg:280.20ms
step:1150/3000 train_loss:3.5937 train_time:319420ms step_avg:280.19ms
step:1151/3000 train_loss:3.6069 train_time:319691ms step_avg:280.18ms
step:1152/3000 train_loss:3.5739 train_time:319956ms step_avg:280.17ms
step:1153/3000 train_loss:3.7251 train_time:320230ms step_avg:280.17ms
step:1154/3000 train_loss:3.6902 train_time:320498ms step_avg:280.16ms
step:1155/3000 train_loss:3.7505 train_time:320767ms step_avg:280.15ms
step:1156/3000 train_loss:3.6042 train_time:321034ms step_avg:280.13ms
step:1157/3000 train_loss:3.7752 train_time:321304ms step_avg:280.13ms
step:1158/3000 train_loss:3.7318 train_time:321574ms step_avg:280.12ms
step:1159/3000 train_loss:3.5456 train_time:321844ms step_avg:280.11ms
step:1160/3000 train_loss:3.5740 train_time:322112ms step_avg:280.10ms
step:1161/3000 train_loss:3.5680 train_time:322381ms step_avg:280.09ms
step:1162/3000 train_loss:3.3870 train_time:322652ms step_avg:280.08ms
step:1163/3000 train_loss:3.6853 train_time:322924ms step_avg:280.07ms
step:1164/3000 train_loss:3.6586 train_time:323193ms step_avg:280.06ms
step:1165/3000 train_loss:3.5175 train_time:323460ms step_avg:280.05ms
step:1166/3000 train_loss:3.5173 train_time:323732ms step_avg:280.04ms
step:1167/3000 train_loss:3.6258 train_time:324001ms step_avg:280.04ms
step:1168/3000 train_loss:3.6249 train_time:324271ms step_avg:280.03ms
step:1169/3000 train_loss:3.9561 train_time:324541ms step_avg:280.02ms
step:1170/3000 train_loss:3.6364 train_time:324811ms step_avg:280.01ms
step:1171/3000 train_loss:3.6446 train_time:325082ms step_avg:280.00ms
step:1172/3000 train_loss:3.5628 train_time:325352ms step_avg:279.99ms
step:1173/3000 train_loss:3.6471 train_time:325622ms step_avg:279.98ms
step:1174/3000 train_loss:3.7891 train_time:325892ms step_avg:279.98ms
step:1175/3000 train_loss:3.6285 train_time:326162ms step_avg:279.97ms
step:1176/3000 train_loss:3.6503 train_time:326433ms step_avg:279.96ms
step:1177/3000 train_loss:3.6965 train_time:326701ms step_avg:279.95ms
step:1178/3000 train_loss:3.6763 train_time:326972ms step_avg:279.94ms
step:1179/3000 train_loss:3.7392 train_time:327241ms step_avg:279.93ms
step:1180/3000 train_loss:3.6499 train_time:327511ms step_avg:279.92ms
step:1181/3000 train_loss:3.6531 train_time:327780ms step_avg:279.91ms
step:1182/3000 train_loss:3.5957 train_time:328050ms step_avg:279.91ms
step:1183/3000 train_loss:3.6621 train_time:328319ms step_avg:279.90ms
step:1184/3000 train_loss:3.5802 train_time:328590ms step_avg:279.89ms
step:1185/3000 train_loss:3.7456 train_time:328856ms step_avg:279.88ms
step:1186/3000 train_loss:3.8097 train_time:329130ms step_avg:279.87ms
step:1187/3000 train_loss:3.6024 train_time:329400ms step_avg:279.86ms
step:1188/3000 train_loss:3.6598 train_time:329670ms step_avg:279.86ms
step:1189/3000 train_loss:3.6859 train_time:329935ms step_avg:279.84ms
step:1190/3000 train_loss:3.5221 train_time:330205ms step_avg:279.83ms
step:1191/3000 train_loss:3.6999 train_time:330477ms step_avg:279.83ms
step:1192/3000 train_loss:3.8413 train_time:330748ms step_avg:279.82ms
step:1193/3000 train_loss:3.6445 train_time:331013ms step_avg:279.81ms
step:1194/3000 train_loss:3.5320 train_time:331284ms step_avg:279.80ms
step:1195/3000 train_loss:3.8249 train_time:331556ms step_avg:279.79ms
step:1196/3000 train_loss:3.6267 train_time:331828ms step_avg:279.79ms
step:1197/3000 train_loss:3.6294 train_time:332095ms step_avg:279.78ms
step:1198/3000 train_loss:3.5283 train_time:332367ms step_avg:279.77ms
step:1199/3000 train_loss:3.5406 train_time:332636ms step_avg:279.76ms
step:1200/3000 train_loss:3.5929 train_time:332908ms step_avg:279.75ms
step:1201/3000 train_loss:3.6822 train_time:333176ms step_avg:279.74ms
step:1202/3000 train_loss:3.7489 train_time:333448ms step_avg:279.74ms
step:1203/3000 train_loss:3.8362 train_time:333714ms step_avg:279.73ms
step:1204/3000 train_loss:3.6659 train_time:333985ms step_avg:279.72ms
step:1205/3000 train_loss:3.5851 train_time:334254ms step_avg:279.71ms
step:1206/3000 train_loss:3.6697 train_time:334527ms step_avg:279.70ms
step:1207/3000 train_loss:3.7231 train_time:334793ms step_avg:279.69ms
step:1208/3000 train_loss:3.7673 train_time:335063ms step_avg:279.69ms
step:1209/3000 train_loss:3.6477 train_time:335334ms step_avg:279.68ms
step:1210/3000 train_loss:3.5074 train_time:335605ms step_avg:279.67ms
step:1211/3000 train_loss:3.5576 train_time:335874ms step_avg:279.66ms
step:1212/3000 train_loss:3.6514 train_time:336143ms step_avg:279.65ms
step:1213/3000 train_loss:3.6663 train_time:336412ms step_avg:279.64ms
step:1214/3000 train_loss:3.7026 train_time:336681ms step_avg:279.64ms
step:1215/3000 train_loss:3.5934 train_time:336951ms step_avg:279.63ms
step:1216/3000 train_loss:3.6538 train_time:337224ms step_avg:279.62ms
step:1217/3000 train_loss:3.5930 train_time:337493ms step_avg:279.61ms
step:1218/3000 train_loss:3.5843 train_time:337761ms step_avg:279.60ms
step:1219/3000 train_loss:3.6824 train_time:338033ms step_avg:279.60ms
step:1220/3000 train_loss:3.5323 train_time:338304ms step_avg:279.59ms
step:1221/3000 train_loss:3.7519 train_time:338574ms step_avg:279.58ms
step:1222/3000 train_loss:3.7725 train_time:338842ms step_avg:279.57ms
step:1223/3000 train_loss:3.7001 train_time:339112ms step_avg:279.56ms
step:1224/3000 train_loss:3.5503 train_time:339382ms step_avg:279.56ms
step:1225/3000 train_loss:3.5427 train_time:339654ms step_avg:279.55ms
step:1226/3000 train_loss:3.6195 train_time:339924ms step_avg:279.54ms
step:1227/3000 train_loss:3.6029 train_time:340195ms step_avg:279.54ms
step:1228/3000 train_loss:3.5389 train_time:340464ms step_avg:279.53ms
step:1229/3000 train_loss:3.7160 train_time:340735ms step_avg:279.52ms
step:1230/3000 train_loss:3.6359 train_time:341003ms step_avg:279.51ms
step:1231/3000 train_loss:3.6931 train_time:341273ms step_avg:279.50ms
step:1232/3000 train_loss:3.8576 train_time:341545ms step_avg:279.50ms
step:1233/3000 train_loss:3.7453 train_time:341815ms step_avg:279.49ms
step:1234/3000 train_loss:3.6797 train_time:342083ms step_avg:279.48ms
step:1235/3000 train_loss:3.8404 train_time:342354ms step_avg:279.47ms
step:1236/3000 train_loss:3.6007 train_time:342624ms step_avg:279.46ms
step:1237/3000 train_loss:3.5649 train_time:342894ms step_avg:279.46ms
step:1238/3000 train_loss:3.5149 train_time:343163ms step_avg:279.45ms
step:1239/3000 train_loss:3.5896 train_time:343435ms step_avg:279.44ms
step:1240/3000 train_loss:3.5968 train_time:343703ms step_avg:279.43ms
step:1241/3000 train_loss:3.6458 train_time:343974ms step_avg:279.43ms
step:1242/3000 train_loss:3.6943 train_time:344245ms step_avg:279.42ms
step:1243/3000 train_loss:3.5640 train_time:344515ms step_avg:279.41ms
step:1244/3000 train_loss:3.6558 train_time:344785ms step_avg:279.40ms
step:1245/3000 train_loss:3.6776 train_time:345055ms step_avg:279.40ms
step:1246/3000 train_loss:3.6753 train_time:345326ms step_avg:279.39ms
step:1247/3000 train_loss:3.5039 train_time:345595ms step_avg:279.38ms
step:1248/3000 train_loss:3.6500 train_time:345863ms step_avg:279.37ms
step:1249/3000 train_loss:3.7091 train_time:346135ms step_avg:279.37ms
step:1250/3000 train_loss:3.6756 train_time:346404ms step_avg:279.36ms
step:1250/3000 val_loss:3.6258 train_time:346405ms step_avg:279.36ms
step:1251/3000 train_loss:3.5702 train_time:346677ms step_avg:279.35ms
step:1252/3000 train_loss:3.7770 train_time:346950ms step_avg:279.35ms
step:1253/3000 train_loss:3.6453 train_time:347222ms step_avg:279.34ms
step:1254/3000 train_loss:3.5736 train_time:347489ms step_avg:279.33ms
step:1255/3000 train_loss:3.7088 train_time:347758ms step_avg:279.32ms
step:1256/3000 train_loss:3.7747 train_time:348029ms step_avg:279.32ms
step:1257/3000 train_loss:3.5851 train_time:348302ms step_avg:279.31ms
step:1258/3000 train_loss:3.6113 train_time:348572ms step_avg:279.30ms
step:1259/3000 train_loss:3.6436 train_time:348837ms step_avg:279.29ms
step:1260/3000 train_loss:3.6084 train_time:349108ms step_avg:279.29ms
step:1261/3000 train_loss:3.4732 train_time:349379ms step_avg:279.28ms
step:1262/3000 train_loss:3.5669 train_time:349649ms step_avg:279.27ms
step:1263/3000 train_loss:3.6352 train_time:349918ms step_avg:279.26ms
step:1264/3000 train_loss:3.4863 train_time:350186ms step_avg:279.26ms
step:1265/3000 train_loss:3.7046 train_time:350458ms step_avg:279.25ms
step:1266/3000 train_loss:3.6910 train_time:350729ms step_avg:279.24ms
step:1267/3000 train_loss:3.6946 train_time:350995ms step_avg:279.23ms
step:1268/3000 train_loss:3.6390 train_time:351264ms step_avg:279.22ms
step:1269/3000 train_loss:3.6727 train_time:351534ms step_avg:279.22ms
step:1270/3000 train_loss:3.5372 train_time:351804ms step_avg:279.21ms
step:1271/3000 train_loss:3.3752 train_time:352073ms step_avg:279.20ms
step:1272/3000 train_loss:3.6566 train_time:352342ms step_avg:279.19ms
step:1273/3000 train_loss:3.6232 train_time:352614ms step_avg:279.19ms
step:1274/3000 train_loss:3.6709 train_time:352883ms step_avg:279.18ms
step:1275/3000 train_loss:3.6175 train_time:353154ms step_avg:279.17ms
step:1276/3000 train_loss:3.7127 train_time:353421ms step_avg:279.16ms
step:1277/3000 train_loss:3.7409 train_time:353691ms step_avg:279.16ms
step:1278/3000 train_loss:3.6958 train_time:353960ms step_avg:279.15ms
step:1279/3000 train_loss:3.6885 train_time:354229ms step_avg:279.14ms
step:1280/3000 train_loss:3.5206 train_time:354497ms step_avg:279.13ms
step:1281/3000 train_loss:3.6407 train_time:354767ms step_avg:279.12ms
step:1282/3000 train_loss:3.7000 train_time:355037ms step_avg:279.12ms
step:1283/3000 train_loss:3.7362 train_time:355309ms step_avg:279.11ms
step:1284/3000 train_loss:3.6247 train_time:355578ms step_avg:279.10ms
step:1285/3000 train_loss:3.6489 train_time:355847ms step_avg:279.10ms
step:1286/3000 train_loss:3.6304 train_time:356117ms step_avg:279.09ms
step:1287/3000 train_loss:3.6074 train_time:356386ms step_avg:279.08ms
step:1288/3000 train_loss:3.7414 train_time:356657ms step_avg:279.07ms
step:1289/3000 train_loss:3.5787 train_time:356927ms step_avg:279.07ms
step:1290/3000 train_loss:3.6557 train_time:357196ms step_avg:279.06ms
step:1291/3000 train_loss:3.7280 train_time:357465ms step_avg:279.05ms
step:1292/3000 train_loss:3.6586 train_time:357736ms step_avg:279.05ms
step:1293/3000 train_loss:3.7540 train_time:358007ms step_avg:279.04ms
step:1294/3000 train_loss:3.7798 train_time:358276ms step_avg:279.03ms
step:1295/3000 train_loss:3.7368 train_time:358545ms step_avg:279.02ms
step:1296/3000 train_loss:3.5569 train_time:358816ms step_avg:279.02ms
step:1297/3000 train_loss:3.6327 train_time:359086ms step_avg:279.01ms
step:1298/3000 train_loss:3.5332 train_time:359356ms step_avg:279.00ms
step:1299/3000 train_loss:3.6008 train_time:359626ms step_avg:279.00ms
step:1300/3000 train_loss:3.6728 train_time:359896ms step_avg:278.99ms
step:1301/3000 train_loss:3.6754 train_time:360167ms step_avg:278.98ms
step:1302/3000 train_loss:3.6856 train_time:360438ms step_avg:278.98ms
step:1303/3000 train_loss:3.8371 train_time:360708ms step_avg:278.97ms
step:1304/3000 train_loss:3.6115 train_time:360977ms step_avg:278.96ms
step:1305/3000 train_loss:3.8197 train_time:361245ms step_avg:278.95ms
step:1306/3000 train_loss:3.5468 train_time:361518ms step_avg:278.95ms
step:1307/3000 train_loss:3.7289 train_time:361786ms step_avg:278.94ms
step:1308/3000 train_loss:3.7297 train_time:362056ms step_avg:278.93ms
step:1309/3000 train_loss:3.5983 train_time:362326ms step_avg:278.93ms
step:1310/3000 train_loss:3.5622 train_time:362596ms step_avg:278.92ms
step:1311/3000 train_loss:3.5833 train_time:362865ms step_avg:278.91ms
step:1312/3000 train_loss:3.5589 train_time:363137ms step_avg:278.91ms
step:1313/3000 train_loss:3.6851 train_time:363407ms step_avg:278.90ms
step:1314/3000 train_loss:3.6246 train_time:363676ms step_avg:278.89ms
step:1315/3000 train_loss:3.3379 train_time:363946ms step_avg:278.89ms
step:1316/3000 train_loss:3.5803 train_time:364217ms step_avg:278.88ms
step:1317/3000 train_loss:3.6467 train_time:364487ms step_avg:278.87ms
step:1318/3000 train_loss:3.6794 train_time:364757ms step_avg:278.87ms
step:1319/3000 train_loss:3.5500 train_time:365025ms step_avg:278.86ms
step:1320/3000 train_loss:3.6949 train_time:365296ms step_avg:278.85ms
step:1321/3000 train_loss:3.7500 train_time:365566ms step_avg:278.85ms
step:1322/3000 train_loss:3.6359 train_time:365836ms step_avg:278.84ms
step:1323/3000 train_loss:3.5830 train_time:366292ms step_avg:278.97ms
step:1324/3000 train_loss:3.6154 train_time:366557ms step_avg:278.96ms
step:1325/3000 train_loss:3.7056 train_time:366821ms step_avg:278.95ms
step:1326/3000 train_loss:3.7597 train_time:367093ms step_avg:278.95ms
step:1327/3000 train_loss:3.5215 train_time:367365ms step_avg:278.94ms
step:1328/3000 train_loss:3.4382 train_time:367634ms step_avg:278.93ms
step:1329/3000 train_loss:3.7484 train_time:367898ms step_avg:278.92ms
step:1330/3000 train_loss:3.5956 train_time:368372ms step_avg:279.07ms
step:1331/3000 train_loss:3.7192 train_time:368638ms step_avg:279.06ms
step:1332/3000 train_loss:3.6324 train_time:368903ms step_avg:279.05ms
step:1333/3000 train_loss:4.0259 train_time:369171ms step_avg:279.04ms
step:1334/3000 train_loss:3.7254 train_time:369445ms step_avg:279.04ms
step:1335/3000 train_loss:3.6351 train_time:369716ms step_avg:279.03ms
step:1336/3000 train_loss:3.5876 train_time:369979ms step_avg:279.02ms
step:1337/3000 train_loss:3.5757 train_time:370250ms step_avg:279.01ms
step:1338/3000 train_loss:3.8363 train_time:370523ms step_avg:279.01ms
step:1339/3000 train_loss:3.7748 train_time:370791ms step_avg:279.00ms
step:1340/3000 train_loss:3.6157 train_time:371060ms step_avg:278.99ms
step:1341/3000 train_loss:3.5760 train_time:371329ms step_avg:278.99ms
step:1342/3000 train_loss:3.8838 train_time:371598ms step_avg:278.98ms
step:1343/3000 train_loss:3.6475 train_time:371869ms step_avg:278.97ms
step:1344/3000 train_loss:3.6462 train_time:372140ms step_avg:278.97ms
step:1345/3000 train_loss:3.7033 train_time:372411ms step_avg:278.96ms
step:1346/3000 train_loss:3.6720 train_time:372679ms step_avg:278.95ms
step:1347/3000 train_loss:3.5697 train_time:372949ms step_avg:278.94ms
step:1348/3000 train_loss:3.5200 train_time:373219ms step_avg:278.94ms
step:1349/3000 train_loss:3.6201 train_time:373489ms step_avg:278.93ms
step:1350/3000 train_loss:3.5488 train_time:373759ms step_avg:278.92ms
step:1351/3000 train_loss:3.6822 train_time:374030ms step_avg:278.92ms
step:1352/3000 train_loss:3.5311 train_time:374300ms step_avg:278.91ms
step:1353/3000 train_loss:3.5895 train_time:374570ms step_avg:278.91ms
step:1354/3000 train_loss:3.6992 train_time:374838ms step_avg:278.90ms
step:1355/3000 train_loss:3.5369 train_time:375110ms step_avg:278.89ms
step:1356/3000 train_loss:3.4607 train_time:375380ms step_avg:278.89ms
step:1357/3000 train_loss:3.8111 train_time:375646ms step_avg:278.88ms
step:1358/3000 train_loss:3.7368 train_time:375917ms step_avg:278.87ms
step:1359/3000 train_loss:3.4534 train_time:376187ms step_avg:278.86ms
step:1360/3000 train_loss:3.7358 train_time:376457ms step_avg:278.86ms
step:1361/3000 train_loss:3.6290 train_time:376727ms step_avg:278.85ms
step:1362/3000 train_loss:3.4944 train_time:376998ms step_avg:278.84ms
step:1363/3000 train_loss:3.6570 train_time:377266ms step_avg:278.84ms
step:1364/3000 train_loss:3.5545 train_time:377538ms step_avg:278.83ms
step:1365/3000 train_loss:3.5813 train_time:377809ms step_avg:278.83ms
step:1366/3000 train_loss:3.6035 train_time:378077ms step_avg:278.82ms
step:1367/3000 train_loss:3.7045 train_time:378345ms step_avg:278.81ms
step:1368/3000 train_loss:3.6817 train_time:378619ms step_avg:278.81ms
step:1369/3000 train_loss:3.6354 train_time:378887ms step_avg:278.80ms
step:1370/3000 train_loss:3.5454 train_time:379158ms step_avg:278.79ms
step:1371/3000 train_loss:3.8739 train_time:379427ms step_avg:278.79ms
step:1372/3000 train_loss:3.6144 train_time:379697ms step_avg:278.78ms
step:1373/3000 train_loss:3.6503 train_time:379967ms step_avg:278.77ms
step:1374/3000 train_loss:3.6476 train_time:380238ms step_avg:278.77ms
step:1375/3000 train_loss:3.4459 train_time:380512ms step_avg:278.76ms
step:1375/3000 val_loss:3.6056 train_time:380513ms step_avg:278.76ms
step:1376/3000 train_loss:3.8455 train_time:380784ms step_avg:278.76ms
step:1377/3000 train_loss:3.6217 train_time:381059ms step_avg:278.76ms
step:1378/3000 train_loss:3.7633 train_time:381332ms step_avg:278.75ms
step:1379/3000 train_loss:3.8103 train_time:381600ms step_avg:278.74ms
step:1380/3000 train_loss:3.4966 train_time:381868ms step_avg:278.74ms
step:1381/3000 train_loss:3.6187 train_time:382138ms step_avg:278.73ms
step:1382/3000 train_loss:4.0589 train_time:382411ms step_avg:278.73ms
step:1383/3000 train_loss:3.5247 train_time:382681ms step_avg:278.72ms
step:1384/3000 train_loss:3.6811 train_time:382948ms step_avg:278.71ms
step:1385/3000 train_loss:3.7545 train_time:383217ms step_avg:278.70ms
step:1386/3000 train_loss:3.6632 train_time:383487ms step_avg:278.70ms
step:1387/3000 train_loss:3.6755 train_time:383758ms step_avg:278.69ms
step:1388/3000 train_loss:3.4901 train_time:384026ms step_avg:278.68ms
step:1389/3000 train_loss:3.6343 train_time:384298ms step_avg:278.68ms
step:1390/3000 train_loss:3.6054 train_time:384567ms step_avg:278.67ms
step:1391/3000 train_loss:3.8735 train_time:384836ms step_avg:278.66ms
step:1392/3000 train_loss:3.5818 train_time:385107ms step_avg:278.66ms
step:1393/3000 train_loss:3.5678 train_time:385375ms step_avg:278.65ms
step:1394/3000 train_loss:3.5416 train_time:385645ms step_avg:278.65ms
step:1395/3000 train_loss:3.8224 train_time:385916ms step_avg:278.64ms
step:1396/3000 train_loss:3.7186 train_time:386186ms step_avg:278.63ms
step:1397/3000 train_loss:3.7188 train_time:386455ms step_avg:278.63ms
step:1398/3000 train_loss:3.5884 train_time:386725ms step_avg:278.62ms
step:1399/3000 train_loss:3.5639 train_time:386995ms step_avg:278.61ms
step:1400/3000 train_loss:3.6186 train_time:387265ms step_avg:278.61ms
step:1401/3000 train_loss:3.5959 train_time:387533ms step_avg:278.60ms
step:1402/3000 train_loss:3.6205 train_time:387804ms step_avg:278.60ms
step:1403/3000 train_loss:3.5900 train_time:388073ms step_avg:278.59ms
step:1404/3000 train_loss:3.8159 train_time:388345ms step_avg:278.58ms
step:1405/3000 train_loss:3.5528 train_time:388610ms step_avg:278.57ms
step:1406/3000 train_loss:3.6075 train_time:388882ms step_avg:278.57ms
step:1407/3000 train_loss:3.5996 train_time:389150ms step_avg:278.56ms
step:1408/3000 train_loss:3.4753 train_time:389423ms step_avg:278.56ms
step:1409/3000 train_loss:3.5866 train_time:389689ms step_avg:278.55ms
step:1410/3000 train_loss:3.5688 train_time:389960ms step_avg:278.54ms
step:1411/3000 train_loss:3.5730 train_time:390229ms step_avg:278.54ms
step:1412/3000 train_loss:3.6630 train_time:390502ms step_avg:278.53ms
step:1413/3000 train_loss:3.5943 train_time:390768ms step_avg:278.52ms
step:1414/3000 train_loss:3.6443 train_time:391038ms step_avg:278.52ms
step:1415/3000 train_loss:3.6381 train_time:391309ms step_avg:278.51ms
step:1416/3000 train_loss:3.7104 train_time:391579ms step_avg:278.51ms
step:1417/3000 train_loss:3.5112 train_time:391849ms step_avg:278.50ms
step:1418/3000 train_loss:3.5836 train_time:392118ms step_avg:278.49ms
step:1419/3000 train_loss:3.6664 train_time:392387ms step_avg:278.49ms
step:1420/3000 train_loss:3.7034 train_time:392656ms step_avg:278.48ms
step:1421/3000 train_loss:3.6782 train_time:392926ms step_avg:278.47ms
step:1422/3000 train_loss:3.6589 train_time:393198ms step_avg:278.47ms
step:1423/3000 train_loss:3.6474 train_time:393466ms step_avg:278.46ms
step:1424/3000 train_loss:3.6345 train_time:393734ms step_avg:278.45ms
step:1425/3000 train_loss:3.6228 train_time:394006ms step_avg:278.45ms
step:1426/3000 train_loss:3.5015 train_time:394276ms step_avg:278.44ms
step:1427/3000 train_loss:3.6139 train_time:394545ms step_avg:278.44ms
step:1428/3000 train_loss:3.5626 train_time:394817ms step_avg:278.43ms
step:1429/3000 train_loss:3.6685 train_time:395086ms step_avg:278.43ms
step:1430/3000 train_loss:3.6359 train_time:395355ms step_avg:278.42ms
step:1431/3000 train_loss:3.5652 train_time:395623ms step_avg:278.41ms
step:1432/3000 train_loss:3.6114 train_time:395894ms step_avg:278.41ms
step:1433/3000 train_loss:3.6494 train_time:396165ms step_avg:278.40ms
step:1434/3000 train_loss:3.5013 train_time:396435ms step_avg:278.40ms
step:1435/3000 train_loss:3.6252 train_time:396705ms step_avg:278.39ms
step:1436/3000 train_loss:3.4392 train_time:396973ms step_avg:278.38ms
step:1437/3000 train_loss:3.5068 train_time:397245ms step_avg:278.38ms
step:1438/3000 train_loss:3.7050 train_time:397515ms step_avg:278.37ms
step:1439/3000 train_loss:3.6611 train_time:397784ms step_avg:278.37ms
step:1440/3000 train_loss:3.6121 train_time:398053ms step_avg:278.36ms
step:1441/3000 train_loss:3.4642 train_time:398325ms step_avg:278.35ms
step:1442/3000 train_loss:3.6425 train_time:398594ms step_avg:278.35ms
step:1443/3000 train_loss:3.6994 train_time:398864ms step_avg:278.34ms
step:1444/3000 train_loss:3.7692 train_time:399130ms step_avg:278.33ms
step:1445/3000 train_loss:3.7423 train_time:399403ms step_avg:278.33ms
step:1446/3000 train_loss:3.6236 train_time:399673ms step_avg:278.32ms
step:1447/3000 train_loss:3.4989 train_time:399944ms step_avg:278.32ms
step:1448/3000 train_loss:3.5726 train_time:400212ms step_avg:278.31ms
step:1449/3000 train_loss:3.5935 train_time:400481ms step_avg:278.30ms
step:1450/3000 train_loss:3.7121 train_time:400751ms step_avg:278.30ms
step:1451/3000 train_loss:3.7011 train_time:401021ms step_avg:278.29ms
step:1452/3000 train_loss:3.5177 train_time:401288ms step_avg:278.29ms
step:1453/3000 train_loss:3.6294 train_time:401558ms step_avg:278.28ms
step:1454/3000 train_loss:3.5443 train_time:401828ms step_avg:278.27ms
step:1455/3000 train_loss:3.5808 train_time:402101ms step_avg:278.27ms
step:1456/3000 train_loss:3.6181 train_time:402368ms step_avg:278.26ms
step:1457/3000 train_loss:3.5521 train_time:402636ms step_avg:278.26ms
step:1458/3000 train_loss:3.4531 train_time:402907ms step_avg:278.25ms
step:1459/3000 train_loss:3.7005 train_time:403178ms step_avg:278.25ms
step:1460/3000 train_loss:3.5742 train_time:403447ms step_avg:278.24ms
step:1461/3000 train_loss:3.6147 train_time:403716ms step_avg:278.23ms
step:1462/3000 train_loss:3.7410 train_time:403985ms step_avg:278.23ms
step:1463/3000 train_loss:3.5623 train_time:404255ms step_avg:278.22ms
step:1464/3000 train_loss:3.7557 train_time:404524ms step_avg:278.21ms
step:1465/3000 train_loss:3.6432 train_time:404794ms step_avg:278.21ms
step:1466/3000 train_loss:3.6477 train_time:405064ms step_avg:278.20ms
step:1467/3000 train_loss:3.5697 train_time:405333ms step_avg:278.20ms
step:1468/3000 train_loss:3.7282 train_time:405605ms step_avg:278.19ms
step:1469/3000 train_loss:3.5899 train_time:405870ms step_avg:278.18ms
step:1470/3000 train_loss:3.5589 train_time:406141ms step_avg:278.18ms
step:1471/3000 train_loss:3.6084 train_time:406409ms step_avg:278.17ms
step:1472/3000 train_loss:3.5410 train_time:406680ms step_avg:278.17ms
step:1473/3000 train_loss:3.6329 train_time:406948ms step_avg:278.16ms
step:1474/3000 train_loss:3.7247 train_time:407221ms step_avg:278.16ms
step:1475/3000 train_loss:3.6000 train_time:407490ms step_avg:278.15ms
step:1476/3000 train_loss:3.4263 train_time:407763ms step_avg:278.15ms
step:1477/3000 train_loss:3.5494 train_time:408030ms step_avg:278.14ms
step:1478/3000 train_loss:3.5269 train_time:408303ms step_avg:278.14ms
step:1479/3000 train_loss:3.6131 train_time:408569ms step_avg:278.13ms
step:1480/3000 train_loss:3.6956 train_time:408840ms step_avg:278.12ms
step:1481/3000 train_loss:3.5709 train_time:409107ms step_avg:278.11ms
step:1482/3000 train_loss:3.7442 train_time:409380ms step_avg:278.11ms
step:1483/3000 train_loss:3.6651 train_time:409649ms step_avg:278.11ms
step:1484/3000 train_loss:3.5672 train_time:409919ms step_avg:278.10ms
step:1485/3000 train_loss:3.5573 train_time:410189ms step_avg:278.09ms
step:1486/3000 train_loss:3.5544 train_time:410462ms step_avg:278.09ms
step:1487/3000 train_loss:3.5310 train_time:410729ms step_avg:278.08ms
step:1488/3000 train_loss:3.6160 train_time:411000ms step_avg:278.08ms
step:1489/3000 train_loss:3.5260 train_time:411269ms step_avg:278.07ms
step:1490/3000 train_loss:3.6207 train_time:411539ms step_avg:278.07ms
step:1491/3000 train_loss:3.5538 train_time:411809ms step_avg:278.06ms
step:1492/3000 train_loss:3.4772 train_time:412078ms step_avg:278.06ms
step:1493/3000 train_loss:3.5550 train_time:412349ms step_avg:278.05ms
step:1494/3000 train_loss:3.7239 train_time:412618ms step_avg:278.04ms
step:1495/3000 train_loss:3.5797 train_time:412885ms step_avg:278.04ms
step:1496/3000 train_loss:3.3321 train_time:413156ms step_avg:278.03ms
step:1497/3000 train_loss:3.6433 train_time:413428ms step_avg:278.03ms
step:1498/3000 train_loss:3.6050 train_time:413698ms step_avg:278.02ms
step:1499/3000 train_loss:3.6456 train_time:413968ms step_avg:278.02ms
step:1500/3000 train_loss:3.6074 train_time:414238ms step_avg:278.01ms
step:1500/3000 val_loss:3.5808 train_time:414238ms step_avg:278.01ms
step:1501/3000 train_loss:3.5825 train_time:414510ms step_avg:278.01ms
step:1502/3000 train_loss:3.3811 train_time:414785ms step_avg:278.01ms
step:1503/3000 train_loss:3.6618 train_time:415057ms step_avg:278.00ms
step:1504/3000 train_loss:3.5291 train_time:415324ms step_avg:277.99ms
step:1505/3000 train_loss:3.5393 train_time:415588ms step_avg:277.99ms
step:1506/3000 train_loss:3.4957 train_time:415865ms step_avg:277.98ms
step:1507/3000 train_loss:3.5814 train_time:416138ms step_avg:277.98ms
step:1508/3000 train_loss:3.4932 train_time:416408ms step_avg:277.98ms
step:1509/3000 train_loss:3.8150 train_time:416674ms step_avg:277.97ms
step:1510/3000 train_loss:3.5523 train_time:416946ms step_avg:277.96ms
step:1511/3000 train_loss:3.5614 train_time:417217ms step_avg:277.96ms
step:1512/3000 train_loss:3.6868 train_time:417679ms step_avg:278.08ms
step:1513/3000 train_loss:3.7181 train_time:417946ms step_avg:278.07ms
step:1514/3000 train_loss:3.5691 train_time:418210ms step_avg:278.07ms
step:1515/3000 train_loss:3.3987 train_time:418484ms step_avg:278.06ms
step:1516/3000 train_loss:3.5331 train_time:418756ms step_avg:278.06ms
step:1517/3000 train_loss:3.5388 train_time:419025ms step_avg:278.05ms
step:1518/3000 train_loss:3.6193 train_time:419290ms step_avg:278.04ms
step:1519/3000 train_loss:3.5114 train_time:419558ms step_avg:278.04ms
step:1520/3000 train_loss:3.8007 train_time:420030ms step_avg:278.17ms
step:1521/3000 train_loss:3.4634 train_time:420296ms step_avg:278.16ms
step:1522/3000 train_loss:3.5216 train_time:420564ms step_avg:278.15ms
step:1523/3000 train_loss:3.6732 train_time:420828ms step_avg:278.14ms
step:1524/3000 train_loss:3.5290 train_time:421107ms step_avg:278.14ms
step:1525/3000 train_loss:3.6164 train_time:421376ms step_avg:278.14ms
step:1526/3000 train_loss:3.6155 train_time:421646ms step_avg:278.13ms
step:1527/3000 train_loss:3.5792 train_time:421910ms step_avg:278.12ms
step:1528/3000 train_loss:3.5826 train_time:422183ms step_avg:278.12ms
step:1529/3000 train_loss:3.7303 train_time:422450ms step_avg:278.11ms
step:1530/3000 train_loss:3.6996 train_time:422720ms step_avg:278.11ms
step:1531/3000 train_loss:3.5332 train_time:422988ms step_avg:278.10ms
step:1532/3000 train_loss:3.4812 train_time:423258ms step_avg:278.09ms
step:1533/3000 train_loss:3.6490 train_time:423529ms step_avg:278.09ms
step:1534/3000 train_loss:3.5972 train_time:423800ms step_avg:278.08ms
step:1535/3000 train_loss:3.5875 train_time:424068ms step_avg:278.08ms
step:1536/3000 train_loss:3.5775 train_time:424338ms step_avg:278.07ms
step:1537/3000 train_loss:3.5150 train_time:424609ms step_avg:278.07ms
step:1538/3000 train_loss:3.5809 train_time:424876ms step_avg:278.06ms
step:1539/3000 train_loss:3.7549 train_time:425145ms step_avg:278.05ms
step:1540/3000 train_loss:3.6859 train_time:425413ms step_avg:278.05ms
step:1541/3000 train_loss:3.5905 train_time:425683ms step_avg:278.04ms
step:1542/3000 train_loss:3.5469 train_time:425951ms step_avg:278.04ms
step:1543/3000 train_loss:3.5415 train_time:426221ms step_avg:278.03ms
step:1544/3000 train_loss:3.5037 train_time:426490ms step_avg:278.02ms
step:1545/3000 train_loss:3.6014 train_time:426760ms step_avg:278.02ms
step:1546/3000 train_loss:3.5656 train_time:427029ms step_avg:278.01ms
step:1547/3000 train_loss:3.5413 train_time:427299ms step_avg:278.01ms
step:1548/3000 train_loss:3.5042 train_time:427569ms step_avg:278.00ms
step:1549/3000 train_loss:3.5384 train_time:427836ms step_avg:278.00ms
step:1550/3000 train_loss:3.6466 train_time:428108ms step_avg:277.99ms
step:1551/3000 train_loss:3.5748 train_time:428377ms step_avg:277.99ms
step:1552/3000 train_loss:3.5159 train_time:428648ms step_avg:277.98ms
step:1553/3000 train_loss:3.5143 train_time:428918ms step_avg:277.98ms
step:1554/3000 train_loss:3.5053 train_time:429187ms step_avg:277.97ms
step:1555/3000 train_loss:3.6341 train_time:429457ms step_avg:277.97ms
step:1556/3000 train_loss:3.6340 train_time:429727ms step_avg:277.96ms
step:1557/3000 train_loss:3.5752 train_time:429998ms step_avg:277.96ms
step:1558/3000 train_loss:3.6231 train_time:430266ms step_avg:277.95ms
step:1559/3000 train_loss:3.5493 train_time:430534ms step_avg:277.94ms
step:1560/3000 train_loss:3.4660 train_time:430805ms step_avg:277.94ms
step:1561/3000 train_loss:3.7091 train_time:431076ms step_avg:277.93ms
step:1562/3000 train_loss:3.5287 train_time:431346ms step_avg:277.93ms
step:1563/3000 train_loss:3.5055 train_time:431615ms step_avg:277.92ms
step:1564/3000 train_loss:3.6294 train_time:431886ms step_avg:277.92ms
step:1565/3000 train_loss:3.4599 train_time:432155ms step_avg:277.91ms
step:1566/3000 train_loss:3.5175 train_time:432426ms step_avg:277.91ms
step:1567/3000 train_loss:3.6620 train_time:432696ms step_avg:277.90ms
step:1568/3000 train_loss:3.5435 train_time:432965ms step_avg:277.90ms
step:1569/3000 train_loss:3.5219 train_time:433235ms step_avg:277.89ms
step:1570/3000 train_loss:3.6280 train_time:433506ms step_avg:277.89ms
step:1571/3000 train_loss:3.6326 train_time:433775ms step_avg:277.88ms
step:1572/3000 train_loss:3.4577 train_time:434046ms step_avg:277.88ms
step:1573/3000 train_loss:3.4900 train_time:434315ms step_avg:277.87ms
step:1574/3000 train_loss:3.6129 train_time:434585ms step_avg:277.87ms
step:1575/3000 train_loss:3.4793 train_time:434855ms step_avg:277.86ms
step:1576/3000 train_loss:3.6291 train_time:435125ms step_avg:277.86ms
step:1577/3000 train_loss:3.5294 train_time:435396ms step_avg:277.85ms
step:1578/3000 train_loss:3.5847 train_time:435666ms step_avg:277.85ms
step:1579/3000 train_loss:3.5547 train_time:435935ms step_avg:277.84ms
step:1580/3000 train_loss:3.5233 train_time:436207ms step_avg:277.84ms
step:1581/3000 train_loss:3.4899 train_time:436476ms step_avg:277.83ms
step:1582/3000 train_loss:3.7391 train_time:436746ms step_avg:277.83ms
step:1583/3000 train_loss:3.5162 train_time:437016ms step_avg:277.82ms
step:1584/3000 train_loss:3.6609 train_time:437287ms step_avg:277.82ms
step:1585/3000 train_loss:3.4970 train_time:437559ms step_avg:277.82ms
step:1586/3000 train_loss:3.6588 train_time:437828ms step_avg:277.81ms
step:1587/3000 train_loss:3.4380 train_time:438098ms step_avg:277.80ms
step:1588/3000 train_loss:3.6377 train_time:438367ms step_avg:277.80ms
step:1589/3000 train_loss:3.5514 train_time:438637ms step_avg:277.79ms
step:1590/3000 train_loss:3.7096 train_time:438907ms step_avg:277.79ms
step:1591/3000 train_loss:3.5264 train_time:439176ms step_avg:277.78ms
step:1592/3000 train_loss:3.5449 train_time:439449ms step_avg:277.78ms
step:1593/3000 train_loss:3.6081 train_time:439719ms step_avg:277.78ms
step:1594/3000 train_loss:3.5836 train_time:439989ms step_avg:277.77ms
step:1595/3000 train_loss:3.5593 train_time:440258ms step_avg:277.77ms
step:1596/3000 train_loss:3.6991 train_time:440532ms step_avg:277.76ms
step:1597/3000 train_loss:3.4351 train_time:440800ms step_avg:277.76ms
step:1598/3000 train_loss:3.5894 train_time:441068ms step_avg:277.75ms
step:1599/3000 train_loss:3.6326 train_time:441338ms step_avg:277.75ms
step:1600/3000 train_loss:3.6798 train_time:441609ms step_avg:277.74ms
step:1601/3000 train_loss:3.5306 train_time:441877ms step_avg:277.74ms
step:1602/3000 train_loss:3.8277 train_time:442149ms step_avg:277.73ms
step:1603/3000 train_loss:3.7163 train_time:442418ms step_avg:277.73ms
step:1604/3000 train_loss:3.4868 train_time:442689ms step_avg:277.72ms
step:1605/3000 train_loss:3.5347 train_time:442957ms step_avg:277.72ms
step:1606/3000 train_loss:3.4176 train_time:443229ms step_avg:277.71ms
step:1607/3000 train_loss:3.7406 train_time:443500ms step_avg:277.71ms
step:1608/3000 train_loss:3.5430 train_time:443770ms step_avg:277.70ms
step:1609/3000 train_loss:3.5664 train_time:444039ms step_avg:277.70ms
step:1610/3000 train_loss:3.5123 train_time:444309ms step_avg:277.69ms
step:1611/3000 train_loss:4.1064 train_time:444578ms step_avg:277.69ms
step:1612/3000 train_loss:3.7499 train_time:444849ms step_avg:277.68ms
step:1613/3000 train_loss:3.6616 train_time:445120ms step_avg:277.68ms
step:1614/3000 train_loss:3.5297 train_time:445387ms step_avg:277.67ms
step:1615/3000 train_loss:3.5726 train_time:445655ms step_avg:277.67ms
step:1616/3000 train_loss:3.5639 train_time:445928ms step_avg:277.66ms
step:1617/3000 train_loss:3.5172 train_time:446200ms step_avg:277.66ms
step:1618/3000 train_loss:3.6027 train_time:446468ms step_avg:277.65ms
step:1619/3000 train_loss:3.5563 train_time:446738ms step_avg:277.65ms
step:1620/3000 train_loss:3.4472 train_time:447009ms step_avg:277.65ms
step:1621/3000 train_loss:3.7225 train_time:447278ms step_avg:277.64ms
step:1622/3000 train_loss:3.6194 train_time:447548ms step_avg:277.64ms
step:1623/3000 train_loss:3.4119 train_time:447817ms step_avg:277.63ms
step:1624/3000 train_loss:3.5309 train_time:448088ms step_avg:277.63ms
step:1625/3000 train_loss:3.4913 train_time:448357ms step_avg:277.62ms
step:1625/3000 val_loss:3.5608 train_time:448358ms step_avg:277.62ms
step:1626/3000 train_loss:3.5704 train_time:448631ms step_avg:277.62ms
step:1627/3000 train_loss:3.5290 train_time:448901ms step_avg:277.61ms
step:1628/3000 train_loss:3.4924 train_time:449173ms step_avg:277.61ms
step:1629/3000 train_loss:3.6026 train_time:449438ms step_avg:277.60ms
step:1630/3000 train_loss:3.5018 train_time:449706ms step_avg:277.60ms
step:1631/3000 train_loss:3.5583 train_time:449976ms step_avg:277.59ms
step:1632/3000 train_loss:3.4352 train_time:450250ms step_avg:277.59ms
step:1633/3000 train_loss:3.4067 train_time:450515ms step_avg:277.58ms
step:1634/3000 train_loss:3.5733 train_time:450787ms step_avg:277.58ms
step:1635/3000 train_loss:3.5480 train_time:451056ms step_avg:277.57ms
step:1636/3000 train_loss:3.4931 train_time:451328ms step_avg:277.57ms
step:1637/3000 train_loss:3.5821 train_time:451595ms step_avg:277.56ms
step:1638/3000 train_loss:3.6303 train_time:451865ms step_avg:277.56ms
step:1639/3000 train_loss:3.6677 train_time:452135ms step_avg:277.55ms
step:1640/3000 train_loss:3.8187 train_time:452407ms step_avg:277.55ms
step:1641/3000 train_loss:3.6492 train_time:452673ms step_avg:277.54ms
step:1642/3000 train_loss:3.5609 train_time:452943ms step_avg:277.54ms
step:1643/3000 train_loss:3.6444 train_time:453213ms step_avg:277.53ms
step:1644/3000 train_loss:3.5419 train_time:453485ms step_avg:277.53ms
step:1645/3000 train_loss:3.5622 train_time:453754ms step_avg:277.53ms
step:1646/3000 train_loss:3.5628 train_time:454023ms step_avg:277.52ms
step:1647/3000 train_loss:3.3381 train_time:454293ms step_avg:277.52ms
step:1648/3000 train_loss:3.5966 train_time:454564ms step_avg:277.51ms
step:1649/3000 train_loss:3.4621 train_time:454835ms step_avg:277.51ms
step:1650/3000 train_loss:3.5417 train_time:455103ms step_avg:277.50ms
step:1651/3000 train_loss:3.5145 train_time:455373ms step_avg:277.50ms
step:1652/3000 train_loss:3.5867 train_time:455643ms step_avg:277.49ms
step:1653/3000 train_loss:3.5189 train_time:455914ms step_avg:277.49ms
step:1654/3000 train_loss:3.6422 train_time:456185ms step_avg:277.48ms
step:1655/3000 train_loss:3.6299 train_time:456453ms step_avg:277.48ms
step:1656/3000 train_loss:3.4524 train_time:456724ms step_avg:277.47ms
step:1657/3000 train_loss:3.6003 train_time:456995ms step_avg:277.47ms
step:1658/3000 train_loss:3.5002 train_time:457262ms step_avg:277.46ms
step:1659/3000 train_loss:3.4855 train_time:457533ms step_avg:277.46ms
step:1660/3000 train_loss:3.5644 train_time:457803ms step_avg:277.46ms
step:1661/3000 train_loss:3.5931 train_time:458073ms step_avg:277.45ms
step:1662/3000 train_loss:3.5119 train_time:458342ms step_avg:277.45ms
step:1663/3000 train_loss:3.6006 train_time:458613ms step_avg:277.44ms
step:1664/3000 train_loss:3.6055 train_time:458884ms step_avg:277.44ms
step:1665/3000 train_loss:3.6343 train_time:459153ms step_avg:277.43ms
step:1666/3000 train_loss:3.6119 train_time:459421ms step_avg:277.43ms
step:1667/3000 train_loss:3.7510 train_time:459693ms step_avg:277.42ms
step:1668/3000 train_loss:3.4624 train_time:459964ms step_avg:277.42ms
step:1669/3000 train_loss:3.5400 train_time:460233ms step_avg:277.42ms
step:1670/3000 train_loss:3.4650 train_time:460502ms step_avg:277.41ms
step:1671/3000 train_loss:3.4707 train_time:460772ms step_avg:277.41ms
step:1672/3000 train_loss:3.6356 train_time:461044ms step_avg:277.40ms
step:1673/3000 train_loss:3.8174 train_time:461315ms step_avg:277.40ms
step:1674/3000 train_loss:3.5289 train_time:461585ms step_avg:277.40ms
step:1675/3000 train_loss:3.5106 train_time:461854ms step_avg:277.39ms
step:1676/3000 train_loss:3.4031 train_time:462127ms step_avg:277.39ms
step:1677/3000 train_loss:3.6054 train_time:462395ms step_avg:277.38ms
step:1678/3000 train_loss:3.5190 train_time:462664ms step_avg:277.38ms
step:1679/3000 train_loss:3.5457 train_time:462934ms step_avg:277.37ms
step:1680/3000 train_loss:3.5335 train_time:463206ms step_avg:277.37ms
step:1681/3000 train_loss:3.3598 train_time:463474ms step_avg:277.36ms
step:1682/3000 train_loss:3.5386 train_time:463743ms step_avg:277.36ms
step:1683/3000 train_loss:3.5525 train_time:464013ms step_avg:277.35ms
step:1684/3000 train_loss:3.5958 train_time:464283ms step_avg:277.35ms
step:1685/3000 train_loss:3.5928 train_time:464553ms step_avg:277.34ms
step:1686/3000 train_loss:3.5057 train_time:464820ms step_avg:277.34ms
step:1687/3000 train_loss:3.6034 train_time:465091ms step_avg:277.34ms
step:1688/3000 train_loss:3.4897 train_time:465359ms step_avg:277.33ms
step:1689/3000 train_loss:3.5765 train_time:465630ms step_avg:277.33ms
step:1690/3000 train_loss:3.4868 train_time:465898ms step_avg:277.32ms
step:1691/3000 train_loss:3.3833 train_time:466168ms step_avg:277.32ms
step:1692/3000 train_loss:3.5411 train_time:466437ms step_avg:277.31ms
step:1693/3000 train_loss:3.5333 train_time:466709ms step_avg:277.31ms
step:1694/3000 train_loss:3.4505 train_time:466977ms step_avg:277.30ms
step:1695/3000 train_loss:3.8933 train_time:467246ms step_avg:277.30ms
step:1696/3000 train_loss:3.6081 train_time:467517ms step_avg:277.29ms
step:1697/3000 train_loss:3.5894 train_time:467791ms step_avg:277.29ms
step:1698/3000 train_loss:3.4974 train_time:468057ms step_avg:277.29ms
step:1699/3000 train_loss:3.4064 train_time:468328ms step_avg:277.28ms
step:1700/3000 train_loss:3.4983 train_time:468597ms step_avg:277.28ms
step:1701/3000 train_loss:3.4891 train_time:469062ms step_avg:277.39ms
step:1702/3000 train_loss:3.5690 train_time:469331ms step_avg:277.38ms
step:1703/3000 train_loss:3.4905 train_time:469595ms step_avg:277.37ms
step:1704/3000 train_loss:3.6900 train_time:469865ms step_avg:277.37ms
step:1705/3000 train_loss:3.4621 train_time:470137ms step_avg:277.37ms
step:1706/3000 train_loss:3.6882 train_time:470406ms step_avg:277.36ms
step:1707/3000 train_loss:3.5302 train_time:470671ms step_avg:277.35ms
step:1708/3000 train_loss:3.3039 train_time:470939ms step_avg:277.35ms
step:1709/3000 train_loss:3.6368 train_time:471212ms step_avg:277.35ms
step:1710/3000 train_loss:3.5531 train_time:471688ms step_avg:277.46ms
step:1711/3000 train_loss:3.5416 train_time:471953ms step_avg:277.46ms
step:1712/3000 train_loss:3.6312 train_time:472217ms step_avg:277.45ms
step:1713/3000 train_loss:3.4364 train_time:472484ms step_avg:277.44ms
step:1714/3000 train_loss:3.5578 train_time:472759ms step_avg:277.44ms
step:1715/3000 train_loss:3.5355 train_time:473027ms step_avg:277.44ms
step:1716/3000 train_loss:3.6478 train_time:473294ms step_avg:277.43ms
step:1717/3000 train_loss:3.5023 train_time:473562ms step_avg:277.42ms
step:1718/3000 train_loss:3.5495 train_time:473837ms step_avg:277.42ms
step:1719/3000 train_loss:3.5142 train_time:474106ms step_avg:277.42ms
step:1720/3000 train_loss:3.6908 train_time:474372ms step_avg:277.41ms
step:1721/3000 train_loss:3.5928 train_time:474639ms step_avg:277.40ms
step:1722/3000 train_loss:3.5522 train_time:474913ms step_avg:277.40ms
step:1723/3000 train_loss:3.6504 train_time:475184ms step_avg:277.40ms
step:1724/3000 train_loss:3.4281 train_time:475453ms step_avg:277.39ms
step:1725/3000 train_loss:3.5140 train_time:475722ms step_avg:277.39ms
step:1726/3000 train_loss:3.5159 train_time:475995ms step_avg:277.39ms
step:1727/3000 train_loss:3.5744 train_time:476264ms step_avg:277.38ms
step:1728/3000 train_loss:3.6150 train_time:476533ms step_avg:277.38ms
step:1729/3000 train_loss:3.5107 train_time:476803ms step_avg:277.37ms
step:1730/3000 train_loss:3.6156 train_time:477073ms step_avg:277.37ms
step:1731/3000 train_loss:3.4323 train_time:477342ms step_avg:277.36ms
step:1732/3000 train_loss:3.5077 train_time:477612ms step_avg:277.36ms
step:1733/3000 train_loss:3.5543 train_time:477882ms step_avg:277.35ms
step:1734/3000 train_loss:3.5688 train_time:478153ms step_avg:277.35ms
step:1735/3000 train_loss:3.7797 train_time:478423ms step_avg:277.35ms
step:1736/3000 train_loss:3.5405 train_time:478694ms step_avg:277.34ms
step:1737/3000 train_loss:3.5970 train_time:478962ms step_avg:277.34ms
step:1738/3000 train_loss:3.6057 train_time:479233ms step_avg:277.33ms
step:1739/3000 train_loss:3.4958 train_time:479502ms step_avg:277.33ms
step:1740/3000 train_loss:3.5748 train_time:479772ms step_avg:277.33ms
step:1741/3000 train_loss:3.4713 train_time:480043ms step_avg:277.32ms
step:1742/3000 train_loss:3.4918 train_time:480307ms step_avg:277.31ms
step:1743/3000 train_loss:3.5027 train_time:480576ms step_avg:277.31ms
step:1744/3000 train_loss:3.4857 train_time:480850ms step_avg:277.31ms
step:1745/3000 train_loss:3.5953 train_time:481117ms step_avg:277.30ms
step:1746/3000 train_loss:3.5825 train_time:481387ms step_avg:277.30ms
step:1747/3000 train_loss:3.6226 train_time:481657ms step_avg:277.29ms
step:1748/3000 train_loss:3.6477 train_time:481928ms step_avg:277.29ms
step:1749/3000 train_loss:3.5255 train_time:482196ms step_avg:277.28ms
step:1750/3000 train_loss:3.4975 train_time:482464ms step_avg:277.28ms
step:1750/3000 val_loss:3.5304 train_time:482465ms step_avg:277.28ms
step:1751/3000 train_loss:3.5022 train_time:482737ms step_avg:277.28ms
step:1752/3000 train_loss:3.4717 train_time:483010ms step_avg:277.27ms
step:1753/3000 train_loss:3.5262 train_time:483280ms step_avg:277.27ms
step:1754/3000 train_loss:3.5931 train_time:483546ms step_avg:277.26ms
step:1755/3000 train_loss:3.5487 train_time:483817ms step_avg:277.26ms
step:1756/3000 train_loss:3.5553 train_time:484089ms step_avg:277.26ms
step:1757/3000 train_loss:3.5287 train_time:484359ms step_avg:277.25ms
step:1758/3000 train_loss:3.4313 train_time:484627ms step_avg:277.25ms
step:1759/3000 train_loss:3.4994 train_time:484897ms step_avg:277.24ms
step:1760/3000 train_loss:3.5205 train_time:485170ms step_avg:277.24ms
step:1761/3000 train_loss:3.6300 train_time:485438ms step_avg:277.23ms
step:1762/3000 train_loss:3.5452 train_time:485706ms step_avg:277.23ms
step:1763/3000 train_loss:3.5045 train_time:485977ms step_avg:277.23ms
step:1764/3000 train_loss:3.6969 train_time:486247ms step_avg:277.22ms
step:1765/3000 train_loss:3.4684 train_time:486519ms step_avg:277.22ms
step:1766/3000 train_loss:3.7974 train_time:486789ms step_avg:277.21ms
step:1767/3000 train_loss:3.4456 train_time:487058ms step_avg:277.21ms
step:1768/3000 train_loss:3.3927 train_time:487329ms step_avg:277.21ms
step:1769/3000 train_loss:3.4097 train_time:487599ms step_avg:277.20ms
step:1770/3000 train_loss:3.4894 train_time:487871ms step_avg:277.20ms
step:1771/3000 train_loss:3.5684 train_time:488139ms step_avg:277.19ms
step:1772/3000 train_loss:3.4391 train_time:488409ms step_avg:277.19ms
step:1773/3000 train_loss:3.5388 train_time:488680ms step_avg:277.19ms
step:1774/3000 train_loss:3.5874 train_time:488950ms step_avg:277.18ms
step:1775/3000 train_loss:3.3956 train_time:489218ms step_avg:277.18ms
step:1776/3000 train_loss:3.4480 train_time:489490ms step_avg:277.17ms
step:1777/3000 train_loss:3.4801 train_time:489760ms step_avg:277.17ms
step:1778/3000 train_loss:3.5044 train_time:490031ms step_avg:277.17ms
step:1779/3000 train_loss:3.6368 train_time:490297ms step_avg:277.16ms
step:1780/3000 train_loss:3.4114 train_time:490569ms step_avg:277.16ms
step:1781/3000 train_loss:3.5053 train_time:490839ms step_avg:277.15ms
step:1782/3000 train_loss:3.5523 train_time:491109ms step_avg:277.15ms
step:1783/3000 train_loss:3.4749 train_time:491378ms step_avg:277.15ms
step:1784/3000 train_loss:3.3959 train_time:491649ms step_avg:277.14ms
step:1785/3000 train_loss:3.5796 train_time:491920ms step_avg:277.14ms
step:1786/3000 train_loss:3.3980 train_time:492189ms step_avg:277.13ms
step:1787/3000 train_loss:3.4724 train_time:492457ms step_avg:277.13ms
step:1788/3000 train_loss:3.5901 train_time:492728ms step_avg:277.12ms
step:1789/3000 train_loss:3.9622 train_time:493000ms step_avg:277.12ms
step:1790/3000 train_loss:3.4252 train_time:493271ms step_avg:277.12ms
step:1791/3000 train_loss:3.4954 train_time:493538ms step_avg:277.11ms
step:1792/3000 train_loss:3.4410 train_time:493807ms step_avg:277.11ms
step:1793/3000 train_loss:3.5491 train_time:494079ms step_avg:277.11ms
step:1794/3000 train_loss:3.5056 train_time:494348ms step_avg:277.10ms
step:1795/3000 train_loss:3.5294 train_time:494616ms step_avg:277.10ms
step:1796/3000 train_loss:3.4595 train_time:494887ms step_avg:277.09ms
step:1797/3000 train_loss:3.6459 train_time:495158ms step_avg:277.09ms
step:1798/3000 train_loss:3.5509 train_time:495427ms step_avg:277.08ms
step:1799/3000 train_loss:3.4256 train_time:495696ms step_avg:277.08ms
step:1800/3000 train_loss:3.4765 train_time:495967ms step_avg:277.08ms
step:1801/3000 train_loss:3.4450 train_time:496237ms step_avg:277.07ms
step:1802/3000 train_loss:3.4961 train_time:496505ms step_avg:277.07ms
step:1803/3000 train_loss:3.5902 train_time:496776ms step_avg:277.06ms
step:1804/3000 train_loss:3.4656 train_time:497046ms step_avg:277.06ms
step:1805/3000 train_loss:3.5629 train_time:497317ms step_avg:277.06ms
step:1806/3000 train_loss:3.6094 train_time:497587ms step_avg:277.05ms
step:1807/3000 train_loss:3.5316 train_time:497856ms step_avg:277.05ms
step:1808/3000 train_loss:3.4894 train_time:498128ms step_avg:277.05ms
step:1809/3000 train_loss:3.5468 train_time:498397ms step_avg:277.04ms
step:1810/3000 train_loss:3.5365 train_time:498668ms step_avg:277.04ms
step:1811/3000 train_loss:3.6607 train_time:498937ms step_avg:277.03ms
step:1812/3000 train_loss:3.4757 train_time:499205ms step_avg:277.03ms
step:1813/3000 train_loss:3.6488 train_time:499476ms step_avg:277.02ms
step:1814/3000 train_loss:3.4345 train_time:499747ms step_avg:277.02ms
step:1815/3000 train_loss:3.5970 train_time:500017ms step_avg:277.02ms
step:1816/3000 train_loss:3.4751 train_time:500287ms step_avg:277.01ms
step:1817/3000 train_loss:3.3788 train_time:500556ms step_avg:277.01ms
step:1818/3000 train_loss:3.4481 train_time:500828ms step_avg:277.01ms
step:1819/3000 train_loss:3.4139 train_time:501100ms step_avg:277.00ms
step:1820/3000 train_loss:3.4389 train_time:501369ms step_avg:277.00ms
step:1821/3000 train_loss:3.4835 train_time:501638ms step_avg:277.00ms
step:1822/3000 train_loss:3.4058 train_time:501908ms step_avg:276.99ms
step:1823/3000 train_loss:3.6070 train_time:502180ms step_avg:276.99ms
step:1824/3000 train_loss:3.4913 train_time:502449ms step_avg:276.98ms
step:1825/3000 train_loss:3.4498 train_time:502719ms step_avg:276.98ms
step:1826/3000 train_loss:3.5016 train_time:502989ms step_avg:276.98ms
step:1827/3000 train_loss:3.5811 train_time:503259ms step_avg:276.97ms
step:1828/3000 train_loss:3.4413 train_time:503528ms step_avg:276.97ms
step:1829/3000 train_loss:3.6862 train_time:503798ms step_avg:276.96ms
step:1830/3000 train_loss:3.5425 train_time:504067ms step_avg:276.96ms
step:1831/3000 train_loss:3.3322 train_time:504337ms step_avg:276.96ms
step:1832/3000 train_loss:3.4092 train_time:504607ms step_avg:276.95ms
step:1833/3000 train_loss:3.5621 train_time:504879ms step_avg:276.95ms
step:1834/3000 train_loss:3.4015 train_time:505148ms step_avg:276.95ms
step:1835/3000 train_loss:3.6758 train_time:505419ms step_avg:276.94ms
step:1836/3000 train_loss:3.5872 train_time:505689ms step_avg:276.94ms
step:1837/3000 train_loss:3.5575 train_time:505958ms step_avg:276.93ms
step:1838/3000 train_loss:3.5071 train_time:506227ms step_avg:276.93ms
step:1839/3000 train_loss:3.5263 train_time:506500ms step_avg:276.93ms
step:1840/3000 train_loss:3.8094 train_time:506772ms step_avg:276.92ms
step:1841/3000 train_loss:3.4744 train_time:507038ms step_avg:276.92ms
step:1842/3000 train_loss:3.5230 train_time:507307ms step_avg:276.91ms
step:1843/3000 train_loss:3.4939 train_time:507580ms step_avg:276.91ms
step:1844/3000 train_loss:3.5962 train_time:507846ms step_avg:276.91ms
step:1845/3000 train_loss:3.4268 train_time:508117ms step_avg:276.90ms
step:1846/3000 train_loss:3.6241 train_time:508385ms step_avg:276.90ms
step:1847/3000 train_loss:3.3668 train_time:508657ms step_avg:276.90ms
step:1848/3000 train_loss:3.5628 train_time:508924ms step_avg:276.89ms
step:1849/3000 train_loss:3.4673 train_time:509193ms step_avg:276.89ms
step:1850/3000 train_loss:3.5710 train_time:509459ms step_avg:276.88ms
step:1851/3000 train_loss:3.6848 train_time:509734ms step_avg:276.88ms
step:1852/3000 train_loss:3.5166 train_time:510001ms step_avg:276.87ms
step:1853/3000 train_loss:3.4429 train_time:510275ms step_avg:276.87ms
step:1854/3000 train_loss:3.5314 train_time:510539ms step_avg:276.86ms
step:1855/3000 train_loss:3.5603 train_time:510811ms step_avg:276.86ms
step:1856/3000 train_loss:3.5267 train_time:511082ms step_avg:276.86ms
step:1857/3000 train_loss:3.3674 train_time:511350ms step_avg:276.85ms
step:1858/3000 train_loss:3.5286 train_time:511618ms step_avg:276.85ms
step:1859/3000 train_loss:3.6009 train_time:511890ms step_avg:276.85ms
step:1860/3000 train_loss:3.4759 train_time:512160ms step_avg:276.84ms
step:1861/3000 train_loss:3.6462 train_time:512429ms step_avg:276.84ms
step:1862/3000 train_loss:3.4799 train_time:512697ms step_avg:276.83ms
step:1863/3000 train_loss:3.5163 train_time:512968ms step_avg:276.83ms
step:1864/3000 train_loss:3.5898 train_time:513240ms step_avg:276.83ms
step:1865/3000 train_loss:3.6431 train_time:513511ms step_avg:276.83ms
step:1866/3000 train_loss:3.4739 train_time:513777ms step_avg:276.82ms
step:1867/3000 train_loss:3.6258 train_time:514049ms step_avg:276.82ms
step:1868/3000 train_loss:3.6466 train_time:514319ms step_avg:276.81ms
step:1869/3000 train_loss:3.4935 train_time:514589ms step_avg:276.81ms
step:1870/3000 train_loss:3.5713 train_time:514857ms step_avg:276.80ms
step:1871/3000 train_loss:3.3672 train_time:515129ms step_avg:276.80ms
step:1872/3000 train_loss:3.6512 train_time:515397ms step_avg:276.80ms
step:1873/3000 train_loss:3.6113 train_time:515666ms step_avg:276.79ms
step:1874/3000 train_loss:3.6099 train_time:515936ms step_avg:276.79ms
step:1875/3000 train_loss:3.4631 train_time:516204ms step_avg:276.78ms
step:1875/3000 val_loss:3.5044 train_time:516205ms step_avg:276.79ms
step:1876/3000 train_loss:3.5714 train_time:516474ms step_avg:276.78ms
step:1877/3000 train_loss:3.5604 train_time:516748ms step_avg:276.78ms
step:1878/3000 train_loss:3.4669 train_time:517019ms step_avg:276.78ms
step:1879/3000 train_loss:3.5312 train_time:517288ms step_avg:276.77ms
step:1880/3000 train_loss:3.4554 train_time:517555ms step_avg:276.77ms
step:1881/3000 train_loss:3.2963 train_time:517828ms step_avg:276.77ms
step:1882/3000 train_loss:3.5001 train_time:518098ms step_avg:276.76ms
step:1883/3000 train_loss:3.5276 train_time:518369ms step_avg:276.76ms
step:1884/3000 train_loss:3.5559 train_time:518634ms step_avg:276.75ms
step:1885/3000 train_loss:3.7120 train_time:518907ms step_avg:276.75ms
step:1886/3000 train_loss:3.5228 train_time:519178ms step_avg:276.75ms
step:1887/3000 train_loss:3.4215 train_time:519449ms step_avg:276.74ms
step:1888/3000 train_loss:3.3870 train_time:519713ms step_avg:276.74ms
step:1889/3000 train_loss:3.5595 train_time:519984ms step_avg:276.73ms
step:1890/3000 train_loss:3.4374 train_time:520448ms step_avg:276.83ms
step:1891/3000 train_loss:3.4587 train_time:520712ms step_avg:276.83ms
step:1892/3000 train_loss:3.6311 train_time:520978ms step_avg:276.82ms
step:1893/3000 train_loss:3.4619 train_time:521251ms step_avg:276.82ms
step:1894/3000 train_loss:3.4072 train_time:521523ms step_avg:276.82ms
step:1895/3000 train_loss:3.4609 train_time:521791ms step_avg:276.81ms
step:1896/3000 train_loss:3.5532 train_time:522061ms step_avg:276.81ms
step:1897/3000 train_loss:3.5527 train_time:522333ms step_avg:276.81ms
step:1898/3000 train_loss:3.5478 train_time:522604ms step_avg:276.80ms
step:1899/3000 train_loss:3.5090 train_time:522875ms step_avg:276.80ms
step:1900/3000 train_loss:3.4653 train_time:523350ms step_avg:276.90ms
step:1901/3000 train_loss:3.5224 train_time:523615ms step_avg:276.90ms
step:1902/3000 train_loss:3.4645 train_time:523882ms step_avg:276.89ms
step:1903/3000 train_loss:3.4071 train_time:524148ms step_avg:276.89ms
step:1904/3000 train_loss:3.6251 train_time:524426ms step_avg:276.89ms
step:1905/3000 train_loss:3.5323 train_time:524695ms step_avg:276.88ms
step:1906/3000 train_loss:3.6950 train_time:524965ms step_avg:276.88ms
step:1907/3000 train_loss:3.5290 train_time:525231ms step_avg:276.87ms
step:1908/3000 train_loss:3.4175 train_time:525503ms step_avg:276.87ms
step:1909/3000 train_loss:3.5619 train_time:525775ms step_avg:276.87ms
step:1910/3000 train_loss:3.4345 train_time:526043ms step_avg:276.86ms
step:1911/3000 train_loss:3.4727 train_time:526312ms step_avg:276.86ms
step:1912/3000 train_loss:3.3666 train_time:526584ms step_avg:276.86ms
step:1913/3000 train_loss:3.6221 train_time:526853ms step_avg:276.85ms
step:1914/3000 train_loss:3.4442 train_time:527121ms step_avg:276.85ms
step:1915/3000 train_loss:3.6048 train_time:527391ms step_avg:276.85ms
step:1916/3000 train_loss:3.6236 train_time:527661ms step_avg:276.84ms
step:1917/3000 train_loss:3.3521 train_time:527932ms step_avg:276.84ms
step:1918/3000 train_loss:3.4637 train_time:528201ms step_avg:276.83ms
step:1919/3000 train_loss:3.5313 train_time:528473ms step_avg:276.83ms
step:1920/3000 train_loss:3.6292 train_time:528740ms step_avg:276.83ms
step:1921/3000 train_loss:3.5772 train_time:529011ms step_avg:276.82ms
step:1922/3000 train_loss:3.4705 train_time:529282ms step_avg:276.82ms
step:1923/3000 train_loss:3.4603 train_time:529553ms step_avg:276.82ms
step:1924/3000 train_loss:3.4659 train_time:529824ms step_avg:276.81ms
step:1925/3000 train_loss:3.5072 train_time:530094ms step_avg:276.81ms
step:1926/3000 train_loss:3.3455 train_time:530367ms step_avg:276.81ms
step:1927/3000 train_loss:3.3536 train_time:530634ms step_avg:276.80ms
step:1928/3000 train_loss:3.3906 train_time:530906ms step_avg:276.80ms
step:1929/3000 train_loss:3.5262 train_time:531175ms step_avg:276.80ms
step:1930/3000 train_loss:3.4834 train_time:531445ms step_avg:276.79ms
step:1931/3000 train_loss:3.5157 train_time:531712ms step_avg:276.79ms
step:1932/3000 train_loss:3.5157 train_time:531984ms step_avg:276.79ms
step:1933/3000 train_loss:3.4089 train_time:532253ms step_avg:276.78ms
step:1934/3000 train_loss:3.3662 train_time:532523ms step_avg:276.78ms
step:1935/3000 train_loss:3.7596 train_time:532792ms step_avg:276.78ms
step:1936/3000 train_loss:3.3664 train_time:533066ms step_avg:276.77ms
step:1937/3000 train_loss:3.4285 train_time:533335ms step_avg:276.77ms
step:1938/3000 train_loss:3.3688 train_time:533604ms step_avg:276.77ms
step:1939/3000 train_loss:3.5717 train_time:533874ms step_avg:276.76ms
step:1940/3000 train_loss:3.3708 train_time:534143ms step_avg:276.76ms
step:1941/3000 train_loss:3.4598 train_time:534414ms step_avg:276.75ms
step:1942/3000 train_loss:3.3658 train_time:534686ms step_avg:276.75ms
step:1943/3000 train_loss:3.4579 train_time:534953ms step_avg:276.75ms
step:1944/3000 train_loss:3.5090 train_time:535222ms step_avg:276.74ms
step:1945/3000 train_loss:3.4939 train_time:535492ms step_avg:276.74ms
step:1946/3000 train_loss:3.4221 train_time:535764ms step_avg:276.74ms
step:1947/3000 train_loss:3.5032 train_time:536033ms step_avg:276.73ms
step:1948/3000 train_loss:3.5323 train_time:536304ms step_avg:276.73ms
step:1949/3000 train_loss:3.4155 train_time:536575ms step_avg:276.73ms
step:1950/3000 train_loss:3.5226 train_time:536845ms step_avg:276.72ms
step:1951/3000 train_loss:3.5878 train_time:537114ms step_avg:276.72ms
step:1952/3000 train_loss:3.4078 train_time:537383ms step_avg:276.72ms
step:1953/3000 train_loss:3.6164 train_time:537653ms step_avg:276.71ms
step:1954/3000 train_loss:3.4868 train_time:537923ms step_avg:276.71ms
step:1955/3000 train_loss:3.5787 train_time:538192ms step_avg:276.71ms
step:1956/3000 train_loss:3.6312 train_time:538463ms step_avg:276.70ms
step:1957/3000 train_loss:3.5156 train_time:538731ms step_avg:276.70ms
step:1958/3000 train_loss:3.4865 train_time:539004ms step_avg:276.70ms
step:1959/3000 train_loss:3.5303 train_time:539274ms step_avg:276.69ms
step:1960/3000 train_loss:3.4183 train_time:539544ms step_avg:276.69ms
step:1961/3000 train_loss:3.4761 train_time:539813ms step_avg:276.69ms
step:1962/3000 train_loss:3.5499 train_time:540083ms step_avg:276.68ms
step:1963/3000 train_loss:3.6645 train_time:540352ms step_avg:276.68ms
step:1964/3000 train_loss:3.3971 train_time:540623ms step_avg:276.68ms
step:1965/3000 train_loss:3.3797 train_time:540892ms step_avg:276.67ms
step:1966/3000 train_loss:3.5726 train_time:541165ms step_avg:276.67ms
step:1967/3000 train_loss:3.4481 train_time:541434ms step_avg:276.67ms
step:1968/3000 train_loss:3.4669 train_time:541705ms step_avg:276.66ms
step:1969/3000 train_loss:3.4757 train_time:541974ms step_avg:276.66ms
step:1970/3000 train_loss:3.5441 train_time:542244ms step_avg:276.65ms
step:1971/3000 train_loss:3.5648 train_time:542513ms step_avg:276.65ms
step:1972/3000 train_loss:3.5378 train_time:542781ms step_avg:276.65ms
step:1973/3000 train_loss:3.4856 train_time:543050ms step_avg:276.64ms
step:1974/3000 train_loss:3.4006 train_time:543322ms step_avg:276.64ms
step:1975/3000 train_loss:3.4881 train_time:543591ms step_avg:276.64ms
step:1976/3000 train_loss:3.4133 train_time:543861ms step_avg:276.63ms
step:1977/3000 train_loss:3.4190 train_time:544130ms step_avg:276.63ms
step:1978/3000 train_loss:3.4166 train_time:544399ms step_avg:276.63ms
step:1979/3000 train_loss:3.4867 train_time:544670ms step_avg:276.62ms
step:1980/3000 train_loss:3.3432 train_time:544939ms step_avg:276.62ms
step:1981/3000 train_loss:3.6168 train_time:545211ms step_avg:276.62ms
step:1982/3000 train_loss:3.4599 train_time:545479ms step_avg:276.61ms
step:1983/3000 train_loss:3.4663 train_time:545749ms step_avg:276.61ms
step:1984/3000 train_loss:3.4702 train_time:546016ms step_avg:276.60ms
step:1985/3000 train_loss:3.5658 train_time:546288ms step_avg:276.60ms
step:1986/3000 train_loss:3.5932 train_time:546557ms step_avg:276.60ms
step:1987/3000 train_loss:3.7570 train_time:546827ms step_avg:276.59ms
step:1988/3000 train_loss:3.5827 train_time:547098ms step_avg:276.59ms
step:1989/3000 train_loss:3.5541 train_time:547369ms step_avg:276.59ms
step:1990/3000 train_loss:3.5360 train_time:547637ms step_avg:276.58ms
step:1991/3000 train_loss:3.7337 train_time:547907ms step_avg:276.58ms
step:1992/3000 train_loss:3.5054 train_time:548173ms step_avg:276.58ms
step:1993/3000 train_loss:3.4580 train_time:548444ms step_avg:276.57ms
step:1994/3000 train_loss:3.4368 train_time:548717ms step_avg:276.57ms
step:1995/3000 train_loss:3.5661 train_time:548987ms step_avg:276.57ms
step:1996/3000 train_loss:3.5841 train_time:549252ms step_avg:276.56ms
step:1997/3000 train_loss:3.6346 train_time:549522ms step_avg:276.56ms
step:1998/3000 train_loss:3.4526 train_time:549794ms step_avg:276.56ms
step:1999/3000 train_loss:3.5755 train_time:550068ms step_avg:276.56ms
step:2000/3000 train_loss:3.3907 train_time:550333ms step_avg:276.55ms
step:2000/3000 val_loss:3.4828 train_time:550334ms step_avg:276.55ms
step:2001/3000 train_loss:3.4065 train_time:550605ms step_avg:276.55ms
step:2002/3000 train_loss:3.4272 train_time:550878ms step_avg:276.55ms
step:2003/3000 train_loss:3.4009 train_time:551150ms step_avg:276.54ms
step:2004/3000 train_loss:3.4432 train_time:551419ms step_avg:276.54ms
step:2005/3000 train_loss:3.4814 train_time:551684ms step_avg:276.53ms
step:2006/3000 train_loss:3.3978 train_time:551954ms step_avg:276.53ms
step:2007/3000 train_loss:3.4200 train_time:552228ms step_avg:276.53ms
step:2008/3000 train_loss:3.4276 train_time:552498ms step_avg:276.53ms
step:2009/3000 train_loss:3.5336 train_time:552763ms step_avg:276.52ms
step:2010/3000 train_loss:3.3883 train_time:553033ms step_avg:276.52ms
step:2011/3000 train_loss:3.4846 train_time:553305ms step_avg:276.51ms
step:2012/3000 train_loss:3.4935 train_time:553578ms step_avg:276.51ms
step:2013/3000 train_loss:3.5080 train_time:553843ms step_avg:276.51ms
step:2014/3000 train_loss:3.5354 train_time:554112ms step_avg:276.50ms
step:2015/3000 train_loss:3.5353 train_time:554383ms step_avg:276.50ms
step:2016/3000 train_loss:4.0159 train_time:554653ms step_avg:276.50ms
step:2017/3000 train_loss:3.5007 train_time:554923ms step_avg:276.49ms
step:2018/3000 train_loss:3.4061 train_time:555191ms step_avg:276.49ms
step:2019/3000 train_loss:3.4989 train_time:555461ms step_avg:276.49ms
step:2020/3000 train_loss:3.4537 train_time:555730ms step_avg:276.48ms
step:2021/3000 train_loss:3.6513 train_time:556001ms step_avg:276.48ms
step:2022/3000 train_loss:3.4642 train_time:556272ms step_avg:276.48ms
step:2023/3000 train_loss:3.4270 train_time:556541ms step_avg:276.47ms
step:2024/3000 train_loss:3.4418 train_time:556810ms step_avg:276.47ms
step:2025/3000 train_loss:3.6368 train_time:557081ms step_avg:276.47ms
step:2026/3000 train_loss:3.5157 train_time:557349ms step_avg:276.46ms
step:2027/3000 train_loss:3.3679 train_time:557621ms step_avg:276.46ms
step:2028/3000 train_loss:3.4615 train_time:557890ms step_avg:276.46ms
step:2029/3000 train_loss:3.5124 train_time:558160ms step_avg:276.45ms
step:2030/3000 train_loss:3.4689 train_time:558428ms step_avg:276.45ms
step:2031/3000 train_loss:3.6174 train_time:558700ms step_avg:276.45ms
step:2032/3000 train_loss:3.5354 train_time:558968ms step_avg:276.44ms
step:2033/3000 train_loss:3.5300 train_time:559239ms step_avg:276.44ms
step:2034/3000 train_loss:3.5956 train_time:559506ms step_avg:276.44ms
step:2035/3000 train_loss:3.4938 train_time:559779ms step_avg:276.43ms
step:2036/3000 train_loss:3.5875 train_time:560046ms step_avg:276.43ms
step:2037/3000 train_loss:3.4831 train_time:560317ms step_avg:276.43ms
step:2038/3000 train_loss:3.9607 train_time:560584ms step_avg:276.42ms
step:2039/3000 train_loss:3.6550 train_time:560854ms step_avg:276.42ms
step:2040/3000 train_loss:3.3859 train_time:561125ms step_avg:276.42ms
step:2041/3000 train_loss:3.3467 train_time:561396ms step_avg:276.41ms
step:2042/3000 train_loss:3.5467 train_time:561661ms step_avg:276.41ms
step:2043/3000 train_loss:3.5154 train_time:561931ms step_avg:276.40ms
step:2044/3000 train_loss:3.4634 train_time:562202ms step_avg:276.40ms
step:2045/3000 train_loss:3.4335 train_time:562473ms step_avg:276.40ms
step:2046/3000 train_loss:3.6158 train_time:562743ms step_avg:276.40ms
step:2047/3000 train_loss:3.5556 train_time:563012ms step_avg:276.39ms
step:2048/3000 train_loss:4.0197 train_time:563282ms step_avg:276.39ms
step:2049/3000 train_loss:3.5123 train_time:563551ms step_avg:276.39ms
step:2050/3000 train_loss:3.4644 train_time:563822ms step_avg:276.38ms
step:2051/3000 train_loss:3.5600 train_time:564092ms step_avg:276.38ms
step:2052/3000 train_loss:3.4517 train_time:564361ms step_avg:276.38ms
step:2053/3000 train_loss:3.4238 train_time:564632ms step_avg:276.37ms
step:2054/3000 train_loss:3.4301 train_time:564902ms step_avg:276.37ms
step:2055/3000 train_loss:3.5975 train_time:565172ms step_avg:276.37ms
step:2056/3000 train_loss:3.4296 train_time:565441ms step_avg:276.36ms
step:2057/3000 train_loss:3.3756 train_time:565710ms step_avg:276.36ms
step:2058/3000 train_loss:3.3836 train_time:565982ms step_avg:276.36ms
step:2059/3000 train_loss:3.4700 train_time:566252ms step_avg:276.36ms
step:2060/3000 train_loss:3.4449 train_time:566523ms step_avg:276.35ms
step:2061/3000 train_loss:3.2334 train_time:566794ms step_avg:276.35ms
step:2062/3000 train_loss:3.4528 train_time:567062ms step_avg:276.35ms
step:2063/3000 train_loss:3.7480 train_time:567332ms step_avg:276.34ms
step:2064/3000 train_loss:3.2827 train_time:567602ms step_avg:276.34ms
step:2065/3000 train_loss:3.5448 train_time:567873ms step_avg:276.34ms
step:2066/3000 train_loss:3.4007 train_time:568143ms step_avg:276.33ms
step:2067/3000 train_loss:3.5047 train_time:568410ms step_avg:276.33ms
step:2068/3000 train_loss:3.3490 train_time:568682ms step_avg:276.33ms
step:2069/3000 train_loss:3.4906 train_time:568953ms step_avg:276.32ms
step:2070/3000 train_loss:3.4844 train_time:569223ms step_avg:276.32ms
step:2071/3000 train_loss:3.0546 train_time:569492ms step_avg:276.32ms
step:2072/3000 train_loss:3.6143 train_time:569761ms step_avg:276.31ms
step:2073/3000 train_loss:3.5282 train_time:570030ms step_avg:276.31ms
step:2074/3000 train_loss:3.4770 train_time:570301ms step_avg:276.31ms
step:2075/3000 train_loss:3.3505 train_time:570570ms step_avg:276.31ms
step:2076/3000 train_loss:3.5539 train_time:570839ms step_avg:276.30ms
step:2077/3000 train_loss:3.4694 train_time:571109ms step_avg:276.30ms
step:2078/3000 train_loss:3.5024 train_time:571379ms step_avg:276.30ms
step:2079/3000 train_loss:3.4969 train_time:571839ms step_avg:276.38ms
step:2080/3000 train_loss:3.3981 train_time:572104ms step_avg:276.38ms
step:2081/3000 train_loss:3.4397 train_time:572369ms step_avg:276.37ms
step:2082/3000 train_loss:3.3157 train_time:572643ms step_avg:276.37ms
step:2083/3000 train_loss:3.3599 train_time:572913ms step_avg:276.37ms
step:2084/3000 train_loss:3.5572 train_time:573183ms step_avg:276.37ms
step:2085/3000 train_loss:3.4574 train_time:573449ms step_avg:276.36ms
step:2086/3000 train_loss:3.4509 train_time:573719ms step_avg:276.36ms
step:2087/3000 train_loss:3.4985 train_time:573986ms step_avg:276.35ms
step:2088/3000 train_loss:3.4563 train_time:574255ms step_avg:276.35ms
step:2089/3000 train_loss:3.4590 train_time:574525ms step_avg:276.35ms
step:2090/3000 train_loss:3.4744 train_time:575000ms step_avg:276.44ms
step:2091/3000 train_loss:3.5764 train_time:575263ms step_avg:276.44ms
step:2092/3000 train_loss:3.4727 train_time:575527ms step_avg:276.43ms
step:2093/3000 train_loss:3.4071 train_time:575792ms step_avg:276.42ms
step:2094/3000 train_loss:3.4701 train_time:576066ms step_avg:276.42ms
step:2095/3000 train_loss:3.5032 train_time:576338ms step_avg:276.42ms
step:2096/3000 train_loss:3.4453 train_time:576604ms step_avg:276.42ms
step:2097/3000 train_loss:3.5134 train_time:576873ms step_avg:276.41ms
step:2098/3000 train_loss:3.6677 train_time:577144ms step_avg:276.41ms
step:2099/3000 train_loss:3.4270 train_time:577413ms step_avg:276.41ms
step:2100/3000 train_loss:3.4279 train_time:577682ms step_avg:276.40ms
step:2101/3000 train_loss:3.5542 train_time:577952ms step_avg:276.40ms
step:2102/3000 train_loss:3.4686 train_time:578223ms step_avg:276.40ms
step:2103/3000 train_loss:3.5696 train_time:578493ms step_avg:276.39ms
step:2104/3000 train_loss:3.4308 train_time:578763ms step_avg:276.39ms
step:2105/3000 train_loss:3.5363 train_time:579032ms step_avg:276.39ms
step:2106/3000 train_loss:3.3002 train_time:579302ms step_avg:276.38ms
step:2107/3000 train_loss:3.5095 train_time:579573ms step_avg:276.38ms
step:2108/3000 train_loss:3.4823 train_time:579842ms step_avg:276.38ms
step:2109/3000 train_loss:3.5388 train_time:580111ms step_avg:276.37ms
step:2110/3000 train_loss:3.4375 train_time:580383ms step_avg:276.37ms
step:2111/3000 train_loss:3.4650 train_time:580652ms step_avg:276.37ms
step:2112/3000 train_loss:3.5882 train_time:580922ms step_avg:276.37ms
step:2113/3000 train_loss:3.4940 train_time:581191ms step_avg:276.36ms
step:2114/3000 train_loss:3.6149 train_time:581459ms step_avg:276.36ms
step:2115/3000 train_loss:3.3268 train_time:581727ms step_avg:276.35ms
step:2116/3000 train_loss:3.4537 train_time:581999ms step_avg:276.35ms
step:2117/3000 train_loss:3.7746 train_time:582265ms step_avg:276.35ms
step:2118/3000 train_loss:3.4611 train_time:582536ms step_avg:276.35ms
step:2119/3000 train_loss:3.4868 train_time:582805ms step_avg:276.34ms
step:2120/3000 train_loss:3.5032 train_time:583076ms step_avg:276.34ms
step:2121/3000 train_loss:3.4330 train_time:583345ms step_avg:276.34ms
step:2122/3000 train_loss:3.4405 train_time:583614ms step_avg:276.33ms
step:2123/3000 train_loss:3.8509 train_time:583884ms step_avg:276.33ms
step:2124/3000 train_loss:3.3043 train_time:584154ms step_avg:276.33ms
step:2125/3000 train_loss:3.6771 train_time:584425ms step_avg:276.32ms
step:2125/3000 val_loss:3.4619 train_time:584426ms step_avg:276.32ms
step:2126/3000 train_loss:3.4287 train_time:584692ms step_avg:276.32ms
step:2127/3000 train_loss:3.4410 train_time:584969ms step_avg:276.32ms
step:2128/3000 train_loss:3.6234 train_time:585241ms step_avg:276.32ms
step:2129/3000 train_loss:3.3724 train_time:585510ms step_avg:276.31ms
step:2130/3000 train_loss:3.4862 train_time:585775ms step_avg:276.31ms
step:2131/3000 train_loss:3.3629 train_time:586046ms step_avg:276.31ms
step:2132/3000 train_loss:3.3315 train_time:586317ms step_avg:276.30ms
step:2133/3000 train_loss:3.4821 train_time:586586ms step_avg:276.30ms
step:2134/3000 train_loss:3.5616 train_time:586852ms step_avg:276.30ms
step:2135/3000 train_loss:3.2902 train_time:587122ms step_avg:276.29ms
step:2136/3000 train_loss:3.4375 train_time:587393ms step_avg:276.29ms
step:2137/3000 train_loss:3.3294 train_time:587664ms step_avg:276.29ms
step:2138/3000 train_loss:3.5688 train_time:587934ms step_avg:276.28ms
step:2139/3000 train_loss:3.4777 train_time:588204ms step_avg:276.28ms
step:2140/3000 train_loss:3.4437 train_time:588475ms step_avg:276.28ms
step:2141/3000 train_loss:3.3894 train_time:588743ms step_avg:276.28ms
step:2142/3000 train_loss:3.2948 train_time:589013ms step_avg:276.27ms
step:2143/3000 train_loss:3.4510 train_time:589284ms step_avg:276.27ms
step:2144/3000 train_loss:3.4833 train_time:589555ms step_avg:276.27ms
step:2145/3000 train_loss:3.4639 train_time:589822ms step_avg:276.26ms
step:2146/3000 train_loss:3.4907 train_time:590092ms step_avg:276.26ms
step:2147/3000 train_loss:3.5334 train_time:590364ms step_avg:276.26ms
step:2148/3000 train_loss:3.3995 train_time:590635ms step_avg:276.26ms
step:2149/3000 train_loss:3.3886 train_time:590904ms step_avg:276.25ms
step:2150/3000 train_loss:3.4154 train_time:591174ms step_avg:276.25ms
step:2151/3000 train_loss:3.5956 train_time:591443ms step_avg:276.25ms
step:2152/3000 train_loss:3.4506 train_time:591714ms step_avg:276.24ms
step:2153/3000 train_loss:3.4304 train_time:591984ms step_avg:276.24ms
step:2154/3000 train_loss:3.3341 train_time:592253ms step_avg:276.24ms
step:2155/3000 train_loss:3.6306 train_time:592523ms step_avg:276.23ms
step:2156/3000 train_loss:3.5409 train_time:592793ms step_avg:276.23ms
step:2157/3000 train_loss:3.5181 train_time:593063ms step_avg:276.23ms
step:2158/3000 train_loss:3.4499 train_time:593333ms step_avg:276.23ms
step:2159/3000 train_loss:3.5703 train_time:593602ms step_avg:276.22ms
step:2160/3000 train_loss:3.4180 train_time:593873ms step_avg:276.22ms
step:2161/3000 train_loss:3.4110 train_time:594142ms step_avg:276.22ms
step:2162/3000 train_loss:3.2998 train_time:594412ms step_avg:276.21ms
step:2163/3000 train_loss:3.4063 train_time:594681ms step_avg:276.21ms
step:2164/3000 train_loss:3.3623 train_time:594951ms step_avg:276.21ms
step:2165/3000 train_loss:3.3342 train_time:595221ms step_avg:276.20ms
step:2166/3000 train_loss:3.5337 train_time:595490ms step_avg:276.20ms
step:2167/3000 train_loss:3.4502 train_time:595756ms step_avg:276.20ms
step:2168/3000 train_loss:3.4892 train_time:596026ms step_avg:276.19ms
step:2169/3000 train_loss:3.5098 train_time:596297ms step_avg:276.19ms
step:2170/3000 train_loss:3.3549 train_time:596570ms step_avg:276.19ms
step:2171/3000 train_loss:3.4974 train_time:596835ms step_avg:276.18ms
step:2172/3000 train_loss:3.4094 train_time:597105ms step_avg:276.18ms
step:2173/3000 train_loss:3.4632 train_time:597376ms step_avg:276.18ms
step:2174/3000 train_loss:3.4696 train_time:597649ms step_avg:276.18ms
step:2175/3000 train_loss:3.4265 train_time:597916ms step_avg:276.17ms
step:2176/3000 train_loss:3.4187 train_time:598185ms step_avg:276.17ms
step:2177/3000 train_loss:3.5084 train_time:598456ms step_avg:276.17ms
step:2178/3000 train_loss:3.5457 train_time:598728ms step_avg:276.17ms
step:2179/3000 train_loss:3.5047 train_time:598996ms step_avg:276.16ms
step:2180/3000 train_loss:3.3973 train_time:599266ms step_avg:276.16ms
step:2181/3000 train_loss:3.4754 train_time:599535ms step_avg:276.16ms
step:2182/3000 train_loss:3.5167 train_time:599806ms step_avg:276.15ms
step:2183/3000 train_loss:3.4933 train_time:600077ms step_avg:276.15ms
step:2184/3000 train_loss:3.4331 train_time:600346ms step_avg:276.15ms
step:2185/3000 train_loss:3.2973 train_time:600616ms step_avg:276.15ms
step:2186/3000 train_loss:3.7287 train_time:600887ms step_avg:276.14ms
step:2187/3000 train_loss:3.4619 train_time:601157ms step_avg:276.14ms
step:2188/3000 train_loss:3.3190 train_time:601426ms step_avg:276.14ms
step:2189/3000 train_loss:3.5525 train_time:601695ms step_avg:276.13ms
step:2190/3000 train_loss:3.4860 train_time:601967ms step_avg:276.13ms
step:2191/3000 train_loss:3.6539 train_time:602236ms step_avg:276.13ms
step:2192/3000 train_loss:3.4398 train_time:602503ms step_avg:276.12ms
step:2193/3000 train_loss:3.2673 train_time:602775ms step_avg:276.12ms
step:2194/3000 train_loss:3.5116 train_time:603045ms step_avg:276.12ms
step:2195/3000 train_loss:3.3818 train_time:603315ms step_avg:276.12ms
step:2196/3000 train_loss:3.3802 train_time:603583ms step_avg:276.11ms
step:2197/3000 train_loss:3.2897 train_time:603852ms step_avg:276.11ms
step:2198/3000 train_loss:3.4277 train_time:604121ms step_avg:276.11ms
step:2199/3000 train_loss:3.6028 train_time:604390ms step_avg:276.10ms
step:2200/3000 train_loss:3.4324 train_time:604659ms step_avg:276.10ms
step:2201/3000 train_loss:3.3270 train_time:604929ms step_avg:276.10ms
step:2202/3000 train_loss:3.3540 train_time:605196ms step_avg:276.09ms
step:2203/3000 train_loss:3.4599 train_time:605470ms step_avg:276.09ms
step:2204/3000 train_loss:3.3037 train_time:605737ms step_avg:276.09ms
step:2205/3000 train_loss:3.4243 train_time:606006ms step_avg:276.08ms
step:2206/3000 train_loss:3.4030 train_time:606275ms step_avg:276.08ms
step:2207/3000 train_loss:3.2189 train_time:606546ms step_avg:276.08ms
step:2208/3000 train_loss:3.4695 train_time:606816ms step_avg:276.08ms
step:2209/3000 train_loss:3.5178 train_time:607086ms step_avg:276.07ms
step:2210/3000 train_loss:3.5260 train_time:607353ms step_avg:276.07ms
step:2211/3000 train_loss:3.4771 train_time:607625ms step_avg:276.07ms
step:2212/3000 train_loss:3.5358 train_time:607895ms step_avg:276.06ms
step:2213/3000 train_loss:3.4990 train_time:608165ms step_avg:276.06ms
step:2214/3000 train_loss:3.5170 train_time:608434ms step_avg:276.06ms
step:2215/3000 train_loss:3.4137 train_time:608704ms step_avg:276.06ms
step:2216/3000 train_loss:3.5427 train_time:608975ms step_avg:276.05ms
step:2217/3000 train_loss:3.3892 train_time:609243ms step_avg:276.05ms
step:2218/3000 train_loss:3.4907 train_time:609513ms step_avg:276.05ms
step:2219/3000 train_loss:3.5694 train_time:609783ms step_avg:276.04ms
step:2220/3000 train_loss:3.4874 train_time:610052ms step_avg:276.04ms
step:2221/3000 train_loss:3.3310 train_time:610322ms step_avg:276.04ms
step:2222/3000 train_loss:3.5069 train_time:610593ms step_avg:276.04ms
step:2223/3000 train_loss:3.4469 train_time:610864ms step_avg:276.03ms
step:2224/3000 train_loss:3.4173 train_time:611133ms step_avg:276.03ms
step:2225/3000 train_loss:3.5707 train_time:611399ms step_avg:276.03ms
step:2226/3000 train_loss:3.4747 train_time:611671ms step_avg:276.02ms
step:2227/3000 train_loss:3.8210 train_time:611941ms step_avg:276.02ms
step:2228/3000 train_loss:3.4526 train_time:612212ms step_avg:276.02ms
step:2229/3000 train_loss:3.5130 train_time:612477ms step_avg:276.01ms
step:2230/3000 train_loss:3.3727 train_time:612748ms step_avg:276.01ms
step:2231/3000 train_loss:3.4285 train_time:613019ms step_avg:276.01ms
step:2232/3000 train_loss:3.4180 train_time:613290ms step_avg:276.01ms
step:2233/3000 train_loss:3.4070 train_time:613555ms step_avg:276.00ms
step:2234/3000 train_loss:4.0409 train_time:613825ms step_avg:276.00ms
step:2235/3000 train_loss:3.4804 train_time:614095ms step_avg:276.00ms
step:2236/3000 train_loss:3.4158 train_time:614367ms step_avg:276.00ms
step:2237/3000 train_loss:3.4400 train_time:614635ms step_avg:275.99ms
step:2238/3000 train_loss:3.4077 train_time:614905ms step_avg:275.99ms
step:2239/3000 train_loss:3.3706 train_time:615176ms step_avg:275.99ms
step:2240/3000 train_loss:3.5980 train_time:615445ms step_avg:275.98ms
step:2241/3000 train_loss:3.4037 train_time:615714ms step_avg:275.98ms
step:2242/3000 train_loss:3.6489 train_time:615984ms step_avg:275.98ms
step:2243/3000 train_loss:3.4740 train_time:616254ms step_avg:275.98ms
step:2244/3000 train_loss:3.4008 train_time:616521ms step_avg:275.97ms
step:2245/3000 train_loss:3.4333 train_time:616792ms step_avg:275.97ms
step:2246/3000 train_loss:3.3712 train_time:617060ms step_avg:275.97ms
step:2247/3000 train_loss:3.5071 train_time:617330ms step_avg:275.96ms
step:2248/3000 train_loss:3.4748 train_time:617598ms step_avg:275.96ms
step:2249/3000 train_loss:3.3675 train_time:617871ms step_avg:275.96ms
step:2250/3000 train_loss:3.8828 train_time:618137ms step_avg:275.95ms
step:2250/3000 val_loss:3.4433 train_time:618138ms step_avg:275.95ms
step:2251/3000 train_loss:3.4238 train_time:618411ms step_avg:275.95ms
step:2252/3000 train_loss:3.5358 train_time:618686ms step_avg:275.95ms
step:2253/3000 train_loss:3.3315 train_time:618959ms step_avg:275.95ms
step:2254/3000 train_loss:3.3333 train_time:619225ms step_avg:275.95ms
step:2255/3000 train_loss:3.3920 train_time:619492ms step_avg:275.94ms
step:2256/3000 train_loss:3.3415 train_time:619766ms step_avg:275.94ms
step:2257/3000 train_loss:3.3913 train_time:620038ms step_avg:275.94ms
step:2258/3000 train_loss:3.3809 train_time:620306ms step_avg:275.94ms
step:2259/3000 train_loss:3.3562 train_time:620574ms step_avg:275.93ms
step:2260/3000 train_loss:3.4685 train_time:620844ms step_avg:275.93ms
step:2261/3000 train_loss:3.3804 train_time:621115ms step_avg:275.93ms
step:2262/3000 train_loss:3.3857 train_time:621385ms step_avg:275.93ms
step:2263/3000 train_loss:3.6634 train_time:621655ms step_avg:275.92ms
step:2264/3000 train_loss:3.5228 train_time:621925ms step_avg:275.92ms
step:2265/3000 train_loss:3.4671 train_time:622192ms step_avg:275.92ms
step:2266/3000 train_loss:3.3604 train_time:622463ms step_avg:275.91ms
step:2267/3000 train_loss:3.4554 train_time:622732ms step_avg:275.91ms
step:2268/3000 train_loss:3.0743 train_time:623190ms step_avg:275.99ms
step:2269/3000 train_loss:3.3878 train_time:623456ms step_avg:275.99ms
step:2270/3000 train_loss:3.4039 train_time:623725ms step_avg:275.98ms
step:2271/3000 train_loss:3.4455 train_time:623995ms step_avg:275.98ms
step:2272/3000 train_loss:3.3851 train_time:624267ms step_avg:275.98ms
step:2273/3000 train_loss:3.3267 train_time:624534ms step_avg:275.98ms
step:2274/3000 train_loss:3.5208 train_time:624803ms step_avg:275.97ms
step:2275/3000 train_loss:3.3317 train_time:625075ms step_avg:275.97ms
step:2276/3000 train_loss:3.4509 train_time:625346ms step_avg:275.97ms
step:2277/3000 train_loss:3.4036 train_time:625615ms step_avg:275.97ms
step:2278/3000 train_loss:3.3750 train_time:625885ms step_avg:275.96ms
step:2279/3000 train_loss:3.4409 train_time:626156ms step_avg:275.96ms
step:2280/3000 train_loss:3.4063 train_time:626628ms step_avg:276.05ms
step:2281/3000 train_loss:3.4595 train_time:626893ms step_avg:276.04ms
step:2282/3000 train_loss:3.5201 train_time:627162ms step_avg:276.04ms
step:2283/3000 train_loss:3.5062 train_time:627428ms step_avg:276.04ms
step:2284/3000 train_loss:3.5282 train_time:627706ms step_avg:276.04ms
step:2285/3000 train_loss:3.5398 train_time:627977ms step_avg:276.03ms
step:2286/3000 train_loss:3.4973 train_time:628244ms step_avg:276.03ms
step:2287/3000 train_loss:3.5468 train_time:628509ms step_avg:276.02ms
step:2288/3000 train_loss:3.4380 train_time:628781ms step_avg:276.02ms
step:2289/3000 train_loss:3.4714 train_time:629049ms step_avg:276.02ms
step:2290/3000 train_loss:3.4460 train_time:629320ms step_avg:276.02ms
step:2291/3000 train_loss:3.3529 train_time:629586ms step_avg:276.01ms
step:2292/3000 train_loss:3.4084 train_time:629857ms step_avg:276.01ms
step:2293/3000 train_loss:3.6146 train_time:630128ms step_avg:276.01ms
step:2294/3000 train_loss:3.3896 train_time:630395ms step_avg:276.00ms
step:2295/3000 train_loss:3.3804 train_time:630666ms step_avg:276.00ms
step:2296/3000 train_loss:3.5500 train_time:630936ms step_avg:276.00ms
step:2297/3000 train_loss:3.3127 train_time:631207ms step_avg:276.00ms
step:2298/3000 train_loss:3.4504 train_time:631477ms step_avg:276.00ms
step:2299/3000 train_loss:3.4050 train_time:631745ms step_avg:275.99ms
step:2300/3000 train_loss:3.7648 train_time:632015ms step_avg:275.99ms
step:2301/3000 train_loss:3.5611 train_time:632285ms step_avg:275.99ms
step:2302/3000 train_loss:3.2958 train_time:632553ms step_avg:275.98ms
step:2303/3000 train_loss:3.3163 train_time:632824ms step_avg:275.98ms
step:2304/3000 train_loss:3.2716 train_time:633092ms step_avg:275.98ms
step:2305/3000 train_loss:3.3429 train_time:633363ms step_avg:275.98ms
step:2306/3000 train_loss:3.7225 train_time:633629ms step_avg:275.97ms
step:2307/3000 train_loss:3.4527 train_time:633901ms step_avg:275.97ms
step:2308/3000 train_loss:3.3625 train_time:634171ms step_avg:275.97ms
step:2309/3000 train_loss:3.4337 train_time:634441ms step_avg:275.96ms
step:2310/3000 train_loss:3.2738 train_time:634708ms step_avg:275.96ms
step:2311/3000 train_loss:3.3798 train_time:634979ms step_avg:275.96ms
step:2312/3000 train_loss:3.4328 train_time:635248ms step_avg:275.95ms
step:2313/3000 train_loss:3.4548 train_time:635518ms step_avg:275.95ms
step:2314/3000 train_loss:3.5700 train_time:635787ms step_avg:275.95ms
step:2315/3000 train_loss:3.4005 train_time:636058ms step_avg:275.95ms
step:2316/3000 train_loss:3.3962 train_time:636327ms step_avg:275.94ms
step:2317/3000 train_loss:3.3794 train_time:636596ms step_avg:275.94ms
step:2318/3000 train_loss:3.6318 train_time:636867ms step_avg:275.94ms
step:2319/3000 train_loss:3.4164 train_time:637136ms step_avg:275.94ms
step:2320/3000 train_loss:3.4118 train_time:637406ms step_avg:275.93ms
step:2321/3000 train_loss:3.4677 train_time:637675ms step_avg:275.93ms
step:2322/3000 train_loss:3.3837 train_time:637946ms step_avg:275.93ms
step:2323/3000 train_loss:3.4130 train_time:638215ms step_avg:275.93ms
step:2324/3000 train_loss:3.5540 train_time:638486ms step_avg:275.92ms
step:2325/3000 train_loss:3.4520 train_time:638756ms step_avg:275.92ms
step:2326/3000 train_loss:3.4822 train_time:639025ms step_avg:275.92ms
step:2327/3000 train_loss:3.4157 train_time:639294ms step_avg:275.91ms
step:2328/3000 train_loss:3.3580 train_time:639567ms step_avg:275.91ms
step:2329/3000 train_loss:3.4846 train_time:639836ms step_avg:275.91ms
step:2330/3000 train_loss:3.3254 train_time:640106ms step_avg:275.91ms
step:2331/3000 train_loss:3.3828 train_time:640376ms step_avg:275.91ms
step:2332/3000 train_loss:3.7167 train_time:640644ms step_avg:275.90ms
step:2333/3000 train_loss:3.3840 train_time:640913ms step_avg:275.90ms
step:2334/3000 train_loss:3.3781 train_time:641183ms step_avg:275.90ms
step:2335/3000 train_loss:3.4937 train_time:641449ms step_avg:275.89ms
step:2336/3000 train_loss:3.4897 train_time:641717ms step_avg:275.89ms
step:2337/3000 train_loss:3.5147 train_time:641988ms step_avg:275.89ms
step:2338/3000 train_loss:3.5306 train_time:642262ms step_avg:275.89ms
step:2339/3000 train_loss:3.5439 train_time:642529ms step_avg:275.88ms
step:2340/3000 train_loss:3.3979 train_time:642798ms step_avg:275.88ms
step:2341/3000 train_loss:3.5227 train_time:643067ms step_avg:275.88ms
step:2342/3000 train_loss:3.5270 train_time:643339ms step_avg:275.87ms
step:2343/3000 train_loss:3.4333 train_time:643608ms step_avg:275.87ms
step:2344/3000 train_loss:3.4115 train_time:643878ms step_avg:275.87ms
step:2345/3000 train_loss:3.4719 train_time:644147ms step_avg:275.87ms
step:2346/3000 train_loss:3.7283 train_time:644418ms step_avg:275.86ms
step:2347/3000 train_loss:3.3562 train_time:644688ms step_avg:275.86ms
step:2348/3000 train_loss:3.1470 train_time:644959ms step_avg:275.86ms
step:2349/3000 train_loss:3.3920 train_time:645227ms step_avg:275.86ms
step:2350/3000 train_loss:3.4365 train_time:645497ms step_avg:275.85ms
step:2351/3000 train_loss:3.3554 train_time:645767ms step_avg:275.85ms
step:2352/3000 train_loss:3.3890 train_time:646036ms step_avg:275.85ms
step:2353/3000 train_loss:3.4261 train_time:646306ms step_avg:275.85ms
step:2354/3000 train_loss:3.3749 train_time:646576ms step_avg:275.84ms
step:2355/3000 train_loss:3.3595 train_time:646845ms step_avg:275.84ms
step:2356/3000 train_loss:3.5661 train_time:647117ms step_avg:275.84ms
step:2357/3000 train_loss:3.4414 train_time:647384ms step_avg:275.83ms
step:2358/3000 train_loss:3.4803 train_time:647653ms step_avg:275.83ms
step:2359/3000 train_loss:3.5285 train_time:647924ms step_avg:275.83ms
step:2360/3000 train_loss:3.5544 train_time:648191ms step_avg:275.83ms
step:2361/3000 train_loss:3.4326 train_time:648464ms step_avg:275.82ms
step:2362/3000 train_loss:3.5588 train_time:648730ms step_avg:275.82ms
step:2363/3000 train_loss:3.3749 train_time:648999ms step_avg:275.82ms
step:2364/3000 train_loss:3.4721 train_time:649269ms step_avg:275.82ms
step:2365/3000 train_loss:3.2339 train_time:649538ms step_avg:275.81ms
step:2366/3000 train_loss:3.3809 train_time:649807ms step_avg:275.81ms
step:2367/3000 train_loss:3.3883 train_time:650078ms step_avg:275.81ms
step:2368/3000 train_loss:3.3094 train_time:650347ms step_avg:275.80ms
step:2369/3000 train_loss:3.4876 train_time:650616ms step_avg:275.80ms
step:2370/3000 train_loss:3.3759 train_time:650887ms step_avg:275.80ms
step:2371/3000 train_loss:3.4925 train_time:651159ms step_avg:275.80ms
step:2372/3000 train_loss:3.5534 train_time:651428ms step_avg:275.80ms
step:2373/3000 train_loss:3.4772 train_time:651696ms step_avg:275.79ms
step:2374/3000 train_loss:3.3587 train_time:651967ms step_avg:275.79ms
step:2375/3000 train_loss:3.4105 train_time:652237ms step_avg:275.79ms
step:2375/3000 val_loss:3.4241 train_time:652238ms step_avg:275.79ms
step:2376/3000 train_loss:3.3153 train_time:652510ms step_avg:275.79ms
step:2377/3000 train_loss:3.5754 train_time:652783ms step_avg:275.78ms
step:2378/3000 train_loss:3.4017 train_time:653055ms step_avg:275.78ms
step:2379/3000 train_loss:3.4598 train_time:653323ms step_avg:275.78ms
step:2380/3000 train_loss:3.2953 train_time:653589ms step_avg:275.78ms
step:2381/3000 train_loss:3.4215 train_time:653860ms step_avg:275.77ms
step:2382/3000 train_loss:3.3685 train_time:654131ms step_avg:275.77ms
step:2383/3000 train_loss:3.3767 train_time:654399ms step_avg:275.77ms
step:2384/3000 train_loss:3.6840 train_time:654667ms step_avg:275.77ms
step:2385/3000 train_loss:3.4353 train_time:654936ms step_avg:275.76ms
step:2386/3000 train_loss:3.5105 train_time:655208ms step_avg:275.76ms
step:2387/3000 train_loss:3.3168 train_time:655477ms step_avg:275.76ms
step:2388/3000 train_loss:3.4066 train_time:655747ms step_avg:275.76ms
step:2389/3000 train_loss:3.3724 train_time:656016ms step_avg:275.75ms
step:2390/3000 train_loss:3.5034 train_time:656287ms step_avg:275.75ms
step:2391/3000 train_loss:3.3826 train_time:656557ms step_avg:275.75ms
step:2392/3000 train_loss:3.4259 train_time:656826ms step_avg:275.75ms
step:2393/3000 train_loss:3.5012 train_time:657092ms step_avg:275.74ms
step:2394/3000 train_loss:3.5367 train_time:657363ms step_avg:275.74ms
step:2395/3000 train_loss:3.4529 train_time:657630ms step_avg:275.74ms
step:2396/3000 train_loss:3.4916 train_time:657899ms step_avg:275.73ms
step:2397/3000 train_loss:3.4420 train_time:658170ms step_avg:275.73ms
step:2398/3000 train_loss:3.4920 train_time:658443ms step_avg:275.73ms
step:2399/3000 train_loss:3.0094 train_time:658710ms step_avg:275.73ms
step:2400/3000 train_loss:3.2307 train_time:658981ms step_avg:275.72ms
step:2401/3000 train_loss:3.3680 train_time:659250ms step_avg:275.72ms
step:2402/3000 train_loss:3.2271 train_time:659518ms step_avg:275.72ms
step:2403/3000 train_loss:3.4410 train_time:659788ms step_avg:275.72ms
step:2404/3000 train_loss:3.4535 train_time:660057ms step_avg:275.71ms
step:2405/3000 train_loss:3.3615 train_time:660328ms step_avg:275.71ms
step:2406/3000 train_loss:3.3579 train_time:660596ms step_avg:275.71ms
step:2407/3000 train_loss:3.6676 train_time:660866ms step_avg:275.71ms
step:2408/3000 train_loss:3.4174 train_time:661133ms step_avg:275.70ms
step:2409/3000 train_loss:3.4669 train_time:661404ms step_avg:275.70ms
step:2410/3000 train_loss:3.5945 train_time:661672ms step_avg:275.70ms
step:2411/3000 train_loss:3.4024 train_time:661946ms step_avg:275.70ms
step:2412/3000 train_loss:3.3663 train_time:662214ms step_avg:275.69ms
step:2413/3000 train_loss:3.3445 train_time:662483ms step_avg:275.69ms
step:2414/3000 train_loss:3.3241 train_time:662752ms step_avg:275.69ms
step:2415/3000 train_loss:3.3790 train_time:663022ms step_avg:275.68ms
step:2416/3000 train_loss:3.3896 train_time:663292ms step_avg:275.68ms
step:2417/3000 train_loss:3.3930 train_time:663562ms step_avg:275.68ms
step:2418/3000 train_loss:3.4538 train_time:663830ms step_avg:275.68ms
step:2419/3000 train_loss:3.4189 train_time:664100ms step_avg:275.67ms
step:2420/3000 train_loss:3.4035 train_time:664371ms step_avg:275.67ms
step:2421/3000 train_loss:3.3570 train_time:664643ms step_avg:275.67ms
step:2422/3000 train_loss:3.4140 train_time:664911ms step_avg:275.67ms
step:2423/3000 train_loss:3.4537 train_time:665181ms step_avg:275.67ms
step:2424/3000 train_loss:3.4746 train_time:665451ms step_avg:275.66ms
step:2425/3000 train_loss:3.3913 train_time:665718ms step_avg:275.66ms
step:2426/3000 train_loss:3.3720 train_time:665989ms step_avg:275.66ms
step:2427/3000 train_loss:3.4062 train_time:666260ms step_avg:275.66ms
step:2428/3000 train_loss:3.5397 train_time:666530ms step_avg:275.65ms
step:2429/3000 train_loss:3.3998 train_time:666799ms step_avg:275.65ms
step:2430/3000 train_loss:3.4955 train_time:667070ms step_avg:275.65ms
step:2431/3000 train_loss:3.7051 train_time:667340ms step_avg:275.65ms
step:2432/3000 train_loss:3.2874 train_time:667609ms step_avg:275.64ms
step:2433/3000 train_loss:3.5525 train_time:667878ms step_avg:275.64ms
step:2434/3000 train_loss:3.5951 train_time:668150ms step_avg:275.64ms
step:2435/3000 train_loss:3.3948 train_time:668419ms step_avg:275.64ms
step:2436/3000 train_loss:3.4688 train_time:668688ms step_avg:275.63ms
step:2437/3000 train_loss:3.3474 train_time:668958ms step_avg:275.63ms
step:2438/3000 train_loss:3.4223 train_time:669228ms step_avg:275.63ms
step:2439/3000 train_loss:3.5604 train_time:669496ms step_avg:275.63ms
step:2440/3000 train_loss:3.4926 train_time:669766ms step_avg:275.62ms
step:2441/3000 train_loss:3.4981 train_time:670035ms step_avg:275.62ms
step:2442/3000 train_loss:3.3755 train_time:670305ms step_avg:275.62ms
step:2443/3000 train_loss:3.4029 train_time:670571ms step_avg:275.61ms
step:2444/3000 train_loss:3.6470 train_time:670843ms step_avg:275.61ms
step:2445/3000 train_loss:3.3771 train_time:671113ms step_avg:275.61ms
step:2446/3000 train_loss:3.4537 train_time:671386ms step_avg:275.61ms
step:2447/3000 train_loss:3.5682 train_time:671650ms step_avg:275.61ms
step:2448/3000 train_loss:3.4958 train_time:671921ms step_avg:275.60ms
step:2449/3000 train_loss:3.4300 train_time:672191ms step_avg:275.60ms
step:2450/3000 train_loss:3.3173 train_time:672463ms step_avg:275.60ms
step:2451/3000 train_loss:3.9276 train_time:672730ms step_avg:275.60ms
step:2452/3000 train_loss:3.3112 train_time:673001ms step_avg:275.59ms
step:2453/3000 train_loss:3.3788 train_time:673271ms step_avg:275.59ms
step:2454/3000 train_loss:3.4144 train_time:673542ms step_avg:275.59ms
step:2455/3000 train_loss:3.4828 train_time:673810ms step_avg:275.59ms
step:2456/3000 train_loss:3.4064 train_time:674079ms step_avg:275.58ms
step:2457/3000 train_loss:3.4383 train_time:674544ms step_avg:275.66ms
step:2458/3000 train_loss:3.4680 train_time:674808ms step_avg:275.66ms
step:2459/3000 train_loss:3.3793 train_time:675072ms step_avg:275.65ms
step:2460/3000 train_loss:3.3903 train_time:675346ms step_avg:275.65ms
step:2461/3000 train_loss:3.4044 train_time:675617ms step_avg:275.65ms
step:2462/3000 train_loss:3.3890 train_time:675886ms step_avg:275.65ms
step:2463/3000 train_loss:3.4434 train_time:676151ms step_avg:275.64ms
step:2464/3000 train_loss:3.4457 train_time:676422ms step_avg:275.64ms
step:2465/3000 train_loss:3.4300 train_time:676693ms step_avg:275.64ms
step:2466/3000 train_loss:3.5015 train_time:676964ms step_avg:275.64ms
step:2467/3000 train_loss:3.3152 train_time:677228ms step_avg:275.63ms
step:2468/3000 train_loss:3.5761 train_time:677498ms step_avg:275.63ms
step:2469/3000 train_loss:3.4648 train_time:677768ms step_avg:275.63ms
step:2470/3000 train_loss:3.4286 train_time:678243ms step_avg:275.71ms
step:2471/3000 train_loss:3.5392 train_time:678509ms step_avg:275.70ms
step:2472/3000 train_loss:3.2477 train_time:678773ms step_avg:275.70ms
step:2473/3000 train_loss:3.3872 train_time:679041ms step_avg:275.70ms
step:2474/3000 train_loss:3.4751 train_time:679313ms step_avg:275.70ms
step:2475/3000 train_loss:3.1439 train_time:679583ms step_avg:275.69ms
step:2476/3000 train_loss:3.5704 train_time:679852ms step_avg:275.69ms
step:2477/3000 train_loss:3.3912 train_time:680118ms step_avg:275.69ms
step:2478/3000 train_loss:3.4023 train_time:680390ms step_avg:275.68ms
step:2479/3000 train_loss:3.4140 train_time:680661ms step_avg:275.68ms
step:2480/3000 train_loss:3.4320 train_time:680929ms step_avg:275.68ms
step:2481/3000 train_loss:3.4773 train_time:681197ms step_avg:275.68ms
step:2482/3000 train_loss:3.7039 train_time:681464ms step_avg:275.67ms
step:2483/3000 train_loss:3.3032 train_time:681734ms step_avg:275.67ms
step:2484/3000 train_loss:3.4675 train_time:682006ms step_avg:275.67ms
step:2485/3000 train_loss:3.4604 train_time:682273ms step_avg:275.67ms
step:2486/3000 train_loss:3.4441 train_time:682542ms step_avg:275.66ms
step:2487/3000 train_loss:3.2374 train_time:682812ms step_avg:275.66ms
step:2488/3000 train_loss:3.2461 train_time:683081ms step_avg:275.66ms
step:2489/3000 train_loss:3.3212 train_time:683350ms step_avg:275.66ms
step:2490/3000 train_loss:3.4172 train_time:683619ms step_avg:275.65ms
step:2491/3000 train_loss:3.4170 train_time:683889ms step_avg:275.65ms
step:2492/3000 train_loss:3.5047 train_time:684157ms step_avg:275.65ms
step:2493/3000 train_loss:3.4309 train_time:684426ms step_avg:275.64ms
step:2494/3000 train_loss:3.3883 train_time:684694ms step_avg:275.64ms
step:2495/3000 train_loss:3.4333 train_time:684966ms step_avg:275.64ms
step:2496/3000 train_loss:3.3915 train_time:685232ms step_avg:275.64ms
step:2497/3000 train_loss:3.2871 train_time:685505ms step_avg:275.64ms
step:2498/3000 train_loss:3.5368 train_time:685773ms step_avg:275.63ms
step:2499/3000 train_loss:3.3326 train_time:686046ms step_avg:275.63ms
step:2500/3000 train_loss:3.3856 train_time:686311ms step_avg:275.63ms
step:2500/3000 val_loss:3.4077 train_time:686312ms step_avg:275.63ms
step:2501/3000 train_loss:3.4698 train_time:686583ms step_avg:275.63ms
step:2502/3000 train_loss:3.6086 train_time:686858ms step_avg:275.63ms
step:2503/3000 train_loss:3.5987 train_time:687130ms step_avg:275.62ms
step:2504/3000 train_loss:3.2635 train_time:687398ms step_avg:275.62ms
step:2505/3000 train_loss:3.4417 train_time:687665ms step_avg:275.62ms
step:2506/3000 train_loss:3.5119 train_time:687937ms step_avg:275.62ms
step:2507/3000 train_loss:3.6135 train_time:688208ms step_avg:275.61ms
step:2508/3000 train_loss:3.3636 train_time:688478ms step_avg:275.61ms
step:2509/3000 train_loss:3.5018 train_time:688747ms step_avg:275.61ms
step:2510/3000 train_loss:3.3913 train_time:689016ms step_avg:275.61ms
step:2511/3000 train_loss:3.3718 train_time:689286ms step_avg:275.60ms
step:2512/3000 train_loss:3.4536 train_time:689557ms step_avg:275.60ms
step:2513/3000 train_loss:3.3315 train_time:689825ms step_avg:275.60ms
step:2514/3000 train_loss:3.3217 train_time:690095ms step_avg:275.60ms
step:2515/3000 train_loss:3.4617 train_time:690364ms step_avg:275.59ms
step:2516/3000 train_loss:3.3577 train_time:690636ms step_avg:275.59ms
step:2517/3000 train_loss:3.3979 train_time:690903ms step_avg:275.59ms
step:2518/3000 train_loss:3.4845 train_time:691172ms step_avg:275.59ms
step:2519/3000 train_loss:3.3863 train_time:691443ms step_avg:275.58ms
step:2520/3000 train_loss:3.3373 train_time:691712ms step_avg:275.58ms
step:2521/3000 train_loss:3.3998 train_time:691981ms step_avg:275.58ms
step:2522/3000 train_loss:3.4183 train_time:692249ms step_avg:275.58ms
step:2523/3000 train_loss:3.4532 train_time:692521ms step_avg:275.58ms
step:2524/3000 train_loss:3.4619 train_time:692791ms step_avg:275.57ms
step:2525/3000 train_loss:3.4032 train_time:693061ms step_avg:275.57ms
step:2526/3000 train_loss:3.4029 train_time:693332ms step_avg:275.57ms
step:2527/3000 train_loss:3.5364 train_time:693601ms step_avg:275.57ms
step:2528/3000 train_loss:3.6051 train_time:693870ms step_avg:275.56ms
step:2529/3000 train_loss:3.3622 train_time:694141ms step_avg:275.56ms
step:2530/3000 train_loss:3.5553 train_time:694411ms step_avg:275.56ms
step:2531/3000 train_loss:3.3308 train_time:694682ms step_avg:275.56ms
step:2532/3000 train_loss:3.4051 train_time:694953ms step_avg:275.56ms
step:2533/3000 train_loss:3.5386 train_time:695220ms step_avg:275.55ms
step:2534/3000 train_loss:3.4204 train_time:695490ms step_avg:275.55ms
step:2535/3000 train_loss:3.3774 train_time:695762ms step_avg:275.55ms
step:2536/3000 train_loss:3.4607 train_time:696036ms step_avg:275.55ms
step:2537/3000 train_loss:3.3433 train_time:696306ms step_avg:275.55ms
step:2538/3000 train_loss:3.5834 train_time:696576ms step_avg:275.54ms
step:2539/3000 train_loss:3.4668 train_time:696845ms step_avg:275.54ms
step:2540/3000 train_loss:3.5020 train_time:697117ms step_avg:275.54ms
step:2541/3000 train_loss:3.3990 train_time:697385ms step_avg:275.54ms
step:2542/3000 train_loss:3.4406 train_time:697656ms step_avg:275.54ms
step:2543/3000 train_loss:3.3587 train_time:697924ms step_avg:275.53ms
step:2544/3000 train_loss:3.5035 train_time:698195ms step_avg:275.53ms
step:2545/3000 train_loss:3.2959 train_time:698463ms step_avg:275.53ms
step:2546/3000 train_loss:3.3089 train_time:698736ms step_avg:275.53ms
step:2547/3000 train_loss:3.5408 train_time:699001ms step_avg:275.52ms
step:2548/3000 train_loss:3.2320 train_time:699271ms step_avg:275.52ms
step:2549/3000 train_loss:3.4344 train_time:699541ms step_avg:275.52ms
step:2550/3000 train_loss:3.2772 train_time:699812ms step_avg:275.52ms
step:2551/3000 train_loss:3.3146 train_time:700082ms step_avg:275.51ms
step:2552/3000 train_loss:3.4155 train_time:700352ms step_avg:275.51ms
step:2553/3000 train_loss:3.4392 train_time:700620ms step_avg:275.51ms
step:2554/3000 train_loss:3.4255 train_time:700893ms step_avg:275.51ms
step:2555/3000 train_loss:3.2909 train_time:701161ms step_avg:275.51ms
step:2556/3000 train_loss:3.5164 train_time:701433ms step_avg:275.50ms
step:2557/3000 train_loss:3.3800 train_time:701701ms step_avg:275.50ms
step:2558/3000 train_loss:3.3439 train_time:701972ms step_avg:275.50ms
step:2559/3000 train_loss:3.4905 train_time:702242ms step_avg:275.50ms
step:2560/3000 train_loss:3.3411 train_time:702512ms step_avg:275.49ms
step:2561/3000 train_loss:3.3108 train_time:702781ms step_avg:275.49ms
step:2562/3000 train_loss:3.5733 train_time:703050ms step_avg:275.49ms
step:2563/3000 train_loss:3.2878 train_time:703321ms step_avg:275.49ms
step:2564/3000 train_loss:3.4183 train_time:703592ms step_avg:275.49ms
step:2565/3000 train_loss:3.4904 train_time:703861ms step_avg:275.48ms
step:2566/3000 train_loss:3.3521 train_time:704135ms step_avg:275.48ms
step:2567/3000 train_loss:3.4083 train_time:704401ms step_avg:275.48ms
step:2568/3000 train_loss:3.4643 train_time:704671ms step_avg:275.48ms
step:2569/3000 train_loss:3.3077 train_time:704942ms step_avg:275.48ms
step:2570/3000 train_loss:3.4074 train_time:705210ms step_avg:275.47ms
step:2571/3000 train_loss:3.4285 train_time:705480ms step_avg:275.47ms
step:2572/3000 train_loss:3.4768 train_time:705750ms step_avg:275.47ms
step:2573/3000 train_loss:3.4756 train_time:706018ms step_avg:275.47ms
step:2574/3000 train_loss:3.4290 train_time:706288ms step_avg:275.46ms
step:2575/3000 train_loss:3.2322 train_time:706560ms step_avg:275.46ms
step:2576/3000 train_loss:3.4490 train_time:706830ms step_avg:275.46ms
step:2577/3000 train_loss:3.7258 train_time:707100ms step_avg:275.46ms
step:2578/3000 train_loss:3.3225 train_time:707367ms step_avg:275.45ms
step:2579/3000 train_loss:3.4992 train_time:707640ms step_avg:275.45ms
step:2580/3000 train_loss:3.4738 train_time:707909ms step_avg:275.45ms
step:2581/3000 train_loss:3.3154 train_time:708179ms step_avg:275.45ms
step:2582/3000 train_loss:3.2233 train_time:708449ms step_avg:275.45ms
step:2583/3000 train_loss:3.5030 train_time:708719ms step_avg:275.44ms
step:2584/3000 train_loss:3.3090 train_time:708988ms step_avg:275.44ms
step:2585/3000 train_loss:3.0996 train_time:709258ms step_avg:275.44ms
step:2586/3000 train_loss:3.4873 train_time:709528ms step_avg:275.44ms
step:2587/3000 train_loss:3.3043 train_time:709797ms step_avg:275.44ms
step:2588/3000 train_loss:3.4685 train_time:710063ms step_avg:275.43ms
step:2589/3000 train_loss:3.3239 train_time:710337ms step_avg:275.43ms
step:2590/3000 train_loss:3.5233 train_time:710606ms step_avg:275.43ms
step:2591/3000 train_loss:3.1923 train_time:710877ms step_avg:275.43ms
step:2592/3000 train_loss:3.3162 train_time:711142ms step_avg:275.42ms
step:2593/3000 train_loss:3.5472 train_time:711412ms step_avg:275.42ms
step:2594/3000 train_loss:3.6931 train_time:711683ms step_avg:275.42ms
step:2595/3000 train_loss:3.4091 train_time:711952ms step_avg:275.42ms
step:2596/3000 train_loss:3.3541 train_time:712219ms step_avg:275.41ms
step:2597/3000 train_loss:3.4143 train_time:712493ms step_avg:275.41ms
step:2598/3000 train_loss:3.9145 train_time:712763ms step_avg:275.41ms
step:2599/3000 train_loss:3.7177 train_time:713032ms step_avg:275.41ms
step:2600/3000 train_loss:3.3738 train_time:713298ms step_avg:275.40ms
step:2601/3000 train_loss:3.3787 train_time:713567ms step_avg:275.40ms
step:2602/3000 train_loss:3.2309 train_time:713839ms step_avg:275.40ms
step:2603/3000 train_loss:3.5856 train_time:714111ms step_avg:275.40ms
step:2604/3000 train_loss:3.2789 train_time:714379ms step_avg:275.40ms
step:2605/3000 train_loss:3.4951 train_time:714649ms step_avg:275.39ms
step:2606/3000 train_loss:3.5375 train_time:714920ms step_avg:275.39ms
step:2607/3000 train_loss:3.3402 train_time:715189ms step_avg:275.39ms
step:2608/3000 train_loss:3.4142 train_time:715458ms step_avg:275.39ms
step:2609/3000 train_loss:3.4449 train_time:715729ms step_avg:275.39ms
step:2610/3000 train_loss:3.3250 train_time:715998ms step_avg:275.38ms
step:2611/3000 train_loss:3.2855 train_time:716267ms step_avg:275.38ms
step:2612/3000 train_loss:3.4774 train_time:716538ms step_avg:275.38ms
step:2613/3000 train_loss:3.4724 train_time:716808ms step_avg:275.38ms
step:2614/3000 train_loss:3.4023 train_time:717078ms step_avg:275.38ms
step:2615/3000 train_loss:3.3564 train_time:717346ms step_avg:275.37ms
step:2616/3000 train_loss:3.3480 train_time:717613ms step_avg:275.37ms
step:2617/3000 train_loss:3.5794 train_time:717882ms step_avg:275.37ms
step:2618/3000 train_loss:3.3748 train_time:718154ms step_avg:275.37ms
step:2619/3000 train_loss:3.4037 train_time:718420ms step_avg:275.36ms
step:2620/3000 train_loss:3.3260 train_time:718690ms step_avg:275.36ms
step:2621/3000 train_loss:3.3941 train_time:718960ms step_avg:275.36ms
step:2622/3000 train_loss:3.4902 train_time:719235ms step_avg:275.36ms
step:2623/3000 train_loss:3.4728 train_time:719502ms step_avg:275.35ms
step:2624/3000 train_loss:3.3370 train_time:719772ms step_avg:275.35ms
step:2625/3000 train_loss:3.5878 train_time:720041ms step_avg:275.35ms
step:2625/3000 val_loss:3.3921 train_time:720042ms step_avg:275.35ms
step:2626/3000 train_loss:3.4026 train_time:720312ms step_avg:275.35ms
step:2627/3000 train_loss:3.4795 train_time:720589ms step_avg:275.35ms
step:2628/3000 train_loss:3.4468 train_time:720861ms step_avg:275.35ms
step:2629/3000 train_loss:4.7259 train_time:721129ms step_avg:275.35ms
step:2630/3000 train_loss:3.3688 train_time:721394ms step_avg:275.34ms
step:2631/3000 train_loss:3.4463 train_time:721670ms step_avg:275.34ms
step:2632/3000 train_loss:3.4076 train_time:721943ms step_avg:275.34ms
step:2633/3000 train_loss:3.4328 train_time:722212ms step_avg:275.34ms
step:2634/3000 train_loss:3.4603 train_time:722480ms step_avg:275.34ms
step:2635/3000 train_loss:3.5506 train_time:722751ms step_avg:275.33ms
step:2636/3000 train_loss:3.5169 train_time:723024ms step_avg:275.33ms
step:2637/3000 train_loss:3.4230 train_time:723292ms step_avg:275.33ms
step:2638/3000 train_loss:3.4091 train_time:723562ms step_avg:275.33ms
step:2639/3000 train_loss:3.6638 train_time:723834ms step_avg:275.33ms
step:2640/3000 train_loss:3.4811 train_time:724106ms step_avg:275.33ms
step:2641/3000 train_loss:3.2848 train_time:724374ms step_avg:275.32ms
step:2642/3000 train_loss:3.3552 train_time:724645ms step_avg:275.32ms
step:2643/3000 train_loss:3.5184 train_time:724914ms step_avg:275.32ms
step:2644/3000 train_loss:3.2196 train_time:725185ms step_avg:275.32ms
step:2645/3000 train_loss:3.4439 train_time:725453ms step_avg:275.31ms
step:2646/3000 train_loss:3.3002 train_time:725909ms step_avg:275.38ms
step:2647/3000 train_loss:3.3832 train_time:726173ms step_avg:275.38ms
step:2648/3000 train_loss:3.4821 train_time:726439ms step_avg:275.38ms
step:2649/3000 train_loss:3.4050 train_time:726714ms step_avg:275.37ms
step:2650/3000 train_loss:3.5515 train_time:726987ms step_avg:275.37ms
step:2651/3000 train_loss:3.3424 train_time:727253ms step_avg:275.37ms
step:2652/3000 train_loss:3.4028 train_time:727522ms step_avg:275.37ms
step:2653/3000 train_loss:3.2110 train_time:727793ms step_avg:275.37ms
step:2654/3000 train_loss:3.5827 train_time:728065ms step_avg:275.37ms
step:2655/3000 train_loss:3.2823 train_time:728334ms step_avg:275.36ms
step:2656/3000 train_loss:3.2872 train_time:728602ms step_avg:275.36ms
step:2657/3000 train_loss:4.9515 train_time:728872ms step_avg:275.36ms
step:2658/3000 train_loss:3.4896 train_time:729144ms step_avg:275.36ms
step:2659/3000 train_loss:3.3687 train_time:729412ms step_avg:275.35ms
step:2660/3000 train_loss:3.2510 train_time:729879ms step_avg:275.43ms
step:2661/3000 train_loss:3.3271 train_time:730147ms step_avg:275.42ms
step:2662/3000 train_loss:3.2685 train_time:730412ms step_avg:275.42ms
step:2663/3000 train_loss:3.3643 train_time:730676ms step_avg:275.41ms
step:2664/3000 train_loss:3.4289 train_time:730956ms step_avg:275.42ms
step:2665/3000 train_loss:3.3320 train_time:731229ms step_avg:275.42ms
step:2666/3000 train_loss:3.3423 train_time:731493ms step_avg:275.41ms
step:2667/3000 train_loss:3.3106 train_time:731760ms step_avg:275.41ms
step:2668/3000 train_loss:3.3537 train_time:732035ms step_avg:275.41ms
step:2669/3000 train_loss:3.3673 train_time:732304ms step_avg:275.41ms
step:2670/3000 train_loss:3.3895 train_time:732572ms step_avg:275.40ms
step:2671/3000 train_loss:3.2919 train_time:732841ms step_avg:275.40ms
step:2672/3000 train_loss:3.5152 train_time:733112ms step_avg:275.40ms
step:2673/3000 train_loss:3.4569 train_time:733383ms step_avg:275.40ms
step:2674/3000 train_loss:3.2697 train_time:733652ms step_avg:275.40ms
step:2675/3000 train_loss:3.3306 train_time:733924ms step_avg:275.39ms
step:2676/3000 train_loss:3.3570 train_time:734193ms step_avg:275.39ms
step:2677/3000 train_loss:3.5718 train_time:734461ms step_avg:275.39ms
step:2678/3000 train_loss:3.3958 train_time:734733ms step_avg:275.39ms
step:2679/3000 train_loss:3.3763 train_time:735003ms step_avg:275.39ms
step:2680/3000 train_loss:3.4503 train_time:735272ms step_avg:275.38ms
step:2681/3000 train_loss:3.2605 train_time:735542ms step_avg:275.38ms
step:2682/3000 train_loss:3.4085 train_time:735811ms step_avg:275.38ms
step:2683/3000 train_loss:3.3348 train_time:736084ms step_avg:275.38ms
step:2684/3000 train_loss:3.4028 train_time:736353ms step_avg:275.37ms
step:2685/3000 train_loss:3.4749 train_time:736627ms step_avg:275.37ms
step:2686/3000 train_loss:3.3493 train_time:736892ms step_avg:275.37ms
step:2687/3000 train_loss:3.5547 train_time:737160ms step_avg:275.37ms
step:2688/3000 train_loss:3.4440 train_time:737432ms step_avg:275.37ms
step:2689/3000 train_loss:3.2420 train_time:737702ms step_avg:275.36ms
step:2690/3000 train_loss:3.5256 train_time:737973ms step_avg:275.36ms
step:2691/3000 train_loss:3.2913 train_time:738242ms step_avg:275.36ms
step:2692/3000 train_loss:3.4607 train_time:738509ms step_avg:275.36ms
step:2693/3000 train_loss:3.4172 train_time:738776ms step_avg:275.35ms
step:2694/3000 train_loss:3.4010 train_time:739047ms step_avg:275.35ms
step:2695/3000 train_loss:3.3944 train_time:739314ms step_avg:275.35ms
step:2696/3000 train_loss:3.4604 train_time:739584ms step_avg:275.35ms
step:2697/3000 train_loss:3.2979 train_time:739854ms step_avg:275.35ms
step:2698/3000 train_loss:3.3670 train_time:740126ms step_avg:275.34ms
step:2699/3000 train_loss:3.3298 train_time:740394ms step_avg:275.34ms
step:2700/3000 train_loss:3.3011 train_time:740663ms step_avg:275.34ms
step:2701/3000 train_loss:3.5446 train_time:740934ms step_avg:275.34ms
step:2702/3000 train_loss:3.3446 train_time:741205ms step_avg:275.34ms
step:2703/3000 train_loss:3.3312 train_time:741473ms step_avg:275.33ms
step:2704/3000 train_loss:3.3681 train_time:741742ms step_avg:275.33ms
step:2705/3000 train_loss:3.4732 train_time:742012ms step_avg:275.33ms
step:2706/3000 train_loss:3.4086 train_time:742283ms step_avg:275.33ms
step:2707/3000 train_loss:3.3378 train_time:742553ms step_avg:275.33ms
step:2708/3000 train_loss:3.6530 train_time:742822ms step_avg:275.32ms
step:2709/3000 train_loss:3.3382 train_time:743091ms step_avg:275.32ms
step:2710/3000 train_loss:3.4610 train_time:743360ms step_avg:275.32ms
step:2711/3000 train_loss:3.3406 train_time:743632ms step_avg:275.32ms
step:2712/3000 train_loss:3.3735 train_time:743901ms step_avg:275.31ms
step:2713/3000 train_loss:3.2569 train_time:744171ms step_avg:275.31ms
step:2714/3000 train_loss:3.4529 train_time:744441ms step_avg:275.31ms
step:2715/3000 train_loss:3.4896 train_time:744711ms step_avg:275.31ms
step:2716/3000 train_loss:3.2816 train_time:744980ms step_avg:275.31ms
step:2717/3000 train_loss:3.3615 train_time:745252ms step_avg:275.31ms
step:2718/3000 train_loss:3.3201 train_time:745523ms step_avg:275.30ms
step:2719/3000 train_loss:3.4364 train_time:745794ms step_avg:275.30ms
step:2720/3000 train_loss:3.5519 train_time:746059ms step_avg:275.30ms
step:2721/3000 train_loss:3.4501 train_time:746332ms step_avg:275.30ms
step:2722/3000 train_loss:3.4196 train_time:746599ms step_avg:275.29ms
step:2723/3000 train_loss:3.2797 train_time:746870ms step_avg:275.29ms
step:2724/3000 train_loss:3.4067 train_time:747139ms step_avg:275.29ms
step:2725/3000 train_loss:3.5147 train_time:747410ms step_avg:275.29ms
step:2726/3000 train_loss:3.2378 train_time:747676ms step_avg:275.29ms
step:2727/3000 train_loss:3.3030 train_time:747948ms step_avg:275.28ms
step:2728/3000 train_loss:3.2832 train_time:748214ms step_avg:275.28ms
step:2729/3000 train_loss:3.2766 train_time:748488ms step_avg:275.28ms
step:2730/3000 train_loss:3.4088 train_time:748756ms step_avg:275.28ms
step:2731/3000 train_loss:3.2997 train_time:749029ms step_avg:275.28ms
step:2732/3000 train_loss:3.2558 train_time:749296ms step_avg:275.27ms
step:2733/3000 train_loss:3.3650 train_time:749567ms step_avg:275.27ms
step:2734/3000 train_loss:3.3786 train_time:749834ms step_avg:275.27ms
step:2735/3000 train_loss:3.3866 train_time:750103ms step_avg:275.27ms
step:2736/3000 train_loss:3.3785 train_time:750373ms step_avg:275.27ms
step:2737/3000 train_loss:3.5290 train_time:750645ms step_avg:275.26ms
step:2738/3000 train_loss:3.2268 train_time:750913ms step_avg:275.26ms
step:2739/3000 train_loss:3.3059 train_time:751181ms step_avg:275.26ms
step:2740/3000 train_loss:3.2123 train_time:751452ms step_avg:275.26ms
step:2741/3000 train_loss:3.4284 train_time:751722ms step_avg:275.26ms
step:2742/3000 train_loss:3.3880 train_time:751992ms step_avg:275.25ms
step:2743/3000 train_loss:3.5783 train_time:752262ms step_avg:275.25ms
step:2744/3000 train_loss:3.3844 train_time:752533ms step_avg:275.25ms
step:2745/3000 train_loss:3.2852 train_time:752800ms step_avg:275.25ms
step:2746/3000 train_loss:3.3369 train_time:753072ms step_avg:275.25ms
step:2747/3000 train_loss:3.3830 train_time:753341ms step_avg:275.24ms
step:2748/3000 train_loss:3.6985 train_time:753610ms step_avg:275.24ms
step:2749/3000 train_loss:3.5153 train_time:753878ms step_avg:275.24ms
step:2750/3000 train_loss:3.4137 train_time:754149ms step_avg:275.24ms
step:2750/3000 val_loss:3.3778 train_time:754149ms step_avg:275.24ms
step:2751/3000 train_loss:3.3027 train_time:754419ms step_avg:275.23ms
step:2752/3000 train_loss:3.3930 train_time:754694ms step_avg:275.23ms
step:2753/3000 train_loss:3.4167 train_time:754966ms step_avg:275.23ms
step:2754/3000 train_loss:3.3546 train_time:755236ms step_avg:275.23ms
step:2755/3000 train_loss:3.3654 train_time:755500ms step_avg:275.23ms
step:2756/3000 train_loss:3.4214 train_time:755772ms step_avg:275.23ms
step:2757/3000 train_loss:3.3381 train_time:756045ms step_avg:275.23ms
step:2758/3000 train_loss:3.5244 train_time:756315ms step_avg:275.22ms
step:2759/3000 train_loss:3.3878 train_time:756579ms step_avg:275.22ms
step:2760/3000 train_loss:3.3091 train_time:756848ms step_avg:275.22ms
step:2761/3000 train_loss:3.2916 train_time:757121ms step_avg:275.22ms
step:2762/3000 train_loss:3.4001 train_time:757391ms step_avg:275.21ms
step:2763/3000 train_loss:3.2848 train_time:757659ms step_avg:275.21ms
step:2764/3000 train_loss:3.6119 train_time:757929ms step_avg:275.21ms
step:2765/3000 train_loss:3.4392 train_time:758199ms step_avg:275.21ms
step:2766/3000 train_loss:3.3078 train_time:758470ms step_avg:275.21ms
step:2767/3000 train_loss:3.4028 train_time:758738ms step_avg:275.20ms
step:2768/3000 train_loss:3.4799 train_time:759007ms step_avg:275.20ms
step:2769/3000 train_loss:3.1944 train_time:759276ms step_avg:275.20ms
step:2770/3000 train_loss:3.3120 train_time:759544ms step_avg:275.20ms
step:2771/3000 train_loss:3.3437 train_time:759816ms step_avg:275.20ms
step:2772/3000 train_loss:3.3128 train_time:760084ms step_avg:275.19ms
step:2773/3000 train_loss:3.2954 train_time:760355ms step_avg:275.19ms
step:2774/3000 train_loss:3.3785 train_time:760623ms step_avg:275.19ms
step:2775/3000 train_loss:3.2739 train_time:760892ms step_avg:275.19ms
step:2776/3000 train_loss:3.2900 train_time:761161ms step_avg:275.18ms
step:2777/3000 train_loss:3.3205 train_time:761431ms step_avg:275.18ms
step:2778/3000 train_loss:3.2155 train_time:761699ms step_avg:275.18ms
step:2779/3000 train_loss:3.3442 train_time:761969ms step_avg:275.18ms
step:2780/3000 train_loss:3.1946 train_time:762240ms step_avg:275.18ms
step:2781/3000 train_loss:3.4798 train_time:762510ms step_avg:275.18ms
step:2782/3000 train_loss:3.4260 train_time:762781ms step_avg:275.17ms
step:2783/3000 train_loss:3.3623 train_time:763050ms step_avg:275.17ms
step:2784/3000 train_loss:3.4218 train_time:763321ms step_avg:275.17ms
step:2785/3000 train_loss:3.3358 train_time:763590ms step_avg:275.17ms
step:2786/3000 train_loss:3.3199 train_time:763860ms step_avg:275.17ms
step:2787/3000 train_loss:3.7176 train_time:764128ms step_avg:275.16ms
step:2788/3000 train_loss:3.3314 train_time:764400ms step_avg:275.16ms
step:2789/3000 train_loss:3.0932 train_time:764671ms step_avg:275.16ms
step:2790/3000 train_loss:3.4550 train_time:764941ms step_avg:275.16ms
step:2791/3000 train_loss:3.3495 train_time:765211ms step_avg:275.16ms
step:2792/3000 train_loss:3.4006 train_time:765480ms step_avg:275.15ms
step:2793/3000 train_loss:3.5153 train_time:765751ms step_avg:275.15ms
step:2794/3000 train_loss:3.4030 train_time:766022ms step_avg:275.15ms
step:2795/3000 train_loss:3.3703 train_time:766290ms step_avg:275.15ms
step:2796/3000 train_loss:3.3578 train_time:766560ms step_avg:275.15ms
step:2797/3000 train_loss:3.5481 train_time:766830ms step_avg:275.15ms
step:2798/3000 train_loss:3.4033 train_time:767101ms step_avg:275.14ms
step:2799/3000 train_loss:3.2812 train_time:767369ms step_avg:275.14ms
step:2800/3000 train_loss:3.2949 train_time:767640ms step_avg:275.14ms
step:2801/3000 train_loss:3.3999 train_time:767910ms step_avg:275.14ms
step:2802/3000 train_loss:3.2016 train_time:768180ms step_avg:275.14ms
step:2803/3000 train_loss:3.3931 train_time:768449ms step_avg:275.13ms
step:2804/3000 train_loss:3.5298 train_time:768719ms step_avg:275.13ms
step:2805/3000 train_loss:3.3714 train_time:768988ms step_avg:275.13ms
step:2806/3000 train_loss:3.3300 train_time:769258ms step_avg:275.13ms
step:2807/3000 train_loss:3.3416 train_time:769529ms step_avg:275.13ms
step:2808/3000 train_loss:3.4040 train_time:769799ms step_avg:275.12ms
step:2809/3000 train_loss:3.4752 train_time:770069ms step_avg:275.12ms
step:2810/3000 train_loss:3.4377 train_time:770340ms step_avg:275.12ms
step:2811/3000 train_loss:3.3398 train_time:770609ms step_avg:275.12ms
step:2812/3000 train_loss:3.2175 train_time:770877ms step_avg:275.12ms
step:2813/3000 train_loss:3.2965 train_time:771145ms step_avg:275.11ms
step:2814/3000 train_loss:3.3588 train_time:771416ms step_avg:275.11ms
step:2815/3000 train_loss:3.2452 train_time:771684ms step_avg:275.11ms
step:2816/3000 train_loss:4.0115 train_time:771956ms step_avg:275.11ms
step:2817/3000 train_loss:3.1448 train_time:772222ms step_avg:275.11ms
step:2818/3000 train_loss:3.4951 train_time:772492ms step_avg:275.10ms
step:2819/3000 train_loss:3.2764 train_time:772762ms step_avg:275.10ms
step:2820/3000 train_loss:3.4271 train_time:773033ms step_avg:275.10ms
step:2821/3000 train_loss:3.3355 train_time:773301ms step_avg:275.10ms
step:2822/3000 train_loss:3.4038 train_time:773570ms step_avg:275.10ms
step:2823/3000 train_loss:3.4907 train_time:773840ms step_avg:275.09ms
step:2824/3000 train_loss:3.3367 train_time:774111ms step_avg:275.09ms
step:2825/3000 train_loss:3.3058 train_time:774381ms step_avg:275.09ms
step:2826/3000 train_loss:3.1638 train_time:774649ms step_avg:275.09ms
step:2827/3000 train_loss:3.3644 train_time:774920ms step_avg:275.09ms
step:2828/3000 train_loss:3.5049 train_time:775190ms step_avg:275.09ms
step:2829/3000 train_loss:3.5558 train_time:775460ms step_avg:275.08ms
step:2830/3000 train_loss:3.3918 train_time:775727ms step_avg:275.08ms
step:2831/3000 train_loss:3.4151 train_time:775997ms step_avg:275.08ms
step:2832/3000 train_loss:3.3202 train_time:776264ms step_avg:275.08ms
step:2833/3000 train_loss:3.3823 train_time:776534ms step_avg:275.07ms
step:2834/3000 train_loss:3.5005 train_time:776801ms step_avg:275.07ms
step:2835/3000 train_loss:3.2658 train_time:777261ms step_avg:275.14ms
step:2836/3000 train_loss:3.1679 train_time:777526ms step_avg:275.13ms
step:2837/3000 train_loss:3.3986 train_time:777793ms step_avg:275.13ms
step:2838/3000 train_loss:3.6085 train_time:778065ms step_avg:275.13ms
step:2839/3000 train_loss:3.1649 train_time:778338ms step_avg:275.13ms
step:2840/3000 train_loss:3.4873 train_time:778602ms step_avg:275.12ms
step:2841/3000 train_loss:3.3002 train_time:778871ms step_avg:275.12ms
step:2842/3000 train_loss:3.3445 train_time:779142ms step_avg:275.12ms
step:2843/3000 train_loss:3.2909 train_time:779420ms step_avg:275.12ms
step:2844/3000 train_loss:3.4339 train_time:779685ms step_avg:275.12ms
step:2845/3000 train_loss:3.3666 train_time:779954ms step_avg:275.12ms
step:2846/3000 train_loss:3.4446 train_time:780221ms step_avg:275.11ms
step:2847/3000 train_loss:3.4887 train_time:780495ms step_avg:275.11ms
step:2848/3000 train_loss:3.3795 train_time:780763ms step_avg:275.11ms
step:2849/3000 train_loss:3.2887 train_time:781031ms step_avg:275.11ms
step:2850/3000 train_loss:3.5941 train_time:781499ms step_avg:275.18ms
step:2851/3000 train_loss:3.3804 train_time:781763ms step_avg:275.17ms
step:2852/3000 train_loss:3.4995 train_time:782029ms step_avg:275.17ms
step:2853/3000 train_loss:3.3629 train_time:782296ms step_avg:275.17ms
step:2854/3000 train_loss:3.2932 train_time:782569ms step_avg:275.17ms
step:2855/3000 train_loss:3.3870 train_time:782839ms step_avg:275.16ms
step:2856/3000 train_loss:3.5024 train_time:783106ms step_avg:275.16ms
step:2857/3000 train_loss:3.5074 train_time:783374ms step_avg:275.16ms
step:2858/3000 train_loss:3.4120 train_time:783645ms step_avg:275.16ms
step:2859/3000 train_loss:3.4284 train_time:783917ms step_avg:275.16ms
step:2860/3000 train_loss:3.2655 train_time:784184ms step_avg:275.15ms
step:2861/3000 train_loss:3.3112 train_time:784451ms step_avg:275.15ms
step:2862/3000 train_loss:3.2670 train_time:784721ms step_avg:275.15ms
step:2863/3000 train_loss:3.3673 train_time:784992ms step_avg:275.15ms
step:2864/3000 train_loss:3.3825 train_time:785262ms step_avg:275.14ms
step:2865/3000 train_loss:3.4520 train_time:785531ms step_avg:275.14ms
step:2866/3000 train_loss:3.2786 train_time:785801ms step_avg:275.14ms
step:2867/3000 train_loss:3.4673 train_time:786072ms step_avg:275.14ms
step:2868/3000 train_loss:3.4229 train_time:786342ms step_avg:275.14ms
step:2869/3000 train_loss:3.2116 train_time:786613ms step_avg:275.14ms
step:2870/3000 train_loss:3.2941 train_time:786883ms step_avg:275.13ms
step:2871/3000 train_loss:3.2725 train_time:787152ms step_avg:275.13ms
step:2872/3000 train_loss:3.0403 train_time:787422ms step_avg:275.13ms
step:2873/3000 train_loss:3.3580 train_time:787691ms step_avg:275.13ms
step:2874/3000 train_loss:3.3423 train_time:787962ms step_avg:275.13ms
step:2875/3000 train_loss:3.2202 train_time:788231ms step_avg:275.12ms
step:2875/3000 val_loss:3.3664 train_time:788232ms step_avg:275.12ms
step:2876/3000 train_loss:3.1837 train_time:788501ms step_avg:275.12ms
step:2877/3000 train_loss:3.3265 train_time:788781ms step_avg:275.12ms
step:2878/3000 train_loss:3.3542 train_time:789055ms step_avg:275.12ms
step:2879/3000 train_loss:3.6568 train_time:789321ms step_avg:275.12ms
step:2880/3000 train_loss:3.3227 train_time:789588ms step_avg:275.12ms
step:2881/3000 train_loss:3.3373 train_time:789859ms step_avg:275.12ms
step:2882/3000 train_loss:3.2206 train_time:790133ms step_avg:275.12ms
step:2883/3000 train_loss:3.3605 train_time:790400ms step_avg:275.11ms
step:2884/3000 train_loss:3.4681 train_time:790669ms step_avg:275.11ms
step:2885/3000 train_loss:3.3198 train_time:790941ms step_avg:275.11ms
step:2886/3000 train_loss:3.3151 train_time:791213ms step_avg:275.11ms
step:2887/3000 train_loss:3.3937 train_time:791479ms step_avg:275.11ms
step:2888/3000 train_loss:3.3821 train_time:791747ms step_avg:275.10ms
step:2889/3000 train_loss:3.4308 train_time:792018ms step_avg:275.10ms
step:2890/3000 train_loss:3.3245 train_time:792287ms step_avg:275.10ms
step:2891/3000 train_loss:3.3252 train_time:792558ms step_avg:275.10ms
step:2892/3000 train_loss:3.2833 train_time:792827ms step_avg:275.10ms
step:2893/3000 train_loss:3.3157 train_time:793097ms step_avg:275.09ms
step:2894/3000 train_loss:3.2788 train_time:793365ms step_avg:275.09ms
step:2895/3000 train_loss:3.4444 train_time:793639ms step_avg:275.09ms
step:2896/3000 train_loss:3.5017 train_time:793909ms step_avg:275.09ms
step:2897/3000 train_loss:3.3187 train_time:794178ms step_avg:275.09ms
step:2898/3000 train_loss:3.3692 train_time:794447ms step_avg:275.09ms
step:2899/3000 train_loss:3.3696 train_time:794719ms step_avg:275.08ms
step:2900/3000 train_loss:3.2336 train_time:794987ms step_avg:275.08ms
step:2901/3000 train_loss:3.3917 train_time:795258ms step_avg:275.08ms
step:2902/3000 train_loss:3.5386 train_time:795523ms step_avg:275.08ms
step:2903/3000 train_loss:3.3376 train_time:795794ms step_avg:275.08ms
step:2904/3000 train_loss:3.2235 train_time:796062ms step_avg:275.07ms
step:2905/3000 train_loss:3.5191 train_time:796333ms step_avg:275.07ms
step:2906/3000 train_loss:3.3103 train_time:796600ms step_avg:275.07ms
step:2907/3000 train_loss:3.3393 train_time:796872ms step_avg:275.07ms
step:2908/3000 train_loss:3.2360 train_time:797142ms step_avg:275.07ms
step:2909/3000 train_loss:3.2526 train_time:797413ms step_avg:275.06ms
step:2910/3000 train_loss:3.2968 train_time:797681ms step_avg:275.06ms
step:2911/3000 train_loss:3.3923 train_time:797951ms step_avg:275.06ms
step:2912/3000 train_loss:3.4388 train_time:798220ms step_avg:275.06ms
step:2913/3000 train_loss:3.5491 train_time:798489ms step_avg:275.06ms
step:2914/3000 train_loss:3.3621 train_time:798759ms step_avg:275.05ms
step:2915/3000 train_loss:3.2727 train_time:799030ms step_avg:275.05ms
step:2916/3000 train_loss:3.3927 train_time:799300ms step_avg:275.05ms
step:2917/3000 train_loss:3.4227 train_time:799569ms step_avg:275.05ms
step:2918/3000 train_loss:3.4609 train_time:799839ms step_avg:275.05ms
step:2919/3000 train_loss:3.3445 train_time:800110ms step_avg:275.05ms
step:2920/3000 train_loss:3.2245 train_time:800380ms step_avg:275.04ms
step:2921/3000 train_loss:3.2572 train_time:800650ms step_avg:275.04ms
step:2922/3000 train_loss:3.3434 train_time:800920ms step_avg:275.04ms
step:2923/3000 train_loss:3.3726 train_time:801190ms step_avg:275.04ms
step:2924/3000 train_loss:3.3910 train_time:801460ms step_avg:275.04ms
step:2925/3000 train_loss:3.2255 train_time:801730ms step_avg:275.04ms
step:2926/3000 train_loss:3.3556 train_time:801999ms step_avg:275.03ms
step:2927/3000 train_loss:3.2900 train_time:802269ms step_avg:275.03ms
step:2928/3000 train_loss:3.2728 train_time:802540ms step_avg:275.03ms
step:2929/3000 train_loss:3.3690 train_time:802811ms step_avg:275.03ms
step:2930/3000 train_loss:3.2046 train_time:803080ms step_avg:275.03ms
step:2931/3000 train_loss:3.4498 train_time:803349ms step_avg:275.03ms
step:2932/3000 train_loss:3.4638 train_time:803621ms step_avg:275.02ms
step:2933/3000 train_loss:3.3725 train_time:803888ms step_avg:275.02ms
step:2934/3000 train_loss:3.2668 train_time:804159ms step_avg:275.02ms
step:2935/3000 train_loss:3.2206 train_time:804427ms step_avg:275.02ms
step:2936/3000 train_loss:3.3141 train_time:804697ms step_avg:275.02ms
step:2937/3000 train_loss:3.3113 train_time:804965ms step_avg:275.01ms
step:2938/3000 train_loss:3.2625 train_time:805237ms step_avg:275.01ms
step:2939/3000 train_loss:3.4083 train_time:805502ms step_avg:275.01ms
step:2940/3000 train_loss:3.3311 train_time:805772ms step_avg:275.01ms
step:2941/3000 train_loss:3.3801 train_time:806042ms step_avg:275.01ms
step:2942/3000 train_loss:3.5383 train_time:806317ms step_avg:275.01ms
step:2943/3000 train_loss:3.4554 train_time:806583ms step_avg:275.00ms
step:2944/3000 train_loss:3.3881 train_time:806852ms step_avg:275.00ms
step:2945/3000 train_loss:3.5320 train_time:807124ms step_avg:275.00ms
step:2946/3000 train_loss:3.2845 train_time:807394ms step_avg:275.00ms
step:2947/3000 train_loss:3.2629 train_time:807662ms step_avg:275.00ms
step:2948/3000 train_loss:3.2214 train_time:807933ms step_avg:274.99ms
step:2949/3000 train_loss:3.2586 train_time:808201ms step_avg:274.99ms
step:2950/3000 train_loss:3.3070 train_time:808472ms step_avg:274.99ms
step:2951/3000 train_loss:3.3448 train_time:808741ms step_avg:274.99ms
step:2952/3000 train_loss:3.3923 train_time:809013ms step_avg:274.99ms
step:2953/3000 train_loss:3.2684 train_time:809281ms step_avg:274.99ms
step:2954/3000 train_loss:3.3715 train_time:809551ms step_avg:274.98ms
step:2955/3000 train_loss:3.3713 train_time:809822ms step_avg:274.98ms
step:2956/3000 train_loss:3.3749 train_time:810092ms step_avg:274.98ms
step:2957/3000 train_loss:3.2116 train_time:810362ms step_avg:274.98ms
step:2958/3000 train_loss:3.3402 train_time:810632ms step_avg:274.98ms
step:2959/3000 train_loss:3.3870 train_time:810901ms step_avg:274.97ms
step:2960/3000 train_loss:3.3894 train_time:811172ms step_avg:274.97ms
step:2961/3000 train_loss:3.2846 train_time:811442ms step_avg:274.97ms
step:2962/3000 train_loss:3.4682 train_time:811714ms step_avg:274.97ms
step:2963/3000 train_loss:3.3217 train_time:811979ms step_avg:274.97ms
step:2964/3000 train_loss:3.2857 train_time:812249ms step_avg:274.97ms
step:2965/3000 train_loss:3.4129 train_time:812522ms step_avg:274.97ms
step:2966/3000 train_loss:3.4740 train_time:812791ms step_avg:274.96ms
step:2967/3000 train_loss:3.2720 train_time:813060ms step_avg:274.96ms
step:2968/3000 train_loss:3.3389 train_time:813330ms step_avg:274.96ms
step:2969/3000 train_loss:3.3848 train_time:813601ms step_avg:274.96ms
step:2970/3000 train_loss:3.2816 train_time:813870ms step_avg:274.96ms
step:2971/3000 train_loss:3.1784 train_time:814140ms step_avg:274.95ms
step:2972/3000 train_loss:3.2873 train_time:814411ms step_avg:274.95ms
step:2973/3000 train_loss:3.3414 train_time:814681ms step_avg:274.95ms
step:2974/3000 train_loss:3.2096 train_time:814950ms step_avg:274.95ms
step:2975/3000 train_loss:3.4003 train_time:815221ms step_avg:274.95ms
step:2976/3000 train_loss:3.3808 train_time:815488ms step_avg:274.95ms
step:2977/3000 train_loss:3.3923 train_time:815760ms step_avg:274.94ms
step:2978/3000 train_loss:3.3439 train_time:816032ms step_avg:274.94ms
step:2979/3000 train_loss:3.3726 train_time:816302ms step_avg:274.94ms
step:2980/3000 train_loss:3.2282 train_time:816570ms step_avg:274.94ms
step:2981/3000 train_loss:3.0834 train_time:816841ms step_avg:274.94ms
step:2982/3000 train_loss:3.3610 train_time:817112ms step_avg:274.94ms
step:2983/3000 train_loss:3.3170 train_time:817381ms step_avg:274.93ms
step:2984/3000 train_loss:3.3519 train_time:817648ms step_avg:274.93ms
step:2985/3000 train_loss:3.3341 train_time:817920ms step_avg:274.93ms
step:2986/3000 train_loss:3.4210 train_time:818189ms step_avg:274.93ms
step:2987/3000 train_loss:3.4366 train_time:818460ms step_avg:274.93ms
step:2988/3000 train_loss:3.3957 train_time:818729ms step_avg:274.93ms
step:2989/3000 train_loss:3.4004 train_time:818999ms step_avg:274.92ms
step:2990/3000 train_loss:3.2402 train_time:819269ms step_avg:274.92ms
step:2991/3000 train_loss:3.3256 train_time:819539ms step_avg:274.92ms
step:2992/3000 train_loss:3.4020 train_time:819810ms step_avg:274.92ms
step:2993/3000 train_loss:3.4360 train_time:820079ms step_avg:274.92ms
step:2994/3000 train_loss:3.3235 train_time:820346ms step_avg:274.91ms
step:2995/3000 train_loss:3.3344 train_time:820617ms step_avg:274.91ms
step:2996/3000 train_loss:3.3382 train_time:820888ms step_avg:274.91ms
step:2997/3000 train_loss:3.3126 train_time:821158ms step_avg:274.91ms
step:2998/3000 train_loss:3.4575 train_time:821423ms step_avg:274.91ms
step:2999/3000 train_loss:3.2599 train_time:821695ms step_avg:274.91ms
step:3000/3000 train_loss:3.3620 train_time:821964ms step_avg:274.90ms
step:3000/3000 val_loss:3.3595 train_time:821966ms step_avg:274.90ms
